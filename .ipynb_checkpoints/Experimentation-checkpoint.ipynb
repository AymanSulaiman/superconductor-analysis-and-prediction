{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/anlgrbz/super-conductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data','train.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in df.columns]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.pop()\n",
    "features = cols\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.columns[-1]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in features:\n",
    "    x=df[i]\n",
    "    y=df[target]\n",
    "    m, c = np.polyfit(x, y, 1)\n",
    "    plt.plot(x, y, 'o')\n",
    "    plt.plot(x, m*x + c)\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel(target)\n",
    "    plt.title(f'{i} and {target}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with different ML, DL, and AI to see what results we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[features]\n",
    "y = df[target].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "r2_training = model_linear.score(X_train,y_train)\n",
    "r2_testing = model_linear.score(X_test, y_test)\n",
    "\n",
    "print(f'''\n",
    "Training R^2 Scores: {round(100*r2_training,2)}%\n",
    "Testing R^2 Scores:  {round(100*r2_testing,2)}%\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "regressor = XGBRegressor()\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(regressor,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train,\n",
    "         y_train)\n",
    "print('---------------------------------------------------------------------')\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_evaluation(model, skip_epochs=0, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    \"\"\"\n",
    "    For a given neural network model that has already been fit, prints for the train and tests sets the MSE and r squared\n",
    "    values, a line graph of the loss in each epoch, and a scatterplot of predicted vs. actual values with a line\n",
    "    representing where predicted = actual values. Optionally, a value for skip_epoch can be provided, which skips that\n",
    "    number of epochs in the line graph of losses (useful in cases where the loss in the first epoch is orders of magnitude\n",
    "    larger than subsequent epochs). Training and test sets can also optionally be specified.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "\n",
    "    # MSE and r squared values\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_pred),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_pred),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_pred),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_pred),4))\n",
    "    \n",
    "    \n",
    "    # Scatterplot of predicted vs. actual values\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    fig.suptitle('Predicted vs. actual values', fontsize=14, y=1)\n",
    "    plt.subplots_adjust(top=0.93, wspace=0)\n",
    "    \n",
    "    ax1.scatter(y_test, y_test_pred, s=2, alpha=0.7)\n",
    "    ax1.plot(list(range(2,8)), list(range(2,8)), color='black', linestyle='--')\n",
    "    ax1.set_title('Test set')\n",
    "    ax1.set_xlabel('Actual values')\n",
    "    ax1.set_ylabel('Predicted values')\n",
    "    \n",
    "    ax2.scatter(y_train, y_train_pred, s=2, alpha=0.7)\n",
    "    ax2.plot(list(range(2,8)), list(range(2,8)), color='black', linestyle='--')\n",
    "    ax2.set_title('Train set')\n",
    "    ax2.set_xlabel('Actual values')\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_yticklabels(labels='')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mae', 'mse'])\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_evaluation(model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
