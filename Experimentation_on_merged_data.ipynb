{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Po</th>\n",
       "      <th>At</th>\n",
       "      <th>Rn</th>\n",
       "      <th>material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ba0.2La1.8Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ba0.1La1.9Ag0.1Cu0.9O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ba0.1La1.9Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ba0.15La1.85Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ba0.3La1.7Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21258</th>\n",
       "      <td>4</td>\n",
       "      <td>106.957877</td>\n",
       "      <td>53.095769</td>\n",
       "      <td>82.515384</td>\n",
       "      <td>43.135565</td>\n",
       "      <td>1.177145</td>\n",
       "      <td>1.254119</td>\n",
       "      <td>146.88130</td>\n",
       "      <td>15.504479</td>\n",
       "      <td>65.764081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tm0.84Lu0.16Fe3Si5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21259</th>\n",
       "      <td>5</td>\n",
       "      <td>92.266740</td>\n",
       "      <td>49.021367</td>\n",
       "      <td>64.812662</td>\n",
       "      <td>32.867748</td>\n",
       "      <td>1.323287</td>\n",
       "      <td>1.571630</td>\n",
       "      <td>188.38390</td>\n",
       "      <td>7.353333</td>\n",
       "      <td>69.232655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tl1Ba2Ca3Cu4O11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>95.609104</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>95.464320</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>53.041104</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nb0.8Pd0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21261</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>97.095602</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>96.901083</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>31.115202</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nb0.69Pd0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21262</th>\n",
       "      <td>3</td>\n",
       "      <td>87.468333</td>\n",
       "      <td>86.858500</td>\n",
       "      <td>82.555758</td>\n",
       "      <td>80.458722</td>\n",
       "      <td>1.041270</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>71.75500</td>\n",
       "      <td>43.144000</td>\n",
       "      <td>29.905282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fe1Se0.2Te0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21263 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                       4         88.944468             57.862692   \n",
       "1                       5         92.729214             58.518416   \n",
       "2                       4         88.944468             57.885242   \n",
       "3                       4         88.944468             57.873967   \n",
       "4                       4         88.944468             57.840143   \n",
       "...                   ...               ...                   ...   \n",
       "21258                   4        106.957877             53.095769   \n",
       "21259                   5         92.266740             49.021367   \n",
       "21260                   2         99.663190             95.609104   \n",
       "21261                   2         99.663190             97.095602   \n",
       "21262                   3         87.468333             86.858500   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0              66.361592              36.116612             1.181795   \n",
       "1              73.132787              36.396602             1.449309   \n",
       "2              66.361592              36.122509             1.181795   \n",
       "3              66.361592              36.119560             1.181795   \n",
       "4              66.361592              36.110716             1.181795   \n",
       "...                  ...                    ...                  ...   \n",
       "21258          82.515384              43.135565             1.177145   \n",
       "21259          64.812662              32.867748             1.323287   \n",
       "21260          99.433882              95.464320             0.690847   \n",
       "21261          99.433882              96.901083             0.690847   \n",
       "21262          82.555758              80.458722             1.041270   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                     1.062396          122.90607              31.794921   \n",
       "1                     1.057755          122.90607              36.161939   \n",
       "2                     0.975980          122.90607              35.741099   \n",
       "3                     1.022291          122.90607              33.768010   \n",
       "4                     1.129224          122.90607              27.848743   \n",
       "...                        ...                ...                    ...   \n",
       "21258                 1.254119          146.88130              15.504479   \n",
       "21259                 1.571630          188.38390               7.353333   \n",
       "21260                 0.530198           13.51362              53.041104   \n",
       "21261                 0.640883           13.51362              31.115202   \n",
       "21262                 0.895229           71.75500              43.144000   \n",
       "\n",
       "       std_atomic_mass  ...   Pt   Au   Hg   Tl   Pb   Bi  Po  At  Rn  \\\n",
       "0            51.968828  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "1            47.094633  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "2            51.968828  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "3            51.968828  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "4            51.968828  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "...                ...  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..   \n",
       "21258        65.764081  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "21259        69.232655  ...  0.0  0.0  0.0  1.0  0.0  0.0   0   0   0   \n",
       "21260         6.756810  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "21261         6.756810  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "21262        29.905282  ...  0.0  0.0  0.0  0.0  0.0  0.0   0   0   0   \n",
       "\n",
       "                     material  \n",
       "0             Ba0.2La1.8Cu1O4  \n",
       "1      Ba0.1La1.9Ag0.1Cu0.9O4  \n",
       "2             Ba0.1La1.9Cu1O4  \n",
       "3           Ba0.15La1.85Cu1O4  \n",
       "4             Ba0.3La1.7Cu1O4  \n",
       "...                       ...  \n",
       "21258      Tm0.84Lu0.16Fe3Si5  \n",
       "21259         Tl1Ba2Ca3Cu4O11  \n",
       "21260              Nb0.8Pd0.2  \n",
       "21261            Nb0.69Pd0.31  \n",
       "21262           Fe1Se0.2Te0.8  \n",
       "\n",
       "[21263 rows x 169 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in df.columns]\n",
    "# cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['critical_temp', 'material'], axis=1)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.critical_temp.values.reshape(-1,1)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training R^2 Scores: 76.42%\n",
      "Testing R^2 Scores:  76.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "r2_training = model_linear.score(X_train,y_train)\n",
    "r2_testing = model_linear.score(X_test, y_test)\n",
    "\n",
    "print(f'''\n",
    "Training R^2 Scores: {round(100*r2_training,2)}%\n",
    "Testing R^2 Scores:  {round(100*r2_testing,2)}%\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9254150975686546"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "regressor = XGBRegressor()\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# xgb1 = XGBRegressor()\n",
    "# parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "#               'objective':['reg:linear'],\n",
    "#               'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "#               'max_depth': [5, 6, 7],\n",
    "#               'min_child_weight': [4],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7],\n",
    "#               'n_estimators': [500]}\n",
    "\n",
    "# xgb_grid = GridSearchCV(regressor,\n",
    "#                         parameters,\n",
    "#                         cv = 2,\n",
    "#                         n_jobs = 5,\n",
    "#                         verbose=True)\n",
    "\n",
    "# xgb_grid.fit(X_train,\n",
    "#          y_train)\n",
    "# print('---------------------------------------------------------------------')\n",
    "# print(xgb_grid.best_score_)\n",
    "# print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Linear Regression Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               21504     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 17,765,633\n",
      "Trainable params: 17,765,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "epochs = 100\n",
    "# def make_model(epochs = 2000):\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mae', 'mse'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=512,\n",
    "#     validation_split=0.1,\n",
    "# )\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17010 samples, validate on 4253 samples\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 214.5420 - mae: 9.5722 - mse: 214.5420 - val_loss: 204.3848 - val_mae: 9.5226 - val_mse: 204.3848\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1, batch_size=512, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning_model_evaluation(model, skip_epochs=0, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    \n",
    "    from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "\n",
    "    # MSE and r squared values\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_pred),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_pred),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_pred),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_pred),4))\n",
    "    \n",
    "\n",
    "    # Scatterplot of predicted vs. actual values\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    fig.suptitle('Predicted vs. actual values', fontsize=14, y=1)\n",
    "    plt.subplots_adjust(top=0.93, wspace=0)\n",
    "    \n",
    "    ax1.scatter(y_test, y_test_pred, s=2, alpha=0.7)\n",
    "    ax1.set_title('Test set')\n",
    "    ax1.set_xlabel('Actual values')\n",
    "    ax1.set_ylabel('Predicted values')\n",
    "    \n",
    "    ax2.scatter(y_train, y_train_pred, s=2, alpha=0.7)\n",
    "    ax2.set_title('Train set')\n",
    "    ax2.set_xlabel('Actual values')\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_yticklabels(labels='')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17010 samples, validate on 4253 samples\n",
      "Epoch 1/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 186.1476 - mae: 8.8550 - mse: 186.1476 - val_loss: 185.2961 - val_mae: 8.9666 - val_mse: 185.2961\n",
      "Epoch 2/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 187.3511 - mae: 8.8064 - mse: 187.3511 - val_loss: 191.8953 - val_mae: 9.1120 - val_mse: 191.8953\n",
      "Epoch 3/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 188.6298 - mae: 8.7968 - mse: 188.6299 - val_loss: 198.9521 - val_mae: 9.4655 - val_mse: 198.9521\n",
      "Epoch 4/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 178.6825 - mae: 8.5749 - mse: 178.6825 - val_loss: 189.6585 - val_mae: 8.7113 - val_mse: 189.6585\n",
      "Epoch 5/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 198.5035 - mae: 9.0522 - mse: 198.5035 - val_loss: 237.1358 - val_mae: 10.2127 - val_mse: 237.1358\n",
      "Epoch 6/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 188.6625 - mae: 8.8284 - mse: 188.6625 - val_loss: 242.3501 - val_mae: 10.4195 - val_mse: 242.3501\n",
      "Epoch 7/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 194.9378 - mae: 9.0018 - mse: 194.9379 - val_loss: 190.3042 - val_mae: 9.1228 - val_mse: 190.3042\n",
      "Epoch 8/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 178.8579 - mae: 8.6541 - mse: 178.8579 - val_loss: 202.2802 - val_mae: 8.9803 - val_mse: 202.2802\n",
      "Epoch 9/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 199.9595 - mae: 9.1490 - mse: 199.9595 - val_loss: 178.3501 - val_mae: 8.8845 - val_mse: 178.3501\n",
      "Epoch 10/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 177.1441 - mae: 8.5860 - mse: 177.1441 - val_loss: 191.4570 - val_mae: 9.2768 - val_mse: 191.4570\n",
      "Epoch 11/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 181.0368 - mae: 8.6639 - mse: 181.0368 - val_loss: 176.7477 - val_mae: 8.4973 - val_mse: 176.7477\n",
      "Epoch 12/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 176.6016 - mae: 8.5337 - mse: 176.6016 - val_loss: 229.8445 - val_mae: 10.1444 - val_mse: 229.8445\n",
      "Epoch 13/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 192.2685 - mae: 8.8790 - mse: 192.2685 - val_loss: 212.7240 - val_mae: 9.4452 - val_mse: 212.7240\n",
      "Epoch 14/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 175.2464 - mae: 8.5167 - mse: 175.2464 - val_loss: 176.4524 - val_mae: 8.4212 - val_mse: 176.4524\n",
      "Epoch 15/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 176.7055 - mae: 8.4978 - mse: 176.7055 - val_loss: 206.3882 - val_mae: 9.3594 - val_mse: 206.3882\n",
      "Epoch 16/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 191.8768 - mae: 8.9694 - mse: 191.8768 - val_loss: 222.2081 - val_mae: 9.1237 - val_mse: 222.2081\n",
      "Epoch 17/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 193.3841 - mae: 8.8866 - mse: 193.3841 - val_loss: 195.9016 - val_mae: 8.6674 - val_mse: 195.9016\n",
      "Epoch 18/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 173.0947 - mae: 8.3531 - mse: 173.0947 - val_loss: 187.0331 - val_mae: 8.9608 - val_mse: 187.0331\n",
      "Epoch 19/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 179.9315 - mae: 8.6604 - mse: 179.9315 - val_loss: 173.6242 - val_mae: 8.4533 - val_mse: 173.6242\n",
      "Epoch 20/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 168.9426 - mae: 8.3111 - mse: 168.9426 - val_loss: 173.4076 - val_mae: 8.4482 - val_mse: 173.4077\n",
      "Epoch 21/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 186.4150 - mae: 8.7156 - mse: 186.4150 - val_loss: 194.0525 - val_mae: 8.8524 - val_mse: 194.0525\n",
      "Epoch 22/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 176.7075 - mae: 8.4760 - mse: 176.7075 - val_loss: 202.8113 - val_mae: 9.0997 - val_mse: 202.8113\n",
      "Epoch 23/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 181.6022 - mae: 8.6588 - mse: 181.6023 - val_loss: 205.2600 - val_mae: 9.1279 - val_mse: 205.2600\n",
      "Epoch 24/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 166.9241 - mae: 8.2271 - mse: 166.9242 - val_loss: 170.6938 - val_mae: 8.1640 - val_mse: 170.6938\n",
      "Epoch 25/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 159.6376 - mae: 8.0443 - mse: 159.6376 - val_loss: 205.4143 - val_mae: 9.3310 - val_mse: 205.4143\n",
      "Epoch 26/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 162.2323 - mae: 8.0725 - mse: 162.2323 - val_loss: 172.7359 - val_mae: 8.2599 - val_mse: 172.7359\n",
      "Epoch 27/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 172.0534 - mae: 8.3420 - mse: 172.0534 - val_loss: 174.5217 - val_mae: 8.2450 - val_mse: 174.5217\n",
      "Epoch 28/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 164.5526 - mae: 8.1175 - mse: 164.5526 - val_loss: 226.0019 - val_mae: 10.0710 - val_mse: 226.0019\n",
      "Epoch 29/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 189.3763 - mae: 8.8825 - mse: 189.3763 - val_loss: 195.7274 - val_mae: 9.3269 - val_mse: 195.7274\n",
      "Epoch 30/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 177.9948 - mae: 8.6410 - mse: 177.9948 - val_loss: 188.8563 - val_mae: 8.9896 - val_mse: 188.8563\n",
      "Epoch 31/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 154.3131 - mae: 7.9316 - mse: 154.3131 - val_loss: 156.8924 - val_mae: 8.0085 - val_mse: 156.8924\n",
      "Epoch 32/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 172.6923 - mae: 8.4374 - mse: 172.6923 - val_loss: 200.8601 - val_mae: 9.5590 - val_mse: 200.8601\n",
      "Epoch 33/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 171.1876 - mae: 8.3733 - mse: 171.1876 - val_loss: 188.6639 - val_mae: 8.5292 - val_mse: 188.6638\n",
      "Epoch 34/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 162.9740 - mae: 8.1247 - mse: 162.9740 - val_loss: 174.4196 - val_mae: 8.7161 - val_mse: 174.4196\n",
      "Epoch 35/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 173.9411 - mae: 8.4360 - mse: 173.9411 - val_loss: 203.3587 - val_mae: 8.8195 - val_mse: 203.3587\n",
      "Epoch 36/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 162.1103 - mae: 8.1193 - mse: 162.1103 - val_loss: 187.5160 - val_mae: 9.0833 - val_mse: 187.5161\n",
      "Epoch 37/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 188.3744 - mae: 8.7476 - mse: 188.3744 - val_loss: 192.4218 - val_mae: 8.9939 - val_mse: 192.4218\n",
      "Epoch 38/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 165.0915 - mae: 8.1412 - mse: 165.0915 - val_loss: 164.7087 - val_mae: 8.0350 - val_mse: 164.7087\n",
      "Epoch 39/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 164.8630 - mae: 8.1752 - mse: 164.8630 - val_loss: 163.0646 - val_mae: 8.0829 - val_mse: 163.0646\n",
      "Epoch 40/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 163.7342 - mae: 8.1390 - mse: 163.7341 - val_loss: 181.6482 - val_mae: 8.6898 - val_mse: 181.6482\n",
      "Epoch 41/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 183.6334 - mae: 8.5544 - mse: 183.6334 - val_loss: 218.6108 - val_mae: 9.8938 - val_mse: 218.6108\n",
      "Epoch 42/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 164.4072 - mae: 8.1836 - mse: 164.4072 - val_loss: 165.4037 - val_mae: 8.2297 - val_mse: 165.4037\n",
      "Epoch 43/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 148.3090 - mae: 7.6676 - mse: 148.3090 - val_loss: 196.4875 - val_mae: 9.1344 - val_mse: 196.4875\n",
      "Epoch 44/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 172.7541 - mae: 8.4007 - mse: 172.7541 - val_loss: 181.0253 - val_mae: 8.2829 - val_mse: 181.0253\n",
      "Epoch 45/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 150.1349 - mae: 7.7609 - mse: 150.1349 - val_loss: 156.3662 - val_mae: 7.8900 - val_mse: 156.3662\n",
      "Epoch 46/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 155.9973 - mae: 7.9190 - mse: 155.9973 - val_loss: 164.6687 - val_mae: 8.0193 - val_mse: 164.6687\n",
      "Epoch 47/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 155.7141 - mae: 7.8962 - mse: 155.7141 - val_loss: 161.1424 - val_mae: 8.2176 - val_mse: 161.1423\n",
      "Epoch 48/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 165.9437 - mae: 8.1183 - mse: 165.9437 - val_loss: 277.9047 - val_mae: 10.4566 - val_mse: 277.9047\n",
      "Epoch 49/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 176.2635 - mae: 8.4254 - mse: 176.2634 - val_loss: 179.4756 - val_mae: 8.8244 - val_mse: 179.4756\n",
      "Epoch 50/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 142.4079 - mae: 7.5507 - mse: 142.4079 - val_loss: 196.9164 - val_mae: 8.4567 - val_mse: 196.9164\n",
      "Epoch 51/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 165.5230 - mae: 8.1665 - mse: 165.5230 - val_loss: 226.6772 - val_mae: 9.7960 - val_mse: 226.6772\n",
      "Epoch 52/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 173.3691 - mae: 8.4196 - mse: 173.3692 - val_loss: 169.4377 - val_mae: 8.1349 - val_mse: 169.4377\n",
      "Epoch 53/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 148.9576 - mae: 7.7319 - mse: 148.9576 - val_loss: 166.3145 - val_mae: 8.4641 - val_mse: 166.3145\n",
      "Epoch 54/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 160.3455 - mae: 8.0068 - mse: 160.3454 - val_loss: 172.8739 - val_mae: 8.4991 - val_mse: 172.8739\n",
      "Epoch 55/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 149.3912 - mae: 7.7632 - mse: 149.3911 - val_loss: 172.5915 - val_mae: 8.2203 - val_mse: 172.5915\n",
      "Epoch 56/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 157.7499 - mae: 8.0081 - mse: 157.7499 - val_loss: 183.4269 - val_mae: 8.8366 - val_mse: 183.4269\n",
      "Epoch 57/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 152.2591 - mae: 7.8664 - mse: 152.2590 - val_loss: 171.5323 - val_mae: 8.4339 - val_mse: 171.5323\n",
      "Epoch 58/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 150.1593 - mae: 7.8473 - mse: 150.1593 - val_loss: 175.8029 - val_mae: 8.6294 - val_mse: 175.8029\n",
      "Epoch 59/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 155.6341 - mae: 7.9488 - mse: 155.6341 - val_loss: 185.6521 - val_mae: 8.3919 - val_mse: 185.6521\n",
      "Epoch 60/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 151.9221 - mae: 7.7303 - mse: 151.9221 - val_loss: 168.7840 - val_mae: 8.3303 - val_mse: 168.7840\n",
      "Epoch 61/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 170.6740 - mae: 8.2663 - mse: 170.6740 - val_loss: 184.1547 - val_mae: 8.4079 - val_mse: 184.1547\n",
      "Epoch 62/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 171.1888 - mae: 8.3683 - mse: 171.1888 - val_loss: 200.3071 - val_mae: 9.3260 - val_mse: 200.3071\n",
      "Epoch 63/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 163.8407 - mae: 8.1343 - mse: 163.8407 - val_loss: 195.2347 - val_mae: 9.1186 - val_mse: 195.2347\n",
      "Epoch 64/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 137.8839 - mae: 7.4059 - mse: 137.8839 - val_loss: 171.7241 - val_mae: 8.0501 - val_mse: 171.7240\n",
      "Epoch 65/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 167.3837 - mae: 8.2114 - mse: 167.3837 - val_loss: 214.8122 - val_mae: 9.2954 - val_mse: 214.8122\n",
      "Epoch 66/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 170.5975 - mae: 8.3554 - mse: 170.5975 - val_loss: 191.2902 - val_mae: 8.9826 - val_mse: 191.2902\n",
      "Epoch 67/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 167.5379 - mae: 8.1552 - mse: 167.5379 - val_loss: 166.6940 - val_mae: 8.5098 - val_mse: 166.6940\n",
      "Epoch 68/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 148.4318 - mae: 7.6715 - mse: 148.4317 - val_loss: 183.4725 - val_mae: 8.7522 - val_mse: 183.4724\n",
      "Epoch 69/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 141.2155 - mae: 7.4718 - mse: 141.2155 - val_loss: 187.7583 - val_mae: 8.2966 - val_mse: 187.7583\n",
      "Epoch 70/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 144.9792 - mae: 7.5724 - mse: 144.9791 - val_loss: 170.6052 - val_mae: 8.2855 - val_mse: 170.6052\n",
      "Epoch 71/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 146.8740 - mae: 7.5813 - mse: 146.8741 - val_loss: 188.8900 - val_mae: 8.5491 - val_mse: 188.8900\n",
      "Epoch 72/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 139.1579 - mae: 7.4534 - mse: 139.1579 - val_loss: 160.5007 - val_mae: 8.2372 - val_mse: 160.5007\n",
      "Epoch 73/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 143.6164 - mae: 7.5129 - mse: 143.6164 - val_loss: 187.4843 - val_mae: 8.7721 - val_mse: 187.4843\n",
      "Epoch 74/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 149.4597 - mae: 7.6068 - mse: 149.4597 - val_loss: 159.9713 - val_mae: 7.6155 - val_mse: 159.9713\n",
      "Epoch 75/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 130.0595 - mae: 7.1742 - mse: 130.0595 - val_loss: 165.4693 - val_mae: 7.8439 - val_mse: 165.4693\n",
      "Epoch 76/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 129.3148 - mae: 7.0872 - mse: 129.3148 - val_loss: 199.8432 - val_mae: 9.0565 - val_mse: 199.8432\n",
      "Epoch 77/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 130.7091 - mae: 7.0992 - mse: 130.7091 - val_loss: 243.6682 - val_mae: 9.7554 - val_mse: 243.6682\n",
      "Epoch 78/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 191.6677 - mae: 8.8137 - mse: 191.6676 - val_loss: 186.0192 - val_mae: 9.0750 - val_mse: 186.0192\n",
      "Epoch 79/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 161.4264 - mae: 8.1167 - mse: 161.4264 - val_loss: 178.8723 - val_mae: 8.6337 - val_mse: 178.8723\n",
      "Epoch 80/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 145.2799 - mae: 7.5686 - mse: 145.2800 - val_loss: 151.7304 - val_mae: 7.8153 - val_mse: 151.7304\n",
      "Epoch 81/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 131.5633 - mae: 7.2108 - mse: 131.5633 - val_loss: 160.6868 - val_mae: 7.6975 - val_mse: 160.6868\n",
      "Epoch 82/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 141.7717 - mae: 7.4433 - mse: 141.7717 - val_loss: 167.6402 - val_mae: 8.2275 - val_mse: 167.6402\n",
      "Epoch 83/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 145.3293 - mae: 7.6125 - mse: 145.3293 - val_loss: 166.9359 - val_mae: 8.0851 - val_mse: 166.9359\n",
      "Epoch 84/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 147.7107 - mae: 7.5331 - mse: 147.7107 - val_loss: 181.4626 - val_mae: 8.4277 - val_mse: 181.4626\n",
      "Epoch 85/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 144.2882 - mae: 7.5263 - mse: 144.2883 - val_loss: 166.9186 - val_mae: 8.0678 - val_mse: 166.9186\n",
      "Epoch 86/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 133.1871 - mae: 7.2144 - mse: 133.1871 - val_loss: 158.3680 - val_mae: 7.8615 - val_mse: 158.3680\n",
      "Epoch 87/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.1013 - mae: 6.9522 - mse: 125.1012 - val_loss: 212.0038 - val_mae: 9.0391 - val_mse: 212.0038\n",
      "Epoch 88/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 156.9101 - mae: 7.8706 - mse: 156.9101 - val_loss: 168.6135 - val_mae: 8.1922 - val_mse: 168.6135\n",
      "Epoch 89/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 143.5228 - mae: 7.4876 - mse: 143.5229 - val_loss: 225.5498 - val_mae: 8.9417 - val_mse: 225.5499\n",
      "Epoch 90/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 155.4375 - mae: 7.9187 - mse: 155.4375 - val_loss: 162.2894 - val_mae: 7.8088 - val_mse: 162.2894\n",
      "Epoch 91/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 129.9921 - mae: 7.1365 - mse: 129.9921 - val_loss: 202.3344 - val_mae: 9.0967 - val_mse: 202.3344\n",
      "Epoch 92/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 148.7461 - mae: 7.6939 - mse: 148.7461 - val_loss: 147.2045 - val_mae: 7.4126 - val_mse: 147.2045\n",
      "Epoch 93/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 123.8671 - mae: 6.9151 - mse: 123.8671 - val_loss: 179.9887 - val_mae: 8.4322 - val_mse: 179.9887\n",
      "Epoch 94/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.7439 - mae: 6.9794 - mse: 125.7440 - val_loss: 178.7571 - val_mae: 7.9943 - val_mse: 178.7571\n",
      "Epoch 95/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 141.6854 - mae: 7.4155 - mse: 141.6854 - val_loss: 162.6453 - val_mae: 8.0602 - val_mse: 162.6452\n",
      "Epoch 96/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.4743 - mae: 6.9822 - mse: 125.4743 - val_loss: 180.8316 - val_mae: 8.3548 - val_mse: 180.8316\n",
      "Epoch 97/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 148.9664 - mae: 7.6458 - mse: 148.9663 - val_loss: 155.5760 - val_mae: 8.1668 - val_mse: 155.5760\n",
      "Epoch 98/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 145.9916 - mae: 7.6060 - mse: 145.9916 - val_loss: 204.4324 - val_mae: 9.4392 - val_mse: 204.4324\n",
      "Epoch 99/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 159.5660 - mae: 8.0547 - mse: 159.5660 - val_loss: 151.0763 - val_mae: 7.9397 - val_mse: 151.0763\n",
      "Epoch 100/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 127.8849 - mae: 7.1076 - mse: 127.8849 - val_loss: 183.4410 - val_mae: 8.5546 - val_mse: 183.4410\n",
      "Epoch 101/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 131.0511 - mae: 7.1606 - mse: 131.0511 - val_loss: 182.3067 - val_mae: 8.5960 - val_mse: 182.3067\n",
      "Epoch 102/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 159.8392 - mae: 7.9852 - mse: 159.8392 - val_loss: 155.4975 - val_mae: 7.8550 - val_mse: 155.4975\n",
      "Epoch 103/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 136.3013 - mae: 7.3616 - mse: 136.3013 - val_loss: 358.1181 - val_mae: 11.7789 - val_mse: 358.1181\n",
      "Epoch 104/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 189.9865 - mae: 8.7339 - mse: 189.9865 - val_loss: 166.2576 - val_mae: 8.2336 - val_mse: 166.2576\n",
      "Epoch 105/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 137.2142 - mae: 7.3790 - mse: 137.2142 - val_loss: 147.6133 - val_mae: 7.6557 - val_mse: 147.6133\n",
      "Epoch 106/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 133.0307 - mae: 7.1981 - mse: 133.0307 - val_loss: 153.5881 - val_mae: 7.6711 - val_mse: 153.5881\n",
      "Epoch 107/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 132.1213 - mae: 7.1763 - mse: 132.1213 - val_loss: 159.2242 - val_mae: 7.8996 - val_mse: 159.2242\n",
      "Epoch 108/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 130.8198 - mae: 7.1781 - mse: 130.8199 - val_loss: 146.0654 - val_mae: 7.6860 - val_mse: 146.0654\n",
      "Epoch 109/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 127.0423 - mae: 7.0110 - mse: 127.0423 - val_loss: 220.4892 - val_mae: 9.6243 - val_mse: 220.4892\n",
      "Epoch 110/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 137.3769 - mae: 7.3377 - mse: 137.3769 - val_loss: 156.2374 - val_mae: 8.0928 - val_mse: 156.2374\n",
      "Epoch 111/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 136.7969 - mae: 7.2671 - mse: 136.7969 - val_loss: 173.2672 - val_mae: 8.4544 - val_mse: 173.2672\n",
      "Epoch 112/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 133.8969 - mae: 7.1947 - mse: 133.8969 - val_loss: 146.3258 - val_mae: 7.5451 - val_mse: 146.3258\n",
      "Epoch 113/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 141.6796 - mae: 7.4640 - mse: 141.6796 - val_loss: 172.4691 - val_mae: 8.4140 - val_mse: 172.4691\n",
      "Epoch 114/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 136.2954 - mae: 7.3699 - mse: 136.2954 - val_loss: 154.3380 - val_mae: 8.0397 - val_mse: 154.3380\n",
      "Epoch 115/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 141.1704 - mae: 7.4348 - mse: 141.1703 - val_loss: 151.0806 - val_mae: 7.6186 - val_mse: 151.0806\n",
      "Epoch 116/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 119.1527 - mae: 6.7753 - mse: 119.1527 - val_loss: 147.0513 - val_mae: 7.8097 - val_mse: 147.0513\n",
      "Epoch 117/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 130.8099 - mae: 7.1520 - mse: 130.8099 - val_loss: 156.8313 - val_mae: 7.8720 - val_mse: 156.8313\n",
      "Epoch 118/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 129.6400 - mae: 7.0772 - mse: 129.6400 - val_loss: 154.1007 - val_mae: 7.5431 - val_mse: 154.1007\n",
      "Epoch 119/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 131.5423 - mae: 7.1336 - mse: 131.5423 - val_loss: 239.1655 - val_mae: 9.4106 - val_mse: 239.1655\n",
      "Epoch 120/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 162.5807 - mae: 8.0197 - mse: 162.5807 - val_loss: 223.5107 - val_mae: 9.1214 - val_mse: 223.5107\n",
      "Epoch 121/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 144.7247 - mae: 7.5729 - mse: 144.7248 - val_loss: 158.7221 - val_mae: 7.7632 - val_mse: 158.7221\n",
      "Epoch 122/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 120.5489 - mae: 6.8356 - mse: 120.5489 - val_loss: 185.2536 - val_mae: 8.1529 - val_mse: 185.2536\n",
      "Epoch 123/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 157.5023 - mae: 7.8886 - mse: 157.5023 - val_loss: 145.8493 - val_mae: 7.7630 - val_mse: 145.8493\n",
      "Epoch 124/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 126.1417 - mae: 6.9718 - mse: 126.1417 - val_loss: 175.2290 - val_mae: 8.3976 - val_mse: 175.2290\n",
      "Epoch 125/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.9144 - mae: 6.9490 - mse: 125.9144 - val_loss: 158.7574 - val_mae: 7.9341 - val_mse: 158.7574\n",
      "Epoch 126/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 135.8453 - mae: 7.2111 - mse: 135.8453 - val_loss: 148.3587 - val_mae: 7.6828 - val_mse: 148.3587\n",
      "Epoch 127/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 148.6933 - mae: 7.6713 - mse: 148.6933 - val_loss: 147.0016 - val_mae: 7.6337 - val_mse: 147.0016\n",
      "Epoch 128/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 126.5079 - mae: 7.0029 - mse: 126.5079 - val_loss: 199.8838 - val_mae: 8.5210 - val_mse: 199.8838\n",
      "Epoch 129/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 141.8306 - mae: 7.4036 - mse: 141.8306 - val_loss: 148.5631 - val_mae: 7.6733 - val_mse: 148.5631\n",
      "Epoch 130/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 137.0668 - mae: 7.3558 - mse: 137.0668 - val_loss: 150.1975 - val_mae: 7.5159 - val_mse: 150.1975\n",
      "Epoch 131/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 127.3348 - mae: 7.0343 - mse: 127.3348 - val_loss: 153.4453 - val_mae: 7.4281 - val_mse: 153.4453\n",
      "Epoch 132/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 123.0174 - mae: 6.8514 - mse: 123.0174 - val_loss: 159.7138 - val_mae: 7.6124 - val_mse: 159.7139\n",
      "Epoch 133/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 120.9062 - mae: 6.8192 - mse: 120.9062 - val_loss: 148.7894 - val_mae: 7.9329 - val_mse: 148.7894\n",
      "Epoch 134/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 133.7533 - mae: 7.1249 - mse: 133.7534 - val_loss: 173.1245 - val_mae: 7.9639 - val_mse: 173.1245\n",
      "Epoch 135/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 129.0604 - mae: 7.0375 - mse: 129.0604 - val_loss: 157.1764 - val_mae: 7.8355 - val_mse: 157.1764\n",
      "Epoch 136/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.8967 - mae: 6.9807 - mse: 125.8967 - val_loss: 175.4704 - val_mae: 8.4857 - val_mse: 175.4704\n",
      "Epoch 137/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 127.3986 - mae: 6.9885 - mse: 127.3985 - val_loss: 171.3555 - val_mae: 7.9699 - val_mse: 171.3555\n",
      "Epoch 138/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 126.3893 - mae: 6.9170 - mse: 126.3892 - val_loss: 164.1403 - val_mae: 8.2363 - val_mse: 164.1403\n",
      "Epoch 139/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 116.0967 - mae: 6.6751 - mse: 116.0967 - val_loss: 169.0360 - val_mae: 7.7909 - val_mse: 169.0360\n",
      "Epoch 140/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 119.2893 - mae: 6.7215 - mse: 119.2893 - val_loss: 164.3766 - val_mae: 8.2329 - val_mse: 164.3766\n",
      "Epoch 141/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 133.9409 - mae: 7.1514 - mse: 133.9409 - val_loss: 184.6420 - val_mae: 9.0088 - val_mse: 184.6420\n",
      "Epoch 142/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 119.5112 - mae: 6.7801 - mse: 119.5111 - val_loss: 160.9310 - val_mae: 8.1592 - val_mse: 160.9310\n",
      "Epoch 143/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 121.9318 - mae: 6.8023 - mse: 121.9318 - val_loss: 144.8750 - val_mae: 7.7232 - val_mse: 144.8750\n",
      "Epoch 144/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 122.2167 - mae: 6.8314 - mse: 122.2167 - val_loss: 152.3076 - val_mae: 7.8120 - val_mse: 152.3076\n",
      "Epoch 145/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.3619 - mae: 6.9505 - mse: 125.3619 - val_loss: 138.8097 - val_mae: 7.2657 - val_mse: 138.8097\n",
      "Epoch 146/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 119.7685 - mae: 6.7540 - mse: 119.7685 - val_loss: 147.0034 - val_mae: 7.5516 - val_mse: 147.0034\n",
      "Epoch 147/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 146.3925 - mae: 7.5346 - mse: 146.3925 - val_loss: 163.9709 - val_mae: 8.0121 - val_mse: 163.9709\n",
      "Epoch 148/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 148.5891 - mae: 7.6306 - mse: 148.5891 - val_loss: 146.7307 - val_mae: 7.6337 - val_mse: 146.7307\n",
      "Epoch 149/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 134.6549 - mae: 7.2426 - mse: 134.6549 - val_loss: 141.5995 - val_mae: 7.3773 - val_mse: 141.5995\n",
      "Epoch 150/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 117.1889 - mae: 6.7332 - mse: 117.1889 - val_loss: 148.4033 - val_mae: 7.6963 - val_mse: 148.4033\n",
      "Epoch 151/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 125.1590 - mae: 6.9750 - mse: 125.1590 - val_loss: 146.4826 - val_mae: 7.5452 - val_mse: 146.4826\n",
      "Epoch 152/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 110.7822 - mae: 6.5195 - mse: 110.7822 - val_loss: 229.4056 - val_mae: 9.4313 - val_mse: 229.4056\n",
      "Epoch 153/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 118.5433 - mae: 6.7472 - mse: 118.5433 - val_loss: 143.4577 - val_mae: 7.4187 - val_mse: 143.4577\n",
      "Epoch 154/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 117.6487 - mae: 6.6730 - mse: 117.6488 - val_loss: 151.9084 - val_mae: 7.8162 - val_mse: 151.9084\n",
      "Epoch 155/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 128.8360 - mae: 7.0538 - mse: 128.8360 - val_loss: 191.4849 - val_mae: 8.2600 - val_mse: 191.4850\n",
      "Epoch 156/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 138.4797 - mae: 7.2817 - mse: 138.4797 - val_loss: 145.0674 - val_mae: 7.5727 - val_mse: 145.0674\n",
      "Epoch 157/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 120.7775 - mae: 6.8288 - mse: 120.7775 - val_loss: 148.4189 - val_mae: 7.5823 - val_mse: 148.4189\n",
      "Epoch 158/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 123.9594 - mae: 6.9237 - mse: 123.9594 - val_loss: 167.0171 - val_mae: 7.8458 - val_mse: 167.0171\n",
      "Epoch 159/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 115.2402 - mae: 6.6324 - mse: 115.2402 - val_loss: 143.8725 - val_mae: 7.3897 - val_mse: 143.8725\n",
      "Epoch 160/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 119.7915 - mae: 6.6707 - mse: 119.7915 - val_loss: 152.4365 - val_mae: 7.9201 - val_mse: 152.4365\n",
      "Epoch 161/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 126.5156 - mae: 6.9022 - mse: 126.5156 - val_loss: 157.4230 - val_mae: 7.9189 - val_mse: 157.4230\n",
      "Epoch 162/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 115.9544 - mae: 6.6682 - mse: 115.9544 - val_loss: 135.6748 - val_mae: 7.2511 - val_mse: 135.6748\n",
      "Epoch 163/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 114.7349 - mae: 6.6118 - mse: 114.7349 - val_loss: 159.4840 - val_mae: 7.8671 - val_mse: 159.4840\n",
      "Epoch 164/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 113.1226 - mae: 6.5939 - mse: 113.1226 - val_loss: 129.5220 - val_mae: 6.9873 - val_mse: 129.5220\n",
      "Epoch 165/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 115.6383 - mae: 6.6307 - mse: 115.6383 - val_loss: 147.2168 - val_mae: 7.6652 - val_mse: 147.2168\n",
      "Epoch 166/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 124.2832 - mae: 6.8972 - mse: 124.2832 - val_loss: 213.3349 - val_mae: 9.6278 - val_mse: 213.3349\n",
      "Epoch 167/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 123.8680 - mae: 6.8478 - mse: 123.8680 - val_loss: 143.2862 - val_mae: 7.2453 - val_mse: 143.2862\n",
      "Epoch 168/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 112.9010 - mae: 6.5285 - mse: 112.9009 - val_loss: 130.6185 - val_mae: 7.0402 - val_mse: 130.6185\n",
      "Epoch 169/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 113.2237 - mae: 6.4897 - mse: 113.2236 - val_loss: 136.0533 - val_mae: 7.2102 - val_mse: 136.0533\n",
      "Epoch 170/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 113.6987 - mae: 6.5821 - mse: 113.6987 - val_loss: 218.2992 - val_mae: 8.8406 - val_mse: 218.2992\n",
      "Epoch 171/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 124.6405 - mae: 6.8952 - mse: 124.6405 - val_loss: 215.9900 - val_mae: 8.9791 - val_mse: 215.9900\n",
      "Epoch 172/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 148.7295 - mae: 7.6213 - mse: 148.7295 - val_loss: 195.9139 - val_mae: 8.5985 - val_mse: 195.9140\n",
      "Epoch 173/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 133.1528 - mae: 7.2069 - mse: 133.1528 - val_loss: 165.2777 - val_mae: 8.1968 - val_mse: 165.2777\n",
      "Epoch 174/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 133.3542 - mae: 7.2099 - mse: 133.3542 - val_loss: 163.2690 - val_mae: 7.6822 - val_mse: 163.2690\n",
      "Epoch 175/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 109.8375 - mae: 6.4935 - mse: 109.8375 - val_loss: 140.1692 - val_mae: 7.4560 - val_mse: 140.1692\n",
      "Epoch 176/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 141.5322 - mae: 7.3862 - mse: 141.5322 - val_loss: 197.6053 - val_mae: 8.8107 - val_mse: 197.6053\n",
      "Epoch 177/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 158.7789 - mae: 7.9831 - mse: 158.7789 - val_loss: 184.6246 - val_mae: 8.9689 - val_mse: 184.6246\n",
      "Epoch 178/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 127.3330 - mae: 7.0945 - mse: 127.3330 - val_loss: 142.2850 - val_mae: 7.3775 - val_mse: 142.2850\n",
      "Epoch 179/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 113.4544 - mae: 6.6435 - mse: 113.4544 - val_loss: 150.0964 - val_mae: 7.3946 - val_mse: 150.0964\n",
      "Epoch 180/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 108.5664 - mae: 6.4657 - mse: 108.5664 - val_loss: 179.7534 - val_mae: 7.9770 - val_mse: 179.7534\n",
      "Epoch 181/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 132.6273 - mae: 7.0690 - mse: 132.6273 - val_loss: 171.2990 - val_mae: 8.5130 - val_mse: 171.2990\n",
      "Epoch 182/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 124.8711 - mae: 6.9224 - mse: 124.8711 - val_loss: 187.2973 - val_mae: 8.8050 - val_mse: 187.2973\n",
      "Epoch 183/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 126.2809 - mae: 6.9027 - mse: 126.2809 - val_loss: 151.3705 - val_mae: 7.7418 - val_mse: 151.3705\n",
      "Epoch 184/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 114.0109 - mae: 6.5563 - mse: 114.0109 - val_loss: 145.9186 - val_mae: 7.8222 - val_mse: 145.9186\n",
      "Epoch 185/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 134.7205 - mae: 7.2083 - mse: 134.7205 - val_loss: 158.0956 - val_mae: 7.9937 - val_mse: 158.0955\n",
      "Epoch 186/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 124.3935 - mae: 6.8785 - mse: 124.3935 - val_loss: 150.7806 - val_mae: 7.8887 - val_mse: 150.7806\n",
      "Epoch 187/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 114.8469 - mae: 6.6150 - mse: 114.8469 - val_loss: 136.5557 - val_mae: 7.3447 - val_mse: 136.5557\n",
      "Epoch 188/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 100.8802 - mae: 6.1543 - mse: 100.8802 - val_loss: 138.3504 - val_mae: 7.0816 - val_mse: 138.3504\n",
      "Epoch 189/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 116.5839 - mae: 6.5944 - mse: 116.5839 - val_loss: 137.6528 - val_mae: 7.6282 - val_mse: 137.6528\n",
      "Epoch 190/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 135.6049 - mae: 7.2940 - mse: 135.6049 - val_loss: 153.9132 - val_mae: 7.8137 - val_mse: 153.9132\n",
      "Epoch 191/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 114.2377 - mae: 6.6151 - mse: 114.2377 - val_loss: 171.6788 - val_mae: 8.5817 - val_mse: 171.6788\n",
      "Epoch 192/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 116.1940 - mae: 6.7635 - mse: 116.1940 - val_loss: 143.0848 - val_mae: 7.3724 - val_mse: 143.0848\n",
      "Epoch 193/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 113.3531 - mae: 6.5423 - mse: 113.3531 - val_loss: 177.5313 - val_mae: 8.2961 - val_mse: 177.5313\n",
      "Epoch 194/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 118.2187 - mae: 6.6465 - mse: 118.2187 - val_loss: 142.2841 - val_mae: 7.3236 - val_mse: 142.2841\n",
      "Epoch 195/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 109.9787 - mae: 6.4502 - mse: 109.9787 - val_loss: 179.3165 - val_mae: 8.5214 - val_mse: 179.3166\n",
      "Epoch 196/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 124.6937 - mae: 6.8450 - mse: 124.6937 - val_loss: 171.3271 - val_mae: 8.2963 - val_mse: 171.3271\n",
      "Epoch 197/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 139.9932 - mae: 7.3049 - mse: 139.9932 - val_loss: 164.0213 - val_mae: 7.6710 - val_mse: 164.0213\n",
      "Epoch 198/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 124.4036 - mae: 6.9002 - mse: 124.4036 - val_loss: 135.0015 - val_mae: 7.2840 - val_mse: 135.0015\n",
      "Epoch 199/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 104.6908 - mae: 6.2915 - mse: 104.6908 - val_loss: 155.9220 - val_mae: 7.8035 - val_mse: 155.9220\n",
      "Epoch 200/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 125.2488 - mae: 6.9324 - mse: 125.2489 - val_loss: 174.2158 - val_mae: 8.0157 - val_mse: 174.2159\n",
      "Epoch 201/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 120.8145 - mae: 6.8045 - mse: 120.8145 - val_loss: 137.0326 - val_mae: 7.0415 - val_mse: 137.0326\n",
      "Epoch 202/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 104.8340 - mae: 6.2709 - mse: 104.8340 - val_loss: 127.9383 - val_mae: 7.1061 - val_mse: 127.9382\n",
      "Epoch 203/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 103.6815 - mae: 6.2471 - mse: 103.6815 - val_loss: 166.2705 - val_mae: 7.7327 - val_mse: 166.2705\n",
      "Epoch 204/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 115.5850 - mae: 6.5840 - mse: 115.5850 - val_loss: 141.0671 - val_mae: 7.0502 - val_mse: 141.0671\n",
      "Epoch 205/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 111.9748 - mae: 6.4872 - mse: 111.9748 - val_loss: 152.7000 - val_mae: 7.4357 - val_mse: 152.7000\n",
      "Epoch 206/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 114.7671 - mae: 6.5424 - mse: 114.7671 - val_loss: 139.2578 - val_mae: 7.1158 - val_mse: 139.2578\n",
      "Epoch 207/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 137.7812 - mae: 7.2912 - mse: 137.7812 - val_loss: 149.1840 - val_mae: 7.5766 - val_mse: 149.1840\n",
      "Epoch 208/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 116.0292 - mae: 6.7244 - mse: 116.0292 - val_loss: 168.7086 - val_mae: 8.2279 - val_mse: 168.7086\n",
      "Epoch 209/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 123.8431 - mae: 6.8239 - mse: 123.8431 - val_loss: 237.1995 - val_mae: 9.7180 - val_mse: 237.1995\n",
      "Epoch 210/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 133.4689 - mae: 7.2881 - mse: 133.4689 - val_loss: 152.2009 - val_mae: 7.8289 - val_mse: 152.2009\n",
      "Epoch 211/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 115.1143 - mae: 6.6372 - mse: 115.1143 - val_loss: 152.6148 - val_mae: 7.8631 - val_mse: 152.6148\n",
      "Epoch 212/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 118.1756 - mae: 6.7032 - mse: 118.1756 - val_loss: 169.0148 - val_mae: 7.8049 - val_mse: 169.0148\n",
      "Epoch 213/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 120.9127 - mae: 6.7006 - mse: 120.9127 - val_loss: 186.4365 - val_mae: 8.7815 - val_mse: 186.4365\n",
      "Epoch 214/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 127.9751 - mae: 7.0230 - mse: 127.9750 - val_loss: 141.1400 - val_mae: 7.4611 - val_mse: 141.1400\n",
      "Epoch 215/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 107.9494 - mae: 6.4470 - mse: 107.9494 - val_loss: 155.5234 - val_mae: 7.7069 - val_mse: 155.5234\n",
      "Epoch 216/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 124.2082 - mae: 6.9219 - mse: 124.2082 - val_loss: 183.9630 - val_mae: 8.1944 - val_mse: 183.9631\n",
      "Epoch 217/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 122.3578 - mae: 6.9099 - mse: 122.3578 - val_loss: 140.6767 - val_mae: 7.4352 - val_mse: 140.6767\n",
      "Epoch 218/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 107.1906 - mae: 6.3738 - mse: 107.1907 - val_loss: 125.2480 - val_mae: 6.8100 - val_mse: 125.2480\n",
      "Epoch 219/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 109.9751 - mae: 6.3567 - mse: 109.9751 - val_loss: 149.8188 - val_mae: 7.3318 - val_mse: 149.8188\n",
      "Epoch 220/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 126.7837 - mae: 6.9176 - mse: 126.7837 - val_loss: 166.5097 - val_mae: 7.7563 - val_mse: 166.5097\n",
      "Epoch 221/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 120.7757 - mae: 6.8238 - mse: 120.7757 - val_loss: 172.6019 - val_mae: 8.2951 - val_mse: 172.6019\n",
      "Epoch 222/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 119.7247 - mae: 6.8295 - mse: 119.7247 - val_loss: 151.1934 - val_mae: 7.6745 - val_mse: 151.1934\n",
      "Epoch 223/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 113.1458 - mae: 6.6098 - mse: 113.1458 - val_loss: 137.1328 - val_mae: 7.1382 - val_mse: 137.1328\n",
      "Epoch 224/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 116.8027 - mae: 6.6322 - mse: 116.8027 - val_loss: 167.4046 - val_mae: 8.0292 - val_mse: 167.4046\n",
      "Epoch 225/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 114.9027 - mae: 6.6997 - mse: 114.9027 - val_loss: 141.9422 - val_mae: 7.6308 - val_mse: 141.9422\n",
      "Epoch 226/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 111.1871 - mae: 6.5403 - mse: 111.1871 - val_loss: 154.8910 - val_mae: 7.7117 - val_mse: 154.8910\n",
      "Epoch 227/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 120.8904 - mae: 6.8205 - mse: 120.8904 - val_loss: 181.0171 - val_mae: 8.0653 - val_mse: 181.0171\n",
      "Epoch 228/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 154.0297 - mae: 7.8346 - mse: 154.0297 - val_loss: 145.7749 - val_mae: 7.3761 - val_mse: 145.7749\n",
      "Epoch 229/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 110.3400 - mae: 6.5384 - mse: 110.3400 - val_loss: 151.7528 - val_mae: 7.4445 - val_mse: 151.7528\n",
      "Epoch 230/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 102.2026 - mae: 6.2080 - mse: 102.2026 - val_loss: 143.7193 - val_mae: 7.1825 - val_mse: 143.7193\n",
      "Epoch 231/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 129.7660 - mae: 6.9532 - mse: 129.7660 - val_loss: 145.8803 - val_mae: 7.3626 - val_mse: 145.8803\n",
      "Epoch 232/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 111.8566 - mae: 6.4129 - mse: 111.8566 - val_loss: 135.4516 - val_mae: 7.1952 - val_mse: 135.4516\n",
      "Epoch 233/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 102.3624 - mae: 6.1666 - mse: 102.3624 - val_loss: 145.7510 - val_mae: 7.2642 - val_mse: 145.7510\n",
      "Epoch 234/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.3291 - mae: 6.1231 - mse: 99.3291 - val_loss: 141.7817 - val_mae: 7.0255 - val_mse: 141.7817\n",
      "Epoch 235/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 96.6316 - mae: 5.9833 - mse: 96.6316 - val_loss: 132.5086 - val_mae: 7.2263 - val_mse: 132.5086\n",
      "Epoch 236/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 129.4709 - mae: 6.9572 - mse: 129.4709 - val_loss: 149.4290 - val_mae: 7.3903 - val_mse: 149.4290\n",
      "Epoch 237/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 117.3772 - mae: 6.6752 - mse: 117.3772 - val_loss: 170.7932 - val_mae: 7.7530 - val_mse: 170.7932\n",
      "Epoch 238/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 111.6816 - mae: 6.5227 - mse: 111.6816 - val_loss: 157.0185 - val_mae: 7.8410 - val_mse: 157.0185\n",
      "Epoch 239/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 114.2818 - mae: 6.6238 - mse: 114.2818 - val_loss: 149.5391 - val_mae: 7.4066 - val_mse: 149.5391\n",
      "Epoch 240/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 111.1824 - mae: 6.4710 - mse: 111.1824 - val_loss: 154.6205 - val_mae: 8.0593 - val_mse: 154.6205\n",
      "Epoch 241/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 114.9392 - mae: 6.6392 - mse: 114.9392 - val_loss: 152.5244 - val_mae: 7.4592 - val_mse: 152.5244\n",
      "Epoch 242/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 109.0692 - mae: 6.5021 - mse: 109.0692 - val_loss: 166.9425 - val_mae: 8.2593 - val_mse: 166.9425\n",
      "Epoch 243/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.9793 - mae: 6.3537 - mse: 105.9793 - val_loss: 149.6333 - val_mae: 7.8384 - val_mse: 149.6333\n",
      "Epoch 244/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 103.9370 - mae: 6.2931 - mse: 103.9370 - val_loss: 182.8040 - val_mae: 8.3205 - val_mse: 182.8040\n",
      "Epoch 245/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 124.9147 - mae: 6.8971 - mse: 124.9147 - val_loss: 156.3681 - val_mae: 7.6574 - val_mse: 156.3681\n",
      "Epoch 246/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 112.6305 - mae: 6.5250 - mse: 112.6305 - val_loss: 162.0617 - val_mae: 7.7837 - val_mse: 162.0617\n",
      "Epoch 247/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 120.1012 - mae: 6.7954 - mse: 120.1011 - val_loss: 163.2544 - val_mae: 7.8254 - val_mse: 163.2544\n",
      "Epoch 248/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 116.5820 - mae: 6.7535 - mse: 116.5821 - val_loss: 145.4996 - val_mae: 7.7910 - val_mse: 145.4996\n",
      "Epoch 249/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.9354 - mae: 6.1834 - mse: 99.9354 - val_loss: 119.1483 - val_mae: 6.5707 - val_mse: 119.1483\n",
      "Epoch 250/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 110.9738 - mae: 6.3879 - mse: 110.9738 - val_loss: 161.3727 - val_mae: 8.1286 - val_mse: 161.3727\n",
      "Epoch 251/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 111.0929 - mae: 6.4488 - mse: 111.0929 - val_loss: 148.8025 - val_mae: 7.7496 - val_mse: 148.8025\n",
      "Epoch 252/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 112.7970 - mae: 6.4196 - mse: 112.7970 - val_loss: 151.9150 - val_mae: 7.8853 - val_mse: 151.9150\n",
      "Epoch 253/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 108.1319 - mae: 6.4029 - mse: 108.1319 - val_loss: 147.2287 - val_mae: 7.9509 - val_mse: 147.2287\n",
      "Epoch 254/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 107.2213 - mae: 6.3349 - mse: 107.2212 - val_loss: 139.0786 - val_mae: 6.9866 - val_mse: 139.0786\n",
      "Epoch 255/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.1483 - mae: 6.1562 - mse: 101.1483 - val_loss: 155.5720 - val_mae: 7.2905 - val_mse: 155.5720\n",
      "Epoch 256/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 102.2179 - mae: 6.1576 - mse: 102.2179 - val_loss: 132.5259 - val_mae: 7.1310 - val_mse: 132.5259\n",
      "Epoch 257/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 110.4059 - mae: 6.5174 - mse: 110.4059 - val_loss: 143.2749 - val_mae: 7.4310 - val_mse: 143.2749\n",
      "Epoch 258/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 100.0720 - mae: 6.2182 - mse: 100.0720 - val_loss: 157.1161 - val_mae: 7.9538 - val_mse: 157.1161\n",
      "Epoch 259/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 112.1318 - mae: 6.5245 - mse: 112.1319 - val_loss: 160.7904 - val_mae: 7.6684 - val_mse: 160.7904\n",
      "Epoch 260/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 118.1062 - mae: 6.7839 - mse: 118.1062 - val_loss: 135.6100 - val_mae: 6.9791 - val_mse: 135.6100\n",
      "Epoch 261/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.8643 - mae: 6.2024 - mse: 101.8643 - val_loss: 156.8382 - val_mae: 7.8716 - val_mse: 156.8382\n",
      "Epoch 262/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 124.8479 - mae: 6.9495 - mse: 124.8479 - val_loss: 149.5819 - val_mae: 7.8029 - val_mse: 149.5819\n",
      "Epoch 263/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 122.0329 - mae: 6.8547 - mse: 122.0329 - val_loss: 186.5961 - val_mae: 8.6916 - val_mse: 186.5961\n",
      "Epoch 264/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 107.1445 - mae: 6.3361 - mse: 107.1445 - val_loss: 138.5982 - val_mae: 7.4356 - val_mse: 138.5982\n",
      "Epoch 265/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 103.8849 - mae: 6.2134 - mse: 103.8849 - val_loss: 153.9861 - val_mae: 8.1614 - val_mse: 153.9861\n",
      "Epoch 266/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 107.5789 - mae: 6.3748 - mse: 107.5789 - val_loss: 224.1867 - val_mae: 8.8999 - val_mse: 224.1867\n",
      "Epoch 267/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 132.5007 - mae: 7.0567 - mse: 132.5007 - val_loss: 132.7639 - val_mae: 7.2647 - val_mse: 132.7639\n",
      "Epoch 268/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.7613 - mae: 6.1639 - mse: 101.7614 - val_loss: 147.1629 - val_mae: 7.3986 - val_mse: 147.1629\n",
      "Epoch 269/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 101.8850 - mae: 6.1397 - mse: 101.8850 - val_loss: 169.1017 - val_mae: 8.2502 - val_mse: 169.1017\n",
      "Epoch 270/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 108.9966 - mae: 6.4246 - mse: 108.9966 - val_loss: 141.4137 - val_mae: 7.3018 - val_mse: 141.4138\n",
      "Epoch 271/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.0561 - mae: 6.1775 - mse: 105.0561 - val_loss: 142.5634 - val_mae: 7.2915 - val_mse: 142.5634\n",
      "Epoch 272/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 95.5631 - mae: 5.9433 - mse: 95.5631 - val_loss: 140.2969 - val_mae: 7.2456 - val_mse: 140.2969\n",
      "Epoch 273/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 98.2295 - mae: 5.9719 - mse: 98.2295 - val_loss: 156.9506 - val_mae: 7.5118 - val_mse: 156.9506\n",
      "Epoch 274/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 104.4228 - mae: 6.1659 - mse: 104.4228 - val_loss: 149.2566 - val_mae: 7.3007 - val_mse: 149.2566\n",
      "Epoch 275/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 123.1912 - mae: 6.7523 - mse: 123.1912 - val_loss: 173.8717 - val_mae: 8.2634 - val_mse: 173.8717\n",
      "Epoch 276/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 108.0159 - mae: 6.4161 - mse: 108.0159 - val_loss: 145.7174 - val_mae: 7.2638 - val_mse: 145.7175\n",
      "Epoch 277/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 101.1710 - mae: 6.2675 - mse: 101.1710 - val_loss: 131.0511 - val_mae: 7.0088 - val_mse: 131.0511\n",
      "Epoch 278/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 96.3843 - mae: 5.9614 - mse: 96.3843 - val_loss: 145.1575 - val_mae: 7.5310 - val_mse: 145.1575\n",
      "Epoch 279/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.7507 - mae: 6.0676 - mse: 99.7507 - val_loss: 138.0982 - val_mae: 7.0685 - val_mse: 138.0982\n",
      "Epoch 280/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 101.4390 - mae: 6.1393 - mse: 101.4390 - val_loss: 126.6240 - val_mae: 6.9032 - val_mse: 126.6240\n",
      "Epoch 281/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 94.8038 - mae: 5.8617 - mse: 94.8038 - val_loss: 141.5097 - val_mae: 6.9783 - val_mse: 141.5097\n",
      "Epoch 282/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 100.6109 - mae: 6.0323 - mse: 100.6109 - val_loss: 156.7958 - val_mae: 7.4764 - val_mse: 156.7958\n",
      "Epoch 283/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 108.0894 - mae: 6.3684 - mse: 108.0894 - val_loss: 124.1920 - val_mae: 6.8496 - val_mse: 124.1920\n",
      "Epoch 284/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 88.9192 - mae: 5.6912 - mse: 88.9192 - val_loss: 115.5630 - val_mae: 6.4700 - val_mse: 115.5630\n",
      "Epoch 285/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.7032 - mae: 5.5362 - mse: 85.7032 - val_loss: 119.3628 - val_mae: 6.6751 - val_mse: 119.3628\n",
      "Epoch 286/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.3168 - mae: 5.8295 - mse: 93.3168 - val_loss: 178.3803 - val_mae: 8.0590 - val_mse: 178.3803\n",
      "Epoch 287/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 118.2181 - mae: 6.7146 - mse: 118.2181 - val_loss: 174.8306 - val_mae: 7.9510 - val_mse: 174.8306\n",
      "Epoch 288/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 116.8727 - mae: 6.6544 - mse: 116.8727 - val_loss: 179.6108 - val_mae: 8.4674 - val_mse: 179.6108\n",
      "Epoch 289/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 117.0422 - mae: 6.6650 - mse: 117.0422 - val_loss: 155.7746 - val_mae: 7.3510 - val_mse: 155.7746\n",
      "Epoch 290/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 117.8171 - mae: 6.6722 - mse: 117.8171 - val_loss: 147.9693 - val_mae: 7.7803 - val_mse: 147.9693\n",
      "Epoch 291/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 109.2629 - mae: 6.4870 - mse: 109.2629 - val_loss: 133.7281 - val_mae: 7.1007 - val_mse: 133.7281\n",
      "Epoch 292/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 96.8156 - mae: 6.0051 - mse: 96.8156 - val_loss: 141.5020 - val_mae: 7.1874 - val_mse: 141.5020\n",
      "Epoch 293/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.5574 - mae: 6.2043 - mse: 101.5574 - val_loss: 132.2948 - val_mae: 7.1620 - val_mse: 132.2948\n",
      "Epoch 294/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 94.0029 - mae: 5.8985 - mse: 94.0029 - val_loss: 118.7056 - val_mae: 6.5839 - val_mse: 118.7056\n",
      "Epoch 295/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 90.0900 - mae: 5.7501 - mse: 90.0900 - val_loss: 120.6364 - val_mae: 6.8975 - val_mse: 120.6364\n",
      "Epoch 296/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 90.4971 - mae: 5.8255 - mse: 90.4971 - val_loss: 125.4079 - val_mae: 6.9825 - val_mse: 125.4079\n",
      "Epoch 297/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 96.9190 - mae: 6.0192 - mse: 96.9190 - val_loss: 125.8770 - val_mae: 6.8160 - val_mse: 125.8771\n",
      "Epoch 298/1000\n",
      "17010/17010 [==============================] - 1s 88us/sample - loss: 92.6208 - mae: 5.9185 - mse: 92.6208 - val_loss: 167.6507 - val_mae: 8.3130 - val_mse: 167.6507\n",
      "Epoch 299/1000\n",
      "17010/17010 [==============================] - 1s 88us/sample - loss: 91.3439 - mae: 5.8227 - mse: 91.3439 - val_loss: 126.8513 - val_mae: 6.8022 - val_mse: 126.8513\n",
      "Epoch 300/1000\n",
      "17010/17010 [==============================] - 1s 88us/sample - loss: 89.6001 - mae: 5.7283 - mse: 89.6001 - val_loss: 225.1961 - val_mae: 9.2808 - val_mse: 225.1961\n",
      "Epoch 301/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 118.6673 - mae: 6.6178 - mse: 118.6673 - val_loss: 131.9413 - val_mae: 7.1584 - val_mse: 131.9413\n",
      "Epoch 302/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.3420 - mae: 5.8889 - mse: 94.3420 - val_loss: 129.7558 - val_mae: 7.2966 - val_mse: 129.7558\n",
      "Epoch 303/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 92.2230 - mae: 5.8664 - mse: 92.2230 - val_loss: 123.4792 - val_mae: 6.5844 - val_mse: 123.4792\n",
      "Epoch 304/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 101.3219 - mae: 6.0555 - mse: 101.3219 - val_loss: 126.9199 - val_mae: 6.7343 - val_mse: 126.9199\n",
      "Epoch 305/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 89.6914 - mae: 5.7015 - mse: 89.6914 - val_loss: 117.7607 - val_mae: 6.5203 - val_mse: 117.7607\n",
      "Epoch 306/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.5215 - mae: 5.5367 - mse: 85.5215 - val_loss: 158.2440 - val_mae: 7.7066 - val_mse: 158.2440\n",
      "Epoch 307/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 119.8738 - mae: 6.6828 - mse: 119.8738 - val_loss: 150.4568 - val_mae: 7.6997 - val_mse: 150.4568\n",
      "Epoch 308/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 107.7268 - mae: 6.3953 - mse: 107.7268 - val_loss: 129.7955 - val_mae: 6.8512 - val_mse: 129.7955\n",
      "Epoch 309/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 90.0339 - mae: 5.7333 - mse: 90.0339 - val_loss: 129.5126 - val_mae: 6.8479 - val_mse: 129.5126\n",
      "Epoch 310/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.4166 - mae: 5.7742 - mse: 91.4166 - val_loss: 127.8347 - val_mae: 6.7524 - val_mse: 127.8347\n",
      "Epoch 311/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 106.6983 - mae: 6.2799 - mse: 106.6983 - val_loss: 164.5208 - val_mae: 7.4846 - val_mse: 164.5208\n",
      "Epoch 312/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.3327 - mae: 6.0787 - mse: 101.3327 - val_loss: 146.0639 - val_mae: 7.1256 - val_mse: 146.0639\n",
      "Epoch 313/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.8574 - mae: 5.8332 - mse: 94.8574 - val_loss: 138.7811 - val_mae: 7.2356 - val_mse: 138.7811\n",
      "Epoch 314/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 88.7335 - mae: 5.6828 - mse: 88.7335 - val_loss: 131.4152 - val_mae: 7.2398 - val_mse: 131.4152\n",
      "Epoch 315/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 93.5546 - mae: 5.8129 - mse: 93.5546 - val_loss: 125.5105 - val_mae: 6.6420 - val_mse: 125.5105\n",
      "Epoch 316/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 107.1253 - mae: 6.2684 - mse: 107.1253 - val_loss: 136.1380 - val_mae: 7.3912 - val_mse: 136.1380\n",
      "Epoch 317/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 106.6434 - mae: 6.3651 - mse: 106.6434 - val_loss: 129.2402 - val_mae: 6.9562 - val_mse: 129.2402\n",
      "Epoch 318/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 98.0389 - mae: 5.9931 - mse: 98.0389 - val_loss: 136.0466 - val_mae: 7.2535 - val_mse: 136.0466\n",
      "Epoch 319/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 96.0763 - mae: 6.0563 - mse: 96.0763 - val_loss: 140.9117 - val_mae: 7.2931 - val_mse: 140.9117\n",
      "Epoch 320/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 95.3969 - mae: 5.9081 - mse: 95.3969 - val_loss: 210.5506 - val_mae: 9.4083 - val_mse: 210.5506\n",
      "Epoch 321/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 151.7671 - mae: 7.5950 - mse: 151.7671 - val_loss: 153.1345 - val_mae: 7.6046 - val_mse: 153.1345\n",
      "Epoch 322/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.0585 - mae: 6.1458 - mse: 99.0585 - val_loss: 133.4615 - val_mae: 6.9247 - val_mse: 133.4615\n",
      "Epoch 323/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 96.1124 - mae: 5.9987 - mse: 96.1124 - val_loss: 132.7662 - val_mae: 7.1926 - val_mse: 132.7662\n",
      "Epoch 324/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 100.6726 - mae: 6.1013 - mse: 100.6726 - val_loss: 151.2335 - val_mae: 7.3377 - val_mse: 151.2335\n",
      "Epoch 325/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 95.6179 - mae: 5.9411 - mse: 95.6179 - val_loss: 138.8092 - val_mae: 7.0613 - val_mse: 138.8092\n",
      "Epoch 326/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 103.2049 - mae: 6.0880 - mse: 103.2049 - val_loss: 137.4224 - val_mae: 7.0429 - val_mse: 137.4224\n",
      "Epoch 327/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 102.4248 - mae: 6.1575 - mse: 102.4248 - val_loss: 130.5905 - val_mae: 6.9623 - val_mse: 130.5906\n",
      "Epoch 328/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 87.1718 - mae: 5.7349 - mse: 87.1718 - val_loss: 127.4854 - val_mae: 6.9186 - val_mse: 127.4854\n",
      "Epoch 329/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 95.8203 - mae: 5.8764 - mse: 95.8203 - val_loss: 132.4485 - val_mae: 6.8604 - val_mse: 132.4485\n",
      "Epoch 330/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 92.0292 - mae: 5.7499 - mse: 92.0292 - val_loss: 126.5266 - val_mae: 6.8502 - val_mse: 126.5266\n",
      "Epoch 331/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 88.5524 - mae: 5.6651 - mse: 88.5524 - val_loss: 127.9183 - val_mae: 6.9744 - val_mse: 127.9183\n",
      "Epoch 332/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.6240 - mae: 5.8071 - mse: 94.6240 - val_loss: 137.1182 - val_mae: 7.4612 - val_mse: 137.1182\n",
      "Epoch 333/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.6360 - mae: 5.6761 - mse: 87.6360 - val_loss: 129.9947 - val_mae: 6.7941 - val_mse: 129.9947\n",
      "Epoch 334/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.6811 - mae: 5.6000 - mse: 85.6811 - val_loss: 126.3121 - val_mae: 6.8092 - val_mse: 126.3121\n",
      "Epoch 335/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 93.9982 - mae: 5.8601 - mse: 93.9982 - val_loss: 136.3018 - val_mae: 6.9416 - val_mse: 136.3018\n",
      "Epoch 336/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 103.1318 - mae: 6.1742 - mse: 103.1318 - val_loss: 131.3540 - val_mae: 6.8181 - val_mse: 131.3540\n",
      "Epoch 337/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 97.5720 - mae: 5.9688 - mse: 97.5720 - val_loss: 127.7237 - val_mae: 6.9410 - val_mse: 127.7238\n",
      "Epoch 338/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 88.6710 - mae: 5.7629 - mse: 88.6711 - val_loss: 139.1697 - val_mae: 7.2784 - val_mse: 139.1697\n",
      "Epoch 339/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.3081 - mae: 5.6862 - mse: 86.3082 - val_loss: 135.0858 - val_mae: 7.2353 - val_mse: 135.0858\n",
      "Epoch 340/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.6971 - mae: 5.8112 - mse: 93.6971 - val_loss: 133.5936 - val_mae: 7.2271 - val_mse: 133.5936\n",
      "Epoch 341/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 87.7915 - mae: 5.6676 - mse: 87.7915 - val_loss: 124.2481 - val_mae: 6.6220 - val_mse: 124.2481\n",
      "Epoch 342/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.8725 - mae: 5.8318 - mse: 93.8725 - val_loss: 145.5755 - val_mae: 7.3811 - val_mse: 145.5755\n",
      "Epoch 343/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.6041 - mae: 6.1371 - mse: 99.6041 - val_loss: 133.9319 - val_mae: 7.0258 - val_mse: 133.9319\n",
      "Epoch 344/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.3809 - mae: 5.8106 - mse: 90.3810 - val_loss: 146.3496 - val_mae: 7.2932 - val_mse: 146.3496\n",
      "Epoch 345/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 100.5967 - mae: 6.0598 - mse: 100.5967 - val_loss: 155.8670 - val_mae: 7.3821 - val_mse: 155.8670\n",
      "Epoch 346/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 94.5800 - mae: 5.8673 - mse: 94.5800 - val_loss: 126.1007 - val_mae: 6.9775 - val_mse: 126.1007\n",
      "Epoch 347/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.2846 - mae: 5.7454 - mse: 91.2846 - val_loss: 141.5355 - val_mae: 7.2826 - val_mse: 141.5355\n",
      "Epoch 348/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 114.1510 - mae: 6.4413 - mse: 114.1510 - val_loss: 134.5420 - val_mae: 7.2630 - val_mse: 134.5420\n",
      "Epoch 349/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 96.3041 - mae: 5.9878 - mse: 96.3041 - val_loss: 127.4231 - val_mae: 6.6208 - val_mse: 127.4231\n",
      "Epoch 350/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 89.7214 - mae: 5.6756 - mse: 89.7214 - val_loss: 125.9891 - val_mae: 6.8979 - val_mse: 125.9891\n",
      "Epoch 351/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.9286 - mae: 5.5899 - mse: 87.9286 - val_loss: 130.3953 - val_mae: 6.8868 - val_mse: 130.3953\n",
      "Epoch 352/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 82.2423 - mae: 5.4626 - mse: 82.2422 - val_loss: 122.8483 - val_mae: 6.8156 - val_mse: 122.8483\n",
      "Epoch 353/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.6861 - mae: 5.5524 - mse: 85.6861 - val_loss: 139.9917 - val_mae: 7.3495 - val_mse: 139.9917\n",
      "Epoch 354/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 89.5882 - mae: 5.7015 - mse: 89.5882 - val_loss: 136.4065 - val_mae: 6.9855 - val_mse: 136.4065\n",
      "Epoch 355/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 95.1822 - mae: 5.8806 - mse: 95.1822 - val_loss: 147.4149 - val_mae: 7.4366 - val_mse: 147.4149\n",
      "Epoch 356/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 100.4675 - mae: 6.1143 - mse: 100.4675 - val_loss: 151.2924 - val_mae: 7.7265 - val_mse: 151.2924\n",
      "Epoch 357/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 102.5593 - mae: 6.2908 - mse: 102.5593 - val_loss: 141.6100 - val_mae: 7.2050 - val_mse: 141.6100\n",
      "Epoch 358/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.1313 - mae: 5.9447 - mse: 93.1313 - val_loss: 127.0965 - val_mae: 6.7168 - val_mse: 127.0964\n",
      "Epoch 359/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.3361 - mae: 5.8810 - mse: 94.3361 - val_loss: 145.0223 - val_mae: 7.6198 - val_mse: 145.0222\n",
      "Epoch 360/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 108.6652 - mae: 6.3703 - mse: 108.6652 - val_loss: 153.8548 - val_mae: 7.7499 - val_mse: 153.8548\n",
      "Epoch 361/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 122.5335 - mae: 6.7500 - mse: 122.5335 - val_loss: 166.2873 - val_mae: 7.7134 - val_mse: 166.2872\n",
      "Epoch 362/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 107.4184 - mae: 6.3011 - mse: 107.4184 - val_loss: 200.4470 - val_mae: 8.4956 - val_mse: 200.4470\n",
      "Epoch 363/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 102.9211 - mae: 6.1477 - mse: 102.9211 - val_loss: 121.3767 - val_mae: 6.6572 - val_mse: 121.3767\n",
      "Epoch 364/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 82.4098 - mae: 5.4817 - mse: 82.4098 - val_loss: 132.8041 - val_mae: 6.9648 - val_mse: 132.8041\n",
      "Epoch 365/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.9207 - mae: 5.4649 - mse: 82.9207 - val_loss: 120.1970 - val_mae: 6.4559 - val_mse: 120.1970\n",
      "Epoch 366/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 77.9474 - mae: 5.2487 - mse: 77.9474 - val_loss: 124.0355 - val_mae: 6.7377 - val_mse: 124.0355\n",
      "Epoch 367/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.9621 - mae: 5.7767 - mse: 93.9622 - val_loss: 136.2394 - val_mae: 6.9188 - val_mse: 136.2394\n",
      "Epoch 368/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 97.4331 - mae: 5.9034 - mse: 97.4331 - val_loss: 139.3519 - val_mae: 6.9784 - val_mse: 139.3519\n",
      "Epoch 369/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.9688 - mae: 5.5628 - mse: 85.9688 - val_loss: 124.1375 - val_mae: 6.6516 - val_mse: 124.1375\n",
      "Epoch 370/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 81.4853 - mae: 5.3321 - mse: 81.4853 - val_loss: 132.2736 - val_mae: 7.0178 - val_mse: 132.2736\n",
      "Epoch 371/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 83.7605 - mae: 5.4709 - mse: 83.7605 - val_loss: 148.4285 - val_mae: 7.2164 - val_mse: 148.4285\n",
      "Epoch 372/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.2746 - mae: 5.9784 - mse: 99.2746 - val_loss: 123.3170 - val_mae: 6.8110 - val_mse: 123.3170\n",
      "Epoch 373/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 84.3026 - mae: 5.5507 - mse: 84.3026 - val_loss: 125.1094 - val_mae: 6.5977 - val_mse: 125.1094\n",
      "Epoch 374/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 89.7860 - mae: 5.7317 - mse: 89.7860 - val_loss: 138.3671 - val_mae: 7.2858 - val_mse: 138.3671\n",
      "Epoch 375/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 91.2764 - mae: 5.7870 - mse: 91.2764 - val_loss: 119.2595 - val_mae: 6.7266 - val_mse: 119.2595\n",
      "Epoch 376/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 89.8977 - mae: 5.6546 - mse: 89.8977 - val_loss: 150.7903 - val_mae: 7.5229 - val_mse: 150.7903\n",
      "Epoch 377/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 103.2521 - mae: 6.1246 - mse: 103.2521 - val_loss: 134.0106 - val_mae: 7.2011 - val_mse: 134.0106\n",
      "Epoch 378/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.7862 - mae: 5.7367 - mse: 90.7862 - val_loss: 136.5260 - val_mae: 6.9733 - val_mse: 136.5260\n",
      "Epoch 379/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.5941 - mae: 5.7743 - mse: 93.5941 - val_loss: 142.5239 - val_mae: 7.3744 - val_mse: 142.5239\n",
      "Epoch 380/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 87.2020 - mae: 5.6350 - mse: 87.2020 - val_loss: 118.2222 - val_mae: 6.5992 - val_mse: 118.2222\n",
      "Epoch 381/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.2641 - mae: 5.4270 - mse: 82.2641 - val_loss: 143.4953 - val_mae: 7.1243 - val_mse: 143.4953\n",
      "Epoch 382/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.7555 - mae: 6.1586 - mse: 105.7555 - val_loss: 131.4824 - val_mae: 7.2351 - val_mse: 131.4824\n",
      "Epoch 383/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 97.2740 - mae: 5.9037 - mse: 97.2740 - val_loss: 170.9925 - val_mae: 8.2945 - val_mse: 170.9925\n",
      "Epoch 384/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 102.9499 - mae: 6.1066 - mse: 102.9499 - val_loss: 124.2299 - val_mae: 6.7683 - val_mse: 124.2299\n",
      "Epoch 385/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.1646 - mae: 5.6211 - mse: 87.1646 - val_loss: 132.2835 - val_mae: 6.9253 - val_mse: 132.2834\n",
      "Epoch 386/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 89.8160 - mae: 5.6843 - mse: 89.8160 - val_loss: 140.6738 - val_mae: 7.2907 - val_mse: 140.6738\n",
      "Epoch 387/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.3362 - mae: 6.2774 - mse: 105.3362 - val_loss: 154.9573 - val_mae: 7.3337 - val_mse: 154.9573\n",
      "Epoch 388/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 120.9712 - mae: 6.7478 - mse: 120.9712 - val_loss: 144.5143 - val_mae: 7.4578 - val_mse: 144.5143\n",
      "Epoch 389/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 104.5620 - mae: 6.2817 - mse: 104.5620 - val_loss: 139.6836 - val_mae: 7.0950 - val_mse: 139.6836\n",
      "Epoch 390/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 112.6653 - mae: 6.4721 - mse: 112.6653 - val_loss: 148.1588 - val_mae: 7.1662 - val_mse: 148.1588\n",
      "Epoch 391/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 97.4345 - mae: 5.9697 - mse: 97.4345 - val_loss: 122.9431 - val_mae: 6.7050 - val_mse: 122.9431\n",
      "Epoch 392/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 99.9635 - mae: 5.9922 - mse: 99.9635 - val_loss: 126.2898 - val_mae: 6.8921 - val_mse: 126.2898\n",
      "Epoch 393/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 87.2704 - mae: 5.7237 - mse: 87.2704 - val_loss: 119.4275 - val_mae: 6.8104 - val_mse: 119.4275\n",
      "Epoch 394/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 90.7523 - mae: 5.7834 - mse: 90.7523 - val_loss: 133.7101 - val_mae: 6.9444 - val_mse: 133.7101\n",
      "Epoch 395/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.9985 - mae: 5.8129 - mse: 93.9985 - val_loss: 137.7388 - val_mae: 7.2574 - val_mse: 137.7388\n",
      "Epoch 396/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.6527 - mae: 5.9875 - mse: 99.6527 - val_loss: 140.2593 - val_mae: 7.0365 - val_mse: 140.2594\n",
      "Epoch 397/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 84.5895 - mae: 5.4749 - mse: 84.5895 - val_loss: 115.3416 - val_mae: 6.3520 - val_mse: 115.3416\n",
      "Epoch 398/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 80.1942 - mae: 5.3202 - mse: 80.1942 - val_loss: 137.6411 - val_mae: 6.8474 - val_mse: 137.6411\n",
      "Epoch 399/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.6404 - mae: 5.7810 - mse: 93.6404 - val_loss: 135.7070 - val_mae: 6.9631 - val_mse: 135.7070\n",
      "Epoch 400/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.3361 - mae: 5.8335 - mse: 94.3361 - val_loss: 145.7051 - val_mae: 7.0947 - val_mse: 145.7051\n",
      "Epoch 401/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 91.5082 - mae: 5.7440 - mse: 91.5082 - val_loss: 125.8796 - val_mae: 6.6399 - val_mse: 125.8796\n",
      "Epoch 402/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 80.4817 - mae: 5.3366 - mse: 80.4817 - val_loss: 168.9331 - val_mae: 8.1042 - val_mse: 168.9331\n",
      "Epoch 403/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.1952 - mae: 5.9736 - mse: 99.1952 - val_loss: 121.7363 - val_mae: 6.7633 - val_mse: 121.7363\n",
      "Epoch 404/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 90.8372 - mae: 5.7946 - mse: 90.8372 - val_loss: 139.5383 - val_mae: 7.0826 - val_mse: 139.5383\n",
      "Epoch 405/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 94.9492 - mae: 5.9906 - mse: 94.9492 - val_loss: 133.3312 - val_mae: 6.7705 - val_mse: 133.3312\n",
      "Epoch 406/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.2450 - mae: 5.5503 - mse: 85.2449 - val_loss: 120.4091 - val_mae: 6.4111 - val_mse: 120.4091\n",
      "Epoch 407/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 77.4090 - mae: 5.2646 - mse: 77.4090 - val_loss: 137.2056 - val_mae: 6.9880 - val_mse: 137.2056\n",
      "Epoch 408/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 84.0470 - mae: 5.4539 - mse: 84.0470 - val_loss: 152.1834 - val_mae: 7.3399 - val_mse: 152.1834\n",
      "Epoch 409/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.6930 - mae: 5.6143 - mse: 86.6930 - val_loss: 136.1795 - val_mae: 7.3599 - val_mse: 136.1795\n",
      "Epoch 410/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 83.4780 - mae: 5.4768 - mse: 83.4780 - val_loss: 146.6382 - val_mae: 7.0470 - val_mse: 146.6382\n",
      "Epoch 411/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 93.7750 - mae: 5.7808 - mse: 93.7750 - val_loss: 126.4080 - val_mae: 6.8665 - val_mse: 126.4080\n",
      "Epoch 412/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 83.4128 - mae: 5.4541 - mse: 83.4128 - val_loss: 132.3542 - val_mae: 6.8375 - val_mse: 132.3542\n",
      "Epoch 413/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 92.8347 - mae: 5.7021 - mse: 92.8347 - val_loss: 122.7951 - val_mae: 6.7531 - val_mse: 122.7951\n",
      "Epoch 414/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 92.9211 - mae: 5.8008 - mse: 92.9211 - val_loss: 161.0815 - val_mae: 8.3672 - val_mse: 161.0815\n",
      "Epoch 415/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 94.6687 - mae: 5.9326 - mse: 94.6687 - val_loss: 127.7728 - val_mae: 6.7861 - val_mse: 127.7728\n",
      "Epoch 416/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.9683 - mae: 5.8161 - mse: 87.9683 - val_loss: 134.0461 - val_mae: 6.8603 - val_mse: 134.0461\n",
      "Epoch 417/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 95.0954 - mae: 5.9751 - mse: 95.0954 - val_loss: 162.7475 - val_mae: 7.8324 - val_mse: 162.7475\n",
      "Epoch 418/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 91.3888 - mae: 5.8484 - mse: 91.3888 - val_loss: 153.8467 - val_mae: 7.2598 - val_mse: 153.8467\n",
      "Epoch 419/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 102.6017 - mae: 6.1082 - mse: 102.6017 - val_loss: 130.2197 - val_mae: 7.3255 - val_mse: 130.2197\n",
      "Epoch 420/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 87.3166 - mae: 5.6292 - mse: 87.3166 - val_loss: 127.0051 - val_mae: 6.7720 - val_mse: 127.0051\n",
      "Epoch 421/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.2274 - mae: 6.1342 - mse: 101.2274 - val_loss: 166.9008 - val_mae: 7.8573 - val_mse: 166.9008\n",
      "Epoch 422/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.6599 - mae: 6.0121 - mse: 99.6599 - val_loss: 126.6511 - val_mae: 6.6653 - val_mse: 126.6512\n",
      "Epoch 423/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.7240 - mae: 5.9604 - mse: 99.7240 - val_loss: 146.3676 - val_mae: 7.3302 - val_mse: 146.3676\n",
      "Epoch 424/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 99.0510 - mae: 6.0679 - mse: 99.0510 - val_loss: 151.5234 - val_mae: 7.2295 - val_mse: 151.5234\n",
      "Epoch 425/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 97.5493 - mae: 5.9793 - mse: 97.5493 - val_loss: 119.1528 - val_mae: 6.6775 - val_mse: 119.1529\n",
      "Epoch 426/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.0557 - mae: 5.7529 - mse: 90.0557 - val_loss: 152.2461 - val_mae: 7.6231 - val_mse: 152.2461\n",
      "Epoch 427/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 89.0299 - mae: 5.6545 - mse: 89.0299 - val_loss: 121.4965 - val_mae: 6.6942 - val_mse: 121.4965\n",
      "Epoch 428/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 87.6424 - mae: 5.5730 - mse: 87.6424 - val_loss: 123.9890 - val_mae: 6.7534 - val_mse: 123.9890\n",
      "Epoch 429/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.9090 - mae: 5.9017 - mse: 94.9090 - val_loss: 125.8823 - val_mae: 6.7879 - val_mse: 125.8823\n",
      "Epoch 430/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.4449 - mae: 5.6897 - mse: 90.4449 - val_loss: 119.6590 - val_mae: 6.6792 - val_mse: 119.6590\n",
      "Epoch 431/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 89.2450 - mae: 5.6525 - mse: 89.2450 - val_loss: 118.2010 - val_mae: 6.5252 - val_mse: 118.2010\n",
      "Epoch 432/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.5653 - mae: 5.4104 - mse: 82.5654 - val_loss: 132.0708 - val_mae: 7.0139 - val_mse: 132.0708\n",
      "Epoch 433/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.4501 - mae: 5.8617 - mse: 94.4501 - val_loss: 126.0631 - val_mae: 6.7107 - val_mse: 126.0631\n",
      "Epoch 434/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.7218 - mae: 5.5450 - mse: 86.7218 - val_loss: 131.3116 - val_mae: 6.8264 - val_mse: 131.3116\n",
      "Epoch 435/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.0534 - mae: 5.4874 - mse: 85.0534 - val_loss: 141.7444 - val_mae: 7.1933 - val_mse: 141.7444\n",
      "Epoch 436/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.8290 - mae: 6.1009 - mse: 105.8290 - val_loss: 126.1398 - val_mae: 6.6785 - val_mse: 126.1398\n",
      "Epoch 437/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.3231 - mae: 5.7190 - mse: 91.3231 - val_loss: 161.6546 - val_mae: 8.1184 - val_mse: 161.6546\n",
      "Epoch 438/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 91.1201 - mae: 5.6977 - mse: 91.1201 - val_loss: 126.0211 - val_mae: 6.6822 - val_mse: 126.0211\n",
      "Epoch 439/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 80.8295 - mae: 5.3272 - mse: 80.8295 - val_loss: 127.0672 - val_mae: 6.6724 - val_mse: 127.0672\n",
      "Epoch 440/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.5154 - mae: 5.3650 - mse: 82.5155 - val_loss: 136.4289 - val_mae: 6.8734 - val_mse: 136.4289\n",
      "Epoch 441/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 87.1836 - mae: 5.4825 - mse: 87.1836 - val_loss: 110.6049 - val_mae: 6.4608 - val_mse: 110.6049\n",
      "Epoch 442/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.4830 - mae: 5.1882 - mse: 76.4831 - val_loss: 121.8714 - val_mae: 6.7853 - val_mse: 121.8714\n",
      "Epoch 443/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.8239 - mae: 5.2501 - mse: 76.8239 - val_loss: 122.7046 - val_mae: 6.4305 - val_mse: 122.7046\n",
      "Epoch 444/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 96.7350 - mae: 5.8390 - mse: 96.7350 - val_loss: 122.5720 - val_mae: 6.6756 - val_mse: 122.5720\n",
      "Epoch 445/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 91.8631 - mae: 5.7775 - mse: 91.8631 - val_loss: 119.9280 - val_mae: 6.8764 - val_mse: 119.9280\n",
      "Epoch 446/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 81.2210 - mae: 5.3776 - mse: 81.2209 - val_loss: 126.7601 - val_mae: 6.7791 - val_mse: 126.7601\n",
      "Epoch 447/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 88.7391 - mae: 5.6383 - mse: 88.7391 - val_loss: 121.3904 - val_mae: 6.7228 - val_mse: 121.3904\n",
      "Epoch 448/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 85.7422 - mae: 5.4979 - mse: 85.7422 - val_loss: 117.3170 - val_mae: 6.3900 - val_mse: 117.3170\n",
      "Epoch 449/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.0120 - mae: 5.4803 - mse: 85.0120 - val_loss: 144.8000 - val_mae: 7.4703 - val_mse: 144.8000\n",
      "Epoch 450/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.5959 - mae: 5.6465 - mse: 91.5959 - val_loss: 115.8132 - val_mae: 6.5500 - val_mse: 115.8132\n",
      "Epoch 451/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.7745 - mae: 5.2559 - mse: 78.7745 - val_loss: 157.1353 - val_mae: 7.4270 - val_mse: 157.1353\n",
      "Epoch 452/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 96.5666 - mae: 5.8172 - mse: 96.5666 - val_loss: 111.7866 - val_mae: 6.2428 - val_mse: 111.7865\n",
      "Epoch 453/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.1341 - mae: 6.1216 - mse: 105.1341 - val_loss: 133.2273 - val_mae: 6.9898 - val_mse: 133.2273\n",
      "Epoch 454/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.1950 - mae: 5.6951 - mse: 91.1951 - val_loss: 128.5292 - val_mae: 6.8514 - val_mse: 128.5292\n",
      "Epoch 455/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 78.4017 - mae: 5.2820 - mse: 78.4016 - val_loss: 116.5383 - val_mae: 6.5045 - val_mse: 116.5383\n",
      "Epoch 456/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 79.1362 - mae: 5.2967 - mse: 79.1362 - val_loss: 134.7995 - val_mae: 6.7701 - val_mse: 134.7995\n",
      "Epoch 457/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 89.2563 - mae: 5.5544 - mse: 89.2563 - val_loss: 121.1702 - val_mae: 6.8828 - val_mse: 121.1702\n",
      "Epoch 458/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.7189 - mae: 5.4273 - mse: 82.7189 - val_loss: 113.0356 - val_mae: 6.4665 - val_mse: 113.0356\n",
      "Epoch 459/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.5711 - mae: 5.2512 - mse: 78.5711 - val_loss: 122.2391 - val_mae: 6.5411 - val_mse: 122.2391\n",
      "Epoch 460/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.8611 - mae: 5.2372 - mse: 78.8611 - val_loss: 121.1384 - val_mae: 6.4301 - val_mse: 121.1384\n",
      "Epoch 461/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 84.5602 - mae: 5.4311 - mse: 84.5602 - val_loss: 112.4145 - val_mae: 6.3071 - val_mse: 112.4145\n",
      "Epoch 462/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 94.7974 - mae: 5.7291 - mse: 94.7974 - val_loss: 160.2285 - val_mae: 7.6450 - val_mse: 160.2285\n",
      "Epoch 463/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.3405 - mae: 5.5358 - mse: 87.3405 - val_loss: 175.1078 - val_mae: 8.3707 - val_mse: 175.1078\n",
      "Epoch 464/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 101.1458 - mae: 5.9840 - mse: 101.1458 - val_loss: 154.4055 - val_mae: 7.2693 - val_mse: 154.4055\n",
      "Epoch 465/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 95.7258 - mae: 5.8391 - mse: 95.7258 - val_loss: 126.3017 - val_mae: 6.5476 - val_mse: 126.3017\n",
      "Epoch 466/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.7996 - mae: 5.5474 - mse: 86.7996 - val_loss: 131.5782 - val_mae: 6.9023 - val_mse: 131.5782\n",
      "Epoch 467/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.0913 - mae: 5.2469 - mse: 78.0912 - val_loss: 118.8110 - val_mae: 6.4950 - val_mse: 118.8110\n",
      "Epoch 468/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.7779 - mae: 5.2005 - mse: 78.7779 - val_loss: 125.5519 - val_mae: 7.0341 - val_mse: 125.5519\n",
      "Epoch 469/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 84.3265 - mae: 5.4335 - mse: 84.3265 - val_loss: 125.6177 - val_mae: 6.5285 - val_mse: 125.6177\n",
      "Epoch 470/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 81.0194 - mae: 5.3079 - mse: 81.0194 - val_loss: 132.2659 - val_mae: 6.8350 - val_mse: 132.2659\n",
      "Epoch 471/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.6762 - mae: 4.9784 - mse: 72.6762 - val_loss: 114.0977 - val_mae: 6.2805 - val_mse: 114.0977\n",
      "Epoch 472/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.0875 - mae: 5.0899 - mse: 76.0875 - val_loss: 123.4652 - val_mae: 6.5828 - val_mse: 123.4652\n",
      "Epoch 473/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.3415 - mae: 5.1297 - mse: 77.3415 - val_loss: 120.5850 - val_mae: 6.4911 - val_mse: 120.5850\n",
      "Epoch 474/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.5493 - mae: 5.1706 - mse: 77.5493 - val_loss: 133.8416 - val_mae: 6.9463 - val_mse: 133.8416\n",
      "Epoch 475/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 79.4060 - mae: 5.2290 - mse: 79.4060 - val_loss: 136.5397 - val_mae: 7.3352 - val_mse: 136.5397\n",
      "Epoch 476/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 81.5867 - mae: 5.3400 - mse: 81.5867 - val_loss: 119.8356 - val_mae: 6.5305 - val_mse: 119.8356\n",
      "Epoch 477/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.2694 - mae: 5.1670 - mse: 77.2694 - val_loss: 125.2369 - val_mae: 6.7063 - val_mse: 125.2369\n",
      "Epoch 478/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 84.8854 - mae: 5.5045 - mse: 84.8854 - val_loss: 122.2211 - val_mae: 6.4907 - val_mse: 122.2211\n",
      "Epoch 479/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 81.0620 - mae: 5.2900 - mse: 81.0620 - val_loss: 117.6025 - val_mae: 6.2319 - val_mse: 117.6025\n",
      "Epoch 480/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.3052 - mae: 5.1732 - mse: 78.3052 - val_loss: 120.1712 - val_mae: 6.4333 - val_mse: 120.1712\n",
      "Epoch 481/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 88.4307 - mae: 5.5969 - mse: 88.4307 - val_loss: 121.8760 - val_mae: 6.5124 - val_mse: 121.8760\n",
      "Epoch 482/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.9308 - mae: 5.3369 - mse: 78.9308 - val_loss: 142.7615 - val_mae: 7.1722 - val_mse: 142.7615\n",
      "Epoch 483/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.0683 - mae: 5.5774 - mse: 86.0683 - val_loss: 129.0777 - val_mae: 6.8075 - val_mse: 129.0777\n",
      "Epoch 484/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 88.5607 - mae: 5.6964 - mse: 88.5607 - val_loss: 129.2188 - val_mae: 6.8789 - val_mse: 129.2188\n",
      "Epoch 485/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.4332 - mae: 5.7348 - mse: 90.4332 - val_loss: 114.7077 - val_mae: 6.4682 - val_mse: 114.7077\n",
      "Epoch 486/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 79.5719 - mae: 5.3245 - mse: 79.5719 - val_loss: 120.2085 - val_mae: 6.3543 - val_mse: 120.2085\n",
      "Epoch 487/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 75.6321 - mae: 5.1650 - mse: 75.6321 - val_loss: 122.0166 - val_mae: 6.6157 - val_mse: 122.0166\n",
      "Epoch 488/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 71.0717 - mae: 5.0012 - mse: 71.0717 - val_loss: 130.6526 - val_mae: 6.7911 - val_mse: 130.6526\n",
      "Epoch 489/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 115.0131 - mae: 6.3914 - mse: 115.0131 - val_loss: 154.0675 - val_mae: 8.1061 - val_mse: 154.0675\n",
      "Epoch 490/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 101.5518 - mae: 6.1218 - mse: 101.5518 - val_loss: 115.4569 - val_mae: 6.6025 - val_mse: 115.4569\n",
      "Epoch 491/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 81.1113 - mae: 5.4977 - mse: 81.1113 - val_loss: 134.9280 - val_mae: 6.9021 - val_mse: 134.9281\n",
      "Epoch 492/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 115.9402 - mae: 6.5169 - mse: 115.9402 - val_loss: 130.7418 - val_mae: 7.0956 - val_mse: 130.7418\n",
      "Epoch 493/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 105.8975 - mae: 6.3085 - mse: 105.8975 - val_loss: 122.8720 - val_mae: 6.6279 - val_mse: 122.8720\n",
      "Epoch 494/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 92.8561 - mae: 5.8709 - mse: 92.8561 - val_loss: 122.0667 - val_mae: 6.6251 - val_mse: 122.0667\n",
      "Epoch 495/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.4367 - mae: 5.6452 - mse: 87.4367 - val_loss: 122.4466 - val_mae: 6.5764 - val_mse: 122.4466\n",
      "Epoch 496/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.7686 - mae: 5.0754 - mse: 72.7686 - val_loss: 121.5073 - val_mae: 6.5086 - val_mse: 121.5073\n",
      "Epoch 497/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.3914 - mae: 5.1429 - mse: 74.3915 - val_loss: 120.3732 - val_mae: 6.6296 - val_mse: 120.3732\n",
      "Epoch 498/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.5378 - mae: 5.1785 - mse: 76.5378 - val_loss: 140.1742 - val_mae: 7.0763 - val_mse: 140.1742\n",
      "Epoch 499/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.9193 - mae: 5.6940 - mse: 90.9193 - val_loss: 116.7561 - val_mae: 6.4790 - val_mse: 116.7561\n",
      "Epoch 500/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 75.4672 - mae: 5.1247 - mse: 75.4672 - val_loss: 126.8011 - val_mae: 7.0541 - val_mse: 126.8011\n",
      "Epoch 501/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.5846 - mae: 5.2197 - mse: 76.5846 - val_loss: 135.7939 - val_mae: 7.1324 - val_mse: 135.7939\n",
      "Epoch 502/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 73.4205 - mae: 5.0032 - mse: 73.4205 - val_loss: 120.9750 - val_mae: 6.5641 - val_mse: 120.9750\n",
      "Epoch 503/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 81.0620 - mae: 5.2743 - mse: 81.0620 - val_loss: 116.3340 - val_mae: 6.3780 - val_mse: 116.3340\n",
      "Epoch 504/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.0684 - mae: 5.1642 - mse: 77.0684 - val_loss: 114.8489 - val_mae: 6.4049 - val_mse: 114.8489\n",
      "Epoch 505/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.8914 - mae: 5.3453 - mse: 82.8914 - val_loss: 129.0807 - val_mae: 6.9294 - val_mse: 129.0807\n",
      "Epoch 506/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 75.8057 - mae: 5.1168 - mse: 75.8057 - val_loss: 114.2703 - val_mae: 6.2788 - val_mse: 114.2703\n",
      "Epoch 507/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 73.1548 - mae: 5.0036 - mse: 73.1549 - val_loss: 118.2925 - val_mae: 6.2969 - val_mse: 118.2925\n",
      "Epoch 508/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 88.4666 - mae: 5.4955 - mse: 88.4666 - val_loss: 120.9445 - val_mae: 6.4186 - val_mse: 120.9445\n",
      "Epoch 509/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 75.6486 - mae: 5.1000 - mse: 75.6486 - val_loss: 143.4654 - val_mae: 7.2466 - val_mse: 143.4654\n",
      "Epoch 510/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.9996 - mae: 5.0592 - mse: 74.9996 - val_loss: 116.7898 - val_mae: 6.4904 - val_mse: 116.7898\n",
      "Epoch 511/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 71.1428 - mae: 4.9888 - mse: 71.1428 - val_loss: 120.4767 - val_mae: 6.3211 - val_mse: 120.4767\n",
      "Epoch 512/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.5268 - mae: 5.0801 - mse: 76.5268 - val_loss: 119.5435 - val_mae: 6.5648 - val_mse: 119.5435\n",
      "Epoch 513/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 79.6954 - mae: 5.2473 - mse: 79.6954 - val_loss: 127.9079 - val_mae: 6.6328 - val_mse: 127.9079\n",
      "Epoch 514/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.9325 - mae: 5.4355 - mse: 82.9324 - val_loss: 194.6990 - val_mae: 8.3060 - val_mse: 194.6990\n",
      "Epoch 515/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 96.3844 - mae: 5.9778 - mse: 96.3844 - val_loss: 118.7670 - val_mae: 6.7731 - val_mse: 118.7670\n",
      "Epoch 516/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.2013 - mae: 5.2108 - mse: 74.2013 - val_loss: 113.3029 - val_mae: 6.4668 - val_mse: 113.3028\n",
      "Epoch 517/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 75.5565 - mae: 5.1995 - mse: 75.5565 - val_loss: 126.4966 - val_mae: 6.9185 - val_mse: 126.4965\n",
      "Epoch 518/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 76.7569 - mae: 5.2496 - mse: 76.7569 - val_loss: 118.3725 - val_mae: 6.7777 - val_mse: 118.3725\n",
      "Epoch 519/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 74.7180 - mae: 5.1849 - mse: 74.7180 - val_loss: 127.3507 - val_mae: 6.7603 - val_mse: 127.3507\n",
      "Epoch 520/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 85.0710 - mae: 5.4331 - mse: 85.0710 - val_loss: 130.0131 - val_mae: 7.2445 - val_mse: 130.0131\n",
      "Epoch 521/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 87.5759 - mae: 5.6109 - mse: 87.5759 - val_loss: 178.0532 - val_mae: 7.7708 - val_mse: 178.0532\n",
      "Epoch 522/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 118.8613 - mae: 6.6009 - mse: 118.8613 - val_loss: 132.5209 - val_mae: 6.9667 - val_mse: 132.5209\n",
      "Epoch 523/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 83.4643 - mae: 5.5133 - mse: 83.4643 - val_loss: 140.9649 - val_mae: 7.0337 - val_mse: 140.9649\n",
      "Epoch 524/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 96.5273 - mae: 5.8061 - mse: 96.5273 - val_loss: 120.3839 - val_mae: 6.5934 - val_mse: 120.3839\n",
      "Epoch 525/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 83.9436 - mae: 5.4783 - mse: 83.9436 - val_loss: 118.7498 - val_mae: 6.8052 - val_mse: 118.7498\n",
      "Epoch 526/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 78.2343 - mae: 5.2896 - mse: 78.2343 - val_loss: 117.0458 - val_mae: 6.3869 - val_mse: 117.0458\n",
      "Epoch 527/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 69.9602 - mae: 5.0343 - mse: 69.9603 - val_loss: 133.3945 - val_mae: 6.8860 - val_mse: 133.3945\n",
      "Epoch 528/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 75.0049 - mae: 5.1645 - mse: 75.0049 - val_loss: 118.1399 - val_mae: 6.4646 - val_mse: 118.1399\n",
      "Epoch 529/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.3674 - mae: 5.3652 - mse: 82.3674 - val_loss: 136.0812 - val_mae: 6.8748 - val_mse: 136.0812\n",
      "Epoch 530/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 103.2219 - mae: 6.1359 - mse: 103.2219 - val_loss: 142.3800 - val_mae: 7.3826 - val_mse: 142.3799\n",
      "Epoch 531/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 83.1812 - mae: 5.5748 - mse: 83.1812 - val_loss: 130.4546 - val_mae: 6.7431 - val_mse: 130.4545\n",
      "Epoch 532/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 73.2019 - mae: 5.0361 - mse: 73.2019 - val_loss: 118.3244 - val_mae: 6.3880 - val_mse: 118.3244\n",
      "Epoch 533/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.4371 - mae: 4.9835 - mse: 72.4371 - val_loss: 127.8123 - val_mae: 6.7795 - val_mse: 127.8123\n",
      "Epoch 534/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.7408 - mae: 5.0751 - mse: 74.7408 - val_loss: 127.7996 - val_mae: 6.6116 - val_mse: 127.7996\n",
      "Epoch 535/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 93.6417 - mae: 5.6722 - mse: 93.6416 - val_loss: 132.9014 - val_mae: 6.9148 - val_mse: 132.9014\n",
      "Epoch 536/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.4225 - mae: 5.6645 - mse: 91.4225 - val_loss: 170.9170 - val_mae: 8.1540 - val_mse: 170.9170\n",
      "Epoch 537/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.2202 - mae: 5.5878 - mse: 90.2203 - val_loss: 128.0352 - val_mae: 6.7744 - val_mse: 128.0352\n",
      "Epoch 538/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.2947 - mae: 5.0752 - mse: 74.2947 - val_loss: 120.0682 - val_mae: 6.4544 - val_mse: 120.0682\n",
      "Epoch 539/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 74.5260 - mae: 5.0076 - mse: 74.5260 - val_loss: 157.4969 - val_mae: 7.2241 - val_mse: 157.4969\n",
      "Epoch 540/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.3043 - mae: 5.3815 - mse: 85.3043 - val_loss: 120.2873 - val_mae: 6.5211 - val_mse: 120.2873\n",
      "Epoch 541/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 70.8692 - mae: 4.9260 - mse: 70.8691 - val_loss: 110.0273 - val_mae: 6.2453 - val_mse: 110.0273\n",
      "Epoch 542/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.6641 - mae: 5.1348 - mse: 77.6641 - val_loss: 142.3125 - val_mae: 7.1398 - val_mse: 142.3125\n",
      "Epoch 543/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 82.2493 - mae: 5.3078 - mse: 82.2493 - val_loss: 123.2557 - val_mae: 6.5783 - val_mse: 123.2557\n",
      "Epoch 544/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 79.1066 - mae: 5.1926 - mse: 79.1066 - val_loss: 110.5994 - val_mae: 6.0571 - val_mse: 110.5994\n",
      "Epoch 545/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 69.4750 - mae: 4.8193 - mse: 69.4750 - val_loss: 118.2386 - val_mae: 6.4068 - val_mse: 118.2386\n",
      "Epoch 546/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 85.1880 - mae: 5.3647 - mse: 85.1880 - val_loss: 117.4206 - val_mae: 6.5810 - val_mse: 117.4206\n",
      "Epoch 547/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 78.8638 - mae: 5.2863 - mse: 78.8638 - val_loss: 120.7708 - val_mae: 6.5302 - val_mse: 120.7708\n",
      "Epoch 548/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 72.8481 - mae: 5.0630 - mse: 72.8481 - val_loss: 117.6656 - val_mae: 6.3246 - val_mse: 117.6656\n",
      "Epoch 549/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 70.7795 - mae: 4.9689 - mse: 70.7795 - val_loss: 117.3227 - val_mae: 6.5370 - val_mse: 117.3228\n",
      "Epoch 550/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 91.2046 - mae: 5.6060 - mse: 91.2046 - val_loss: 133.7403 - val_mae: 6.7982 - val_mse: 133.7403\n",
      "Epoch 551/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 70.9108 - mae: 4.9422 - mse: 70.9108 - val_loss: 109.2477 - val_mae: 6.1523 - val_mse: 109.2477\n",
      "Epoch 552/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 64.0304 - mae: 4.6134 - mse: 64.0304 - val_loss: 130.3940 - val_mae: 6.6291 - val_mse: 130.3940\n",
      "Epoch 553/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.4835 - mae: 4.9374 - mse: 72.4835 - val_loss: 124.6865 - val_mae: 6.6977 - val_mse: 124.6865\n",
      "Epoch 554/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.9352 - mae: 5.0099 - mse: 72.9352 - val_loss: 121.0940 - val_mae: 6.8216 - val_mse: 121.0940\n",
      "Epoch 555/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 72.0991 - mae: 5.0029 - mse: 72.0991 - val_loss: 135.3614 - val_mae: 7.1427 - val_mse: 135.3614\n",
      "Epoch 556/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 91.6233 - mae: 5.6574 - mse: 91.6233 - val_loss: 133.4984 - val_mae: 6.8116 - val_mse: 133.4984\n",
      "Epoch 557/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 82.2343 - mae: 5.3828 - mse: 82.2342 - val_loss: 118.8431 - val_mae: 6.6287 - val_mse: 118.8431\n",
      "Epoch 558/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 71.0054 - mae: 5.0037 - mse: 71.0054 - val_loss: 120.9477 - val_mae: 6.4059 - val_mse: 120.9477\n",
      "Epoch 559/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 73.8749 - mae: 5.0568 - mse: 73.8749 - val_loss: 118.3055 - val_mae: 6.4134 - val_mse: 118.3055\n",
      "Epoch 560/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 70.1733 - mae: 4.9220 - mse: 70.1732 - val_loss: 131.2199 - val_mae: 6.7154 - val_mse: 131.2199\n",
      "Epoch 561/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 76.5515 - mae: 5.0657 - mse: 76.5515 - val_loss: 148.0020 - val_mae: 7.2351 - val_mse: 148.0020\n",
      "Epoch 562/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 96.7732 - mae: 5.8560 - mse: 96.7732 - val_loss: 144.0375 - val_mae: 7.2521 - val_mse: 144.0375\n",
      "Epoch 563/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 114.3066 - mae: 6.3861 - mse: 114.3066 - val_loss: 155.5945 - val_mae: 7.6375 - val_mse: 155.5945\n",
      "Epoch 564/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 95.7896 - mae: 5.8882 - mse: 95.7896 - val_loss: 186.0030 - val_mae: 8.3034 - val_mse: 186.0030\n",
      "Epoch 565/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 84.1150 - mae: 5.4685 - mse: 84.1150 - val_loss: 126.2023 - val_mae: 6.5677 - val_mse: 126.2023\n",
      "Epoch 566/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 86.1051 - mae: 5.4446 - mse: 86.1051 - val_loss: 165.5463 - val_mae: 7.4905 - val_mse: 165.5463\n",
      "Epoch 567/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 97.1004 - mae: 5.8048 - mse: 97.1004 - val_loss: 128.0415 - val_mae: 6.9329 - val_mse: 128.0415\n",
      "Epoch 568/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 85.8035 - mae: 5.4655 - mse: 85.8035 - val_loss: 117.8109 - val_mae: 6.4550 - val_mse: 117.8109\n",
      "Epoch 569/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 84.8358 - mae: 5.4034 - mse: 84.8358 - val_loss: 116.1508 - val_mae: 6.5321 - val_mse: 116.1508\n",
      "Epoch 570/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 78.0204 - mae: 5.1946 - mse: 78.0204 - val_loss: 122.1810 - val_mae: 6.7517 - val_mse: 122.1810\n",
      "Epoch 571/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 101.1465 - mae: 6.0078 - mse: 101.1465 - val_loss: 130.0836 - val_mae: 7.0925 - val_mse: 130.0836\n",
      "Epoch 572/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 75.6205 - mae: 5.1563 - mse: 75.6205 - val_loss: 110.6396 - val_mae: 6.3476 - val_mse: 110.6396\n",
      "Epoch 573/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 80.7391 - mae: 5.2595 - mse: 80.7391 - val_loss: 110.9336 - val_mae: 6.3627 - val_mse: 110.9336\n",
      "Epoch 574/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 72.2425 - mae: 4.9714 - mse: 72.2425 - val_loss: 111.0998 - val_mae: 6.4264 - val_mse: 111.0998\n",
      "Epoch 575/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.5802 - mae: 4.8658 - mse: 69.5802 - val_loss: 114.6649 - val_mae: 6.4521 - val_mse: 114.6649\n",
      "Epoch 576/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 75.9128 - mae: 5.0810 - mse: 75.9128 - val_loss: 149.2765 - val_mae: 7.4947 - val_mse: 149.2765\n",
      "Epoch 577/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.5419 - mae: 5.0160 - mse: 74.5419 - val_loss: 117.2527 - val_mae: 6.3905 - val_mse: 117.2527\n",
      "Epoch 578/1000\n",
      "17010/17010 [==============================] - 2s 88us/sample - loss: 78.5157 - mae: 5.1190 - mse: 78.5157 - val_loss: 119.5506 - val_mae: 6.2788 - val_mse: 119.5506\n",
      "Epoch 579/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 70.8859 - mae: 4.8949 - mse: 70.8859 - val_loss: 113.0590 - val_mae: 6.3821 - val_mse: 113.0591\n",
      "Epoch 580/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 76.1351 - mae: 5.0781 - mse: 76.1351 - val_loss: 127.7080 - val_mae: 6.7650 - val_mse: 127.7080\n",
      "Epoch 581/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 79.7851 - mae: 5.2272 - mse: 79.7851 - val_loss: 157.1905 - val_mae: 7.2028 - val_mse: 157.1905\n",
      "Epoch 582/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 79.6786 - mae: 5.1818 - mse: 79.6786 - val_loss: 127.7816 - val_mae: 6.6082 - val_mse: 127.7816\n",
      "Epoch 583/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 81.8475 - mae: 5.2581 - mse: 81.8475 - val_loss: 117.0038 - val_mae: 6.4191 - val_mse: 117.0038\n",
      "Epoch 584/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 81.6743 - mae: 5.3321 - mse: 81.6743 - val_loss: 116.8722 - val_mae: 6.4019 - val_mse: 116.8722\n",
      "Epoch 585/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 75.8485 - mae: 5.2006 - mse: 75.8485 - val_loss: 118.0697 - val_mae: 6.3712 - val_mse: 118.0697\n",
      "Epoch 586/1000\n",
      "17010/17010 [==============================] - 2s 90us/sample - loss: 73.5731 - mae: 5.0795 - mse: 73.5731 - val_loss: 129.2505 - val_mae: 6.7009 - val_mse: 129.2505\n",
      "Epoch 587/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 73.6376 - mae: 5.0179 - mse: 73.6376 - val_loss: 118.2018 - val_mae: 6.4999 - val_mse: 118.2018\n",
      "Epoch 588/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 69.3821 - mae: 4.8337 - mse: 69.3821 - val_loss: 113.0816 - val_mae: 6.1610 - val_mse: 113.0816\n",
      "Epoch 589/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 65.6524 - mae: 4.7137 - mse: 65.6524 - val_loss: 116.3069 - val_mae: 6.3491 - val_mse: 116.3069\n",
      "Epoch 590/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 73.2130 - mae: 4.9651 - mse: 73.2130 - val_loss: 146.1019 - val_mae: 6.9884 - val_mse: 146.1019\n",
      "Epoch 591/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 73.6665 - mae: 5.0421 - mse: 73.6665 - val_loss: 110.7472 - val_mae: 6.1728 - val_mse: 110.7472\n",
      "Epoch 592/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 69.3565 - mae: 4.8649 - mse: 69.3565 - val_loss: 120.2793 - val_mae: 6.4550 - val_mse: 120.2793\n",
      "Epoch 593/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 92.2998 - mae: 5.6208 - mse: 92.2998 - val_loss: 118.0022 - val_mae: 6.4622 - val_mse: 118.0022\n",
      "Epoch 594/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 72.4971 - mae: 4.9411 - mse: 72.4971 - val_loss: 113.5549 - val_mae: 6.1998 - val_mse: 113.5549\n",
      "Epoch 595/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 65.7058 - mae: 4.6968 - mse: 65.7058 - val_loss: 118.1586 - val_mae: 6.3078 - val_mse: 118.1586\n",
      "Epoch 596/1000\n",
      "17010/17010 [==============================] - 1s 87us/sample - loss: 67.0681 - mae: 4.7636 - mse: 67.0681 - val_loss: 122.5599 - val_mae: 6.5760 - val_mse: 122.5599\n",
      "Epoch 597/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.8026 - mae: 4.8870 - mse: 72.8026 - val_loss: 146.1140 - val_mae: 7.1634 - val_mse: 146.1140\n",
      "Epoch 598/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 78.6159 - mae: 5.1856 - mse: 78.6159 - val_loss: 121.3927 - val_mae: 6.6127 - val_mse: 121.3927\n",
      "Epoch 599/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 82.7029 - mae: 5.3007 - mse: 82.7029 - val_loss: 132.2255 - val_mae: 6.8828 - val_mse: 132.2255\n",
      "Epoch 600/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.6718 - mae: 5.1555 - mse: 78.6718 - val_loss: 117.5818 - val_mae: 6.4295 - val_mse: 117.5818\n",
      "Epoch 601/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 67.5720 - mae: 4.7308 - mse: 67.5720 - val_loss: 117.0393 - val_mae: 6.1900 - val_mse: 117.0393\n",
      "Epoch 602/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.9335 - mae: 5.0699 - mse: 76.9334 - val_loss: 115.7666 - val_mae: 6.2035 - val_mse: 115.7666\n",
      "Epoch 603/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 80.2586 - mae: 5.2225 - mse: 80.2586 - val_loss: 113.8655 - val_mae: 6.3255 - val_mse: 113.8655\n",
      "Epoch 604/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 70.4244 - mae: 4.8542 - mse: 70.4244 - val_loss: 160.9114 - val_mae: 7.4817 - val_mse: 160.9114\n",
      "Epoch 605/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 74.3278 - mae: 5.0228 - mse: 74.3278 - val_loss: 109.9760 - val_mae: 6.2208 - val_mse: 109.9760\n",
      "Epoch 606/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 72.6646 - mae: 4.9943 - mse: 72.6646 - val_loss: 149.6738 - val_mae: 7.1461 - val_mse: 149.6738\n",
      "Epoch 607/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 83.0852 - mae: 5.3473 - mse: 83.0852 - val_loss: 127.6403 - val_mae: 6.8075 - val_mse: 127.6403\n",
      "Epoch 608/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 89.3080 - mae: 5.6058 - mse: 89.3080 - val_loss: 124.7494 - val_mae: 6.7268 - val_mse: 124.7494\n",
      "Epoch 609/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 85.1336 - mae: 5.5105 - mse: 85.1336 - val_loss: 117.1838 - val_mae: 6.4803 - val_mse: 117.1838\n",
      "Epoch 610/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 70.9445 - mae: 4.9399 - mse: 70.9445 - val_loss: 122.3984 - val_mae: 6.8593 - val_mse: 122.3984\n",
      "Epoch 611/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 83.7461 - mae: 5.3014 - mse: 83.7461 - val_loss: 133.6810 - val_mae: 7.1343 - val_mse: 133.6810\n",
      "Epoch 612/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 87.4504 - mae: 5.5348 - mse: 87.4504 - val_loss: 116.4088 - val_mae: 6.3126 - val_mse: 116.4088\n",
      "Epoch 613/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 71.4947 - mae: 4.9934 - mse: 71.4947 - val_loss: 120.3921 - val_mae: 6.7641 - val_mse: 120.3921\n",
      "Epoch 614/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.4699 - mae: 5.2546 - mse: 77.4699 - val_loss: 151.2269 - val_mae: 7.3034 - val_mse: 151.2269\n",
      "Epoch 615/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 73.6412 - mae: 5.1171 - mse: 73.6412 - val_loss: 109.7575 - val_mae: 6.0701 - val_mse: 109.7575\n",
      "Epoch 616/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 72.5420 - mae: 5.0000 - mse: 72.5420 - val_loss: 147.1809 - val_mae: 7.3863 - val_mse: 147.1809\n",
      "Epoch 617/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 74.0750 - mae: 5.0972 - mse: 74.0750 - val_loss: 121.0469 - val_mae: 6.4171 - val_mse: 121.0469\n",
      "Epoch 618/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 69.8845 - mae: 4.9608 - mse: 69.8845 - val_loss: 120.8261 - val_mae: 6.6053 - val_mse: 120.8261\n",
      "Epoch 619/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 65.1153 - mae: 4.7321 - mse: 65.1153 - val_loss: 110.1958 - val_mae: 6.0073 - val_mse: 110.1958\n",
      "Epoch 620/1000\n",
      "17010/17010 [==============================] - 1s 88us/sample - loss: 68.1091 - mae: 4.7566 - mse: 68.1091 - val_loss: 165.0627 - val_mae: 7.4538 - val_mse: 165.0627\n",
      "Epoch 621/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 92.1196 - mae: 5.6164 - mse: 92.1196 - val_loss: 137.6962 - val_mae: 7.0604 - val_mse: 137.6962\n",
      "Epoch 622/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 72.6013 - mae: 4.9453 - mse: 72.6013 - val_loss: 115.0640 - val_mae: 6.3691 - val_mse: 115.0640\n",
      "Epoch 623/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 68.6805 - mae: 4.8144 - mse: 68.6805 - val_loss: 125.4468 - val_mae: 6.8680 - val_mse: 125.4468\n",
      "Epoch 624/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 68.7953 - mae: 4.8145 - mse: 68.7953 - val_loss: 177.6289 - val_mae: 8.0174 - val_mse: 177.6289\n",
      "Epoch 625/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 110.3198 - mae: 6.2409 - mse: 110.3198 - val_loss: 132.3203 - val_mae: 6.6713 - val_mse: 132.3203\n",
      "Epoch 626/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 75.7439 - mae: 5.2178 - mse: 75.7439 - val_loss: 151.7726 - val_mae: 7.4149 - val_mse: 151.7726\n",
      "Epoch 627/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.7962 - mae: 5.4905 - mse: 86.7962 - val_loss: 134.9595 - val_mae: 6.9491 - val_mse: 134.9595\n",
      "Epoch 628/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.2838 - mae: 5.3396 - mse: 77.2838 - val_loss: 126.9819 - val_mae: 7.0433 - val_mse: 126.9819\n",
      "Epoch 629/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 85.7548 - mae: 5.5570 - mse: 85.7548 - val_loss: 131.8764 - val_mae: 6.7707 - val_mse: 131.8764\n",
      "Epoch 630/1000\n",
      "17010/17010 [==============================] - 1s 86us/sample - loss: 81.0834 - mae: 5.3192 - mse: 81.0834 - val_loss: 134.7161 - val_mae: 7.0980 - val_mse: 134.7161\n",
      "Epoch 631/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 73.0011 - mae: 5.0733 - mse: 73.0011 - val_loss: 117.1567 - val_mae: 6.2541 - val_mse: 117.1567\n",
      "Epoch 632/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 66.2006 - mae: 4.7678 - mse: 66.2006 - val_loss: 115.8135 - val_mae: 6.1143 - val_mse: 115.8135\n",
      "Epoch 633/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 65.8069 - mae: 4.6899 - mse: 65.8069 - val_loss: 125.8136 - val_mae: 6.6318 - val_mse: 125.8136\n",
      "Epoch 634/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 106.2098 - mae: 6.0269 - mse: 106.2098 - val_loss: 133.8284 - val_mae: 7.2463 - val_mse: 133.8284\n",
      "Epoch 635/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 96.0467 - mae: 5.7696 - mse: 96.0467 - val_loss: 130.8088 - val_mae: 6.6580 - val_mse: 130.8088\n",
      "Epoch 636/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 84.9919 - mae: 5.4704 - mse: 84.9919 - val_loss: 118.9608 - val_mae: 6.2956 - val_mse: 118.9608\n",
      "Epoch 637/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 70.7240 - mae: 4.9699 - mse: 70.7240 - val_loss: 116.3512 - val_mae: 6.2187 - val_mse: 116.3512\n",
      "Epoch 638/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.2139 - mae: 4.6882 - mse: 66.2140 - val_loss: 129.5897 - val_mae: 6.4560 - val_mse: 129.5897\n",
      "Epoch 639/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 73.9577 - mae: 4.9768 - mse: 73.9577 - val_loss: 132.2514 - val_mae: 6.8824 - val_mse: 132.2514\n",
      "Epoch 640/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 68.2959 - mae: 4.7578 - mse: 68.2959 - val_loss: 123.0533 - val_mae: 6.4387 - val_mse: 123.0533\n",
      "Epoch 641/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 77.2479 - mae: 5.0954 - mse: 77.2479 - val_loss: 125.2614 - val_mae: 6.6597 - val_mse: 125.2614\n",
      "Epoch 642/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.8209 - mae: 4.9916 - mse: 74.8208 - val_loss: 171.6014 - val_mae: 8.0542 - val_mse: 171.6014\n",
      "Epoch 643/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.8015 - mae: 5.1376 - mse: 78.8015 - val_loss: 123.2769 - val_mae: 6.4691 - val_mse: 123.2769\n",
      "Epoch 644/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.7812 - mae: 4.9843 - mse: 74.7812 - val_loss: 126.4320 - val_mae: 6.6389 - val_mse: 126.4320\n",
      "Epoch 645/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 66.4786 - mae: 4.6588 - mse: 66.4786 - val_loss: 130.0896 - val_mae: 6.8003 - val_mse: 130.0896\n",
      "Epoch 646/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 73.1931 - mae: 4.9301 - mse: 73.1931 - val_loss: 122.2699 - val_mae: 6.5697 - val_mse: 122.2699\n",
      "Epoch 647/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 69.9181 - mae: 4.8399 - mse: 69.9181 - val_loss: 111.9080 - val_mae: 6.0264 - val_mse: 111.9080\n",
      "Epoch 648/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 61.1174 - mae: 4.4914 - mse: 61.1174 - val_loss: 110.7425 - val_mae: 6.2808 - val_mse: 110.7425\n",
      "Epoch 649/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 63.9986 - mae: 4.5652 - mse: 63.9986 - val_loss: 121.5708 - val_mae: 6.6825 - val_mse: 121.5708\n",
      "Epoch 650/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 78.4140 - mae: 5.1119 - mse: 78.4140 - val_loss: 120.4844 - val_mae: 6.4790 - val_mse: 120.4844\n",
      "Epoch 651/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 71.8164 - mae: 4.9085 - mse: 71.8164 - val_loss: 116.0757 - val_mae: 6.2361 - val_mse: 116.0757\n",
      "Epoch 652/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 70.4384 - mae: 4.8601 - mse: 70.4385 - val_loss: 140.9166 - val_mae: 7.2383 - val_mse: 140.9166\n",
      "Epoch 653/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.7683 - mae: 5.1176 - mse: 76.7682 - val_loss: 121.9210 - val_mae: 6.6644 - val_mse: 121.9210\n",
      "Epoch 654/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 80.7190 - mae: 5.2081 - mse: 80.7190 - val_loss: 132.4284 - val_mae: 6.6744 - val_mse: 132.4284\n",
      "Epoch 655/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 80.5446 - mae: 5.2115 - mse: 80.5446 - val_loss: 119.5242 - val_mae: 6.2756 - val_mse: 119.5242\n",
      "Epoch 656/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 61.7353 - mae: 4.5684 - mse: 61.7353 - val_loss: 115.4045 - val_mae: 6.1763 - val_mse: 115.4045\n",
      "Epoch 657/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 65.5399 - mae: 4.6906 - mse: 65.5399 - val_loss: 130.6186 - val_mae: 6.5478 - val_mse: 130.6186\n",
      "Epoch 658/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 70.5125 - mae: 4.8303 - mse: 70.5125 - val_loss: 116.6979 - val_mae: 6.3097 - val_mse: 116.6979\n",
      "Epoch 659/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 72.5320 - mae: 4.8817 - mse: 72.5320 - val_loss: 148.8969 - val_mae: 7.3855 - val_mse: 148.8969\n",
      "Epoch 660/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 70.3803 - mae: 4.8151 - mse: 70.3803 - val_loss: 127.1418 - val_mae: 6.7011 - val_mse: 127.1418\n",
      "Epoch 661/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 61.5644 - mae: 4.4939 - mse: 61.5644 - val_loss: 118.9282 - val_mae: 6.2694 - val_mse: 118.9282\n",
      "Epoch 662/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 65.4210 - mae: 4.5772 - mse: 65.4210 - val_loss: 110.5079 - val_mae: 6.0184 - val_mse: 110.5079\n",
      "Epoch 663/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 69.3138 - mae: 4.7615 - mse: 69.3138 - val_loss: 127.3769 - val_mae: 6.6652 - val_mse: 127.3769\n",
      "Epoch 664/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 71.6868 - mae: 4.8934 - mse: 71.6868 - val_loss: 132.5989 - val_mae: 6.5522 - val_mse: 132.5989\n",
      "Epoch 665/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 74.6524 - mae: 4.9781 - mse: 74.6524 - val_loss: 121.4757 - val_mae: 6.5096 - val_mse: 121.4757\n",
      "Epoch 666/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 64.7071 - mae: 4.6368 - mse: 64.7071 - val_loss: 110.8565 - val_mae: 6.2864 - val_mse: 110.8565\n",
      "Epoch 667/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 60.2529 - mae: 4.4257 - mse: 60.2529 - val_loss: 120.3332 - val_mae: 6.5285 - val_mse: 120.3332\n",
      "Epoch 668/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 64.0804 - mae: 4.6652 - mse: 64.0804 - val_loss: 107.5439 - val_mae: 6.0910 - val_mse: 107.5439\n",
      "Epoch 669/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 67.5190 - mae: 4.7835 - mse: 67.5190 - val_loss: 107.9818 - val_mae: 6.1592 - val_mse: 107.9818\n",
      "Epoch 670/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 65.5936 - mae: 4.6967 - mse: 65.5936 - val_loss: 141.2061 - val_mae: 7.0046 - val_mse: 141.2061\n",
      "Epoch 671/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 79.9180 - mae: 5.1837 - mse: 79.9180 - val_loss: 128.1778 - val_mae: 6.6051 - val_mse: 128.1778\n",
      "Epoch 672/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 90.4714 - mae: 5.5527 - mse: 90.4714 - val_loss: 115.0612 - val_mae: 6.4376 - val_mse: 115.0612\n",
      "Epoch 673/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 73.7268 - mae: 4.9396 - mse: 73.7268 - val_loss: 130.8597 - val_mae: 7.0228 - val_mse: 130.8597\n",
      "Epoch 674/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 78.6947 - mae: 5.1669 - mse: 78.6946 - val_loss: 119.2526 - val_mae: 6.4511 - val_mse: 119.2526\n",
      "Epoch 675/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 64.4038 - mae: 4.6896 - mse: 64.4038 - val_loss: 107.0649 - val_mae: 6.1463 - val_mse: 107.0649\n",
      "Epoch 676/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 59.1243 - mae: 4.4542 - mse: 59.1243 - val_loss: 113.5794 - val_mae: 6.4126 - val_mse: 113.5794\n",
      "Epoch 677/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 66.0835 - mae: 4.6875 - mse: 66.0835 - val_loss: 132.0712 - val_mae: 6.7546 - val_mse: 132.0712\n",
      "Epoch 678/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 68.4266 - mae: 4.6996 - mse: 68.4266 - val_loss: 115.5369 - val_mae: 6.4621 - val_mse: 115.5369\n",
      "Epoch 679/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.4401 - mae: 4.9164 - mse: 72.4401 - val_loss: 113.4021 - val_mae: 6.2433 - val_mse: 113.4021\n",
      "Epoch 680/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 69.8212 - mae: 4.7565 - mse: 69.8212 - val_loss: 121.5444 - val_mae: 6.3382 - val_mse: 121.5444\n",
      "Epoch 681/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 86.6811 - mae: 5.4926 - mse: 86.6811 - val_loss: 133.0882 - val_mae: 7.0426 - val_mse: 133.0882\n",
      "Epoch 682/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 84.3561 - mae: 5.4450 - mse: 84.3561 - val_loss: 130.1994 - val_mae: 7.0668 - val_mse: 130.1993\n",
      "Epoch 683/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 73.7691 - mae: 5.0983 - mse: 73.7692 - val_loss: 118.2663 - val_mae: 6.5674 - val_mse: 118.2663\n",
      "Epoch 684/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 67.4894 - mae: 4.8406 - mse: 67.4894 - val_loss: 114.5050 - val_mae: 6.1562 - val_mse: 114.5050\n",
      "Epoch 685/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 67.0471 - mae: 4.7616 - mse: 67.0471 - val_loss: 119.8303 - val_mae: 6.2355 - val_mse: 119.8304\n",
      "Epoch 686/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 64.3463 - mae: 4.6614 - mse: 64.3463 - val_loss: 113.8288 - val_mae: 6.0573 - val_mse: 113.8288\n",
      "Epoch 687/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 66.3638 - mae: 4.6409 - mse: 66.3638 - val_loss: 113.9733 - val_mae: 6.0773 - val_mse: 113.9733\n",
      "Epoch 688/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 62.2520 - mae: 4.4794 - mse: 62.2520 - val_loss: 132.4748 - val_mae: 6.6765 - val_mse: 132.4747\n",
      "Epoch 689/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 68.9780 - mae: 4.7178 - mse: 68.9780 - val_loss: 129.7091 - val_mae: 6.8132 - val_mse: 129.7091\n",
      "Epoch 690/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 67.5807 - mae: 4.6374 - mse: 67.5807 - val_loss: 139.6143 - val_mae: 7.1645 - val_mse: 139.6143\n",
      "Epoch 691/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 75.1102 - mae: 4.9777 - mse: 75.1102 - val_loss: 109.2621 - val_mae: 6.2476 - val_mse: 109.2621\n",
      "Epoch 692/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 65.2908 - mae: 4.6306 - mse: 65.2908 - val_loss: 121.1743 - val_mae: 6.5188 - val_mse: 121.1743\n",
      "Epoch 693/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 80.3131 - mae: 5.1770 - mse: 80.3131 - val_loss: 134.0069 - val_mae: 6.6949 - val_mse: 134.0069\n",
      "Epoch 694/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 86.1600 - mae: 5.3802 - mse: 86.1600 - val_loss: 130.3446 - val_mae: 6.6218 - val_mse: 130.3446\n",
      "Epoch 695/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 81.9315 - mae: 5.2650 - mse: 81.9315 - val_loss: 128.9547 - val_mae: 6.6849 - val_mse: 128.9547\n",
      "Epoch 696/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 73.7065 - mae: 4.9697 - mse: 73.7065 - val_loss: 125.1897 - val_mae: 6.7051 - val_mse: 125.1897\n",
      "Epoch 697/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 79.8341 - mae: 5.1733 - mse: 79.8341 - val_loss: 141.5049 - val_mae: 7.0138 - val_mse: 141.5049\n",
      "Epoch 698/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 74.7110 - mae: 5.0202 - mse: 74.7110 - val_loss: 115.9719 - val_mae: 6.1676 - val_mse: 115.9719\n",
      "Epoch 699/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.6491 - mae: 4.7393 - mse: 66.6491 - val_loss: 119.8698 - val_mae: 6.3849 - val_mse: 119.8698\n",
      "Epoch 700/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 78.3545 - mae: 5.1870 - mse: 78.3545 - val_loss: 123.8830 - val_mae: 6.6147 - val_mse: 123.8830\n",
      "Epoch 701/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 88.4309 - mae: 5.5824 - mse: 88.4309 - val_loss: 122.8741 - val_mae: 6.7684 - val_mse: 122.8741\n",
      "Epoch 702/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.9820 - mae: 4.9425 - mse: 69.9820 - val_loss: 117.0388 - val_mae: 6.5460 - val_mse: 117.0388\n",
      "Epoch 703/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.8344 - mae: 4.9588 - mse: 71.8344 - val_loss: 119.0874 - val_mae: 6.2771 - val_mse: 119.0874\n",
      "Epoch 704/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.3921 - mae: 4.5167 - mse: 61.3921 - val_loss: 112.3826 - val_mae: 6.0496 - val_mse: 112.3826\n",
      "Epoch 705/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.8275 - mae: 4.5023 - mse: 61.8275 - val_loss: 108.6579 - val_mae: 6.2601 - val_mse: 108.6579\n",
      "Epoch 706/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.2019 - mae: 4.4038 - mse: 60.2019 - val_loss: 133.9589 - val_mae: 6.5807 - val_mse: 133.9589\n",
      "Epoch 707/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 62.9993 - mae: 4.5210 - mse: 62.9993 - val_loss: 132.0334 - val_mae: 6.9569 - val_mse: 132.0334\n",
      "Epoch 708/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 78.5525 - mae: 5.0742 - mse: 78.5525 - val_loss: 113.3963 - val_mae: 6.1638 - val_mse: 113.3963\n",
      "Epoch 709/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.5871 - mae: 4.5044 - mse: 61.5871 - val_loss: 105.6990 - val_mae: 6.1495 - val_mse: 105.6990\n",
      "Epoch 710/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 58.8951 - mae: 4.3652 - mse: 58.8951 - val_loss: 109.9967 - val_mae: 6.0108 - val_mse: 109.9967\n",
      "Epoch 711/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 58.1711 - mae: 4.3022 - mse: 58.1711 - val_loss: 111.8321 - val_mae: 6.0597 - val_mse: 111.8321\n",
      "Epoch 712/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.6966 - mae: 4.6145 - mse: 66.6966 - val_loss: 115.9720 - val_mae: 6.1142 - val_mse: 115.9720\n",
      "Epoch 713/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.2827 - mae: 4.6454 - mse: 66.2827 - val_loss: 136.9944 - val_mae: 6.7219 - val_mse: 136.9944\n",
      "Epoch 714/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 84.3774 - mae: 5.2873 - mse: 84.3773 - val_loss: 140.0613 - val_mae: 7.0428 - val_mse: 140.0613\n",
      "Epoch 715/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 91.2202 - mae: 5.5912 - mse: 91.2202 - val_loss: 152.1667 - val_mae: 7.6547 - val_mse: 152.1667\n",
      "Epoch 716/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 77.2116 - mae: 5.3403 - mse: 77.2116 - val_loss: 125.0409 - val_mae: 6.6464 - val_mse: 125.0409\n",
      "Epoch 717/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 72.4980 - mae: 5.0950 - mse: 72.4980 - val_loss: 115.4784 - val_mae: 6.2896 - val_mse: 115.4784\n",
      "Epoch 718/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 70.8405 - mae: 4.9758 - mse: 70.8405 - val_loss: 117.1197 - val_mae: 6.2696 - val_mse: 117.1197\n",
      "Epoch 719/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.1017 - mae: 4.6944 - mse: 64.1017 - val_loss: 111.4812 - val_mae: 6.0770 - val_mse: 111.4812\n",
      "Epoch 720/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.3909 - mae: 4.4981 - mse: 60.3909 - val_loss: 119.4796 - val_mae: 6.4415 - val_mse: 119.4796\n",
      "Epoch 721/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 72.5698 - mae: 4.9294 - mse: 72.5698 - val_loss: 112.7439 - val_mae: 6.0078 - val_mse: 112.7439\n",
      "Epoch 722/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.5489 - mae: 4.9662 - mse: 74.5489 - val_loss: 118.7564 - val_mae: 6.5149 - val_mse: 118.7564\n",
      "Epoch 723/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 63.4855 - mae: 4.6122 - mse: 63.4855 - val_loss: 108.8980 - val_mae: 6.1686 - val_mse: 108.8980\n",
      "Epoch 724/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.3861 - mae: 4.6814 - mse: 64.3861 - val_loss: 107.8700 - val_mae: 6.0462 - val_mse: 107.8700\n",
      "Epoch 725/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 61.9040 - mae: 4.5656 - mse: 61.9040 - val_loss: 111.9552 - val_mae: 6.1837 - val_mse: 111.9552\n",
      "Epoch 726/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 77.0536 - mae: 5.1424 - mse: 77.0536 - val_loss: 129.9519 - val_mae: 6.7962 - val_mse: 129.9519\n",
      "Epoch 727/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.4073 - mae: 5.0379 - mse: 74.4073 - val_loss: 131.7932 - val_mae: 7.0963 - val_mse: 131.7932\n",
      "Epoch 728/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 68.1778 - mae: 4.8171 - mse: 68.1778 - val_loss: 132.5481 - val_mae: 6.7478 - val_mse: 132.5481\n",
      "Epoch 729/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 73.9110 - mae: 4.9945 - mse: 73.9110 - val_loss: 116.7715 - val_mae: 6.2208 - val_mse: 116.7715\n",
      "Epoch 730/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 62.0515 - mae: 4.5404 - mse: 62.0515 - val_loss: 123.6154 - val_mae: 6.3342 - val_mse: 123.6154\n",
      "Epoch 731/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.4247 - mae: 4.6752 - mse: 66.4247 - val_loss: 121.5986 - val_mae: 6.3388 - val_mse: 121.5986\n",
      "Epoch 732/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.7369 - mae: 4.6025 - mse: 63.7369 - val_loss: 108.1138 - val_mae: 6.0455 - val_mse: 108.1138\n",
      "Epoch 733/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.6913 - mae: 4.4416 - mse: 60.6913 - val_loss: 113.6219 - val_mae: 6.1516 - val_mse: 113.6219\n",
      "Epoch 734/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 61.1334 - mae: 4.5251 - mse: 61.1334 - val_loss: 108.7975 - val_mae: 6.2523 - val_mse: 108.7975\n",
      "Epoch 735/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.2247 - mae: 4.4216 - mse: 60.2247 - val_loss: 111.4690 - val_mae: 6.1621 - val_mse: 111.4690\n",
      "Epoch 736/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.3758 - mae: 4.4800 - mse: 61.3758 - val_loss: 106.6132 - val_mae: 5.9757 - val_mse: 106.6132\n",
      "Epoch 737/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 70.3191 - mae: 4.8439 - mse: 70.3191 - val_loss: 131.4830 - val_mae: 6.6896 - val_mse: 131.4830\n",
      "Epoch 738/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 67.9232 - mae: 4.7741 - mse: 67.9232 - val_loss: 115.3245 - val_mae: 6.2056 - val_mse: 115.3245\n",
      "Epoch 739/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.1173 - mae: 4.6465 - mse: 63.1173 - val_loss: 135.5687 - val_mae: 7.2862 - val_mse: 135.5687\n",
      "Epoch 740/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 69.9606 - mae: 4.8457 - mse: 69.9606 - val_loss: 170.4607 - val_mae: 7.8113 - val_mse: 170.4607\n",
      "Epoch 741/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 84.1152 - mae: 5.3409 - mse: 84.1152 - val_loss: 114.5729 - val_mae: 6.3442 - val_mse: 114.5729\n",
      "Epoch 742/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.4773 - mae: 4.6911 - mse: 63.4773 - val_loss: 114.3708 - val_mae: 6.1514 - val_mse: 114.3708\n",
      "Epoch 743/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.2845 - mae: 4.5897 - mse: 64.2845 - val_loss: 119.6125 - val_mae: 6.3930 - val_mse: 119.6125\n",
      "Epoch 744/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 74.5612 - mae: 4.9405 - mse: 74.5612 - val_loss: 140.3182 - val_mae: 7.0400 - val_mse: 140.3182\n",
      "Epoch 745/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 87.1097 - mae: 5.4931 - mse: 87.1097 - val_loss: 119.1994 - val_mae: 6.7401 - val_mse: 119.1994\n",
      "Epoch 746/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.4475 - mae: 5.0813 - mse: 74.4475 - val_loss: 128.1174 - val_mae: 6.7153 - val_mse: 128.1173\n",
      "Epoch 747/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 73.3635 - mae: 5.0230 - mse: 73.3635 - val_loss: 106.4421 - val_mae: 6.0376 - val_mse: 106.4421\n",
      "Epoch 748/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.3996 - mae: 4.9269 - mse: 71.3996 - val_loss: 112.5020 - val_mae: 6.1841 - val_mse: 112.5020\n",
      "Epoch 749/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 88.9971 - mae: 5.4442 - mse: 88.9971 - val_loss: 142.8964 - val_mae: 7.0201 - val_mse: 142.8964\n",
      "Epoch 750/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 92.7289 - mae: 5.5978 - mse: 92.7289 - val_loss: 122.4896 - val_mae: 6.5938 - val_mse: 122.4896\n",
      "Epoch 751/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.2074 - mae: 4.9307 - mse: 71.2074 - val_loss: 139.9098 - val_mae: 7.1036 - val_mse: 139.9098\n",
      "Epoch 752/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 70.1506 - mae: 4.8607 - mse: 70.1506 - val_loss: 127.2380 - val_mae: 6.7869 - val_mse: 127.2380\n",
      "Epoch 753/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 67.4659 - mae: 4.7536 - mse: 67.4659 - val_loss: 141.6370 - val_mae: 7.1833 - val_mse: 141.6370\n",
      "Epoch 754/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 89.0712 - mae: 5.3963 - mse: 89.0712 - val_loss: 110.3955 - val_mae: 6.3006 - val_mse: 110.3955\n",
      "Epoch 755/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.7317 - mae: 4.5533 - mse: 61.7317 - val_loss: 114.0031 - val_mae: 6.4422 - val_mse: 114.0031\n",
      "Epoch 756/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 62.9818 - mae: 4.5272 - mse: 62.9818 - val_loss: 104.7673 - val_mae: 6.1151 - val_mse: 104.7673\n",
      "Epoch 757/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.2927 - mae: 4.4510 - mse: 60.2927 - val_loss: 119.8378 - val_mae: 6.5899 - val_mse: 119.8379\n",
      "Epoch 758/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 72.1805 - mae: 4.8681 - mse: 72.1805 - val_loss: 118.9040 - val_mae: 6.2556 - val_mse: 118.9040\n",
      "Epoch 759/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.8809 - mae: 4.6184 - mse: 64.8809 - val_loss: 106.3071 - val_mae: 6.0298 - val_mse: 106.3071\n",
      "Epoch 760/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 57.0839 - mae: 4.2464 - mse: 57.0839 - val_loss: 109.9220 - val_mae: 6.0044 - val_mse: 109.9220\n",
      "Epoch 761/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 68.0203 - mae: 4.7094 - mse: 68.0203 - val_loss: 114.9498 - val_mae: 6.3347 - val_mse: 114.9498\n",
      "Epoch 762/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.9532 - mae: 4.5544 - mse: 63.9532 - val_loss: 108.2084 - val_mae: 6.0374 - val_mse: 108.2084\n",
      "Epoch 763/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 65.7521 - mae: 4.5705 - mse: 65.7521 - val_loss: 107.5946 - val_mae: 5.9836 - val_mse: 107.5946\n",
      "Epoch 764/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 73.1065 - mae: 4.8746 - mse: 73.1065 - val_loss: 117.2531 - val_mae: 6.4180 - val_mse: 117.2531\n",
      "Epoch 765/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 69.8150 - mae: 4.7950 - mse: 69.8150 - val_loss: 108.8800 - val_mae: 6.0463 - val_mse: 108.8800\n",
      "Epoch 766/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.8516 - mae: 4.4825 - mse: 60.8516 - val_loss: 114.7312 - val_mae: 6.0362 - val_mse: 114.7312\n",
      "Epoch 767/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 59.7717 - mae: 4.3581 - mse: 59.7717 - val_loss: 103.2277 - val_mae: 5.9732 - val_mse: 103.2277\n",
      "Epoch 768/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 55.5396 - mae: 4.1880 - mse: 55.5396 - val_loss: 111.6927 - val_mae: 6.2625 - val_mse: 111.6927\n",
      "Epoch 769/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 70.1076 - mae: 4.7036 - mse: 70.1076 - val_loss: 129.8603 - val_mae: 6.5631 - val_mse: 129.8603\n",
      "Epoch 770/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 67.3693 - mae: 4.6586 - mse: 67.3693 - val_loss: 134.3639 - val_mae: 7.0891 - val_mse: 134.3639\n",
      "Epoch 771/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 73.3661 - mae: 4.8566 - mse: 73.3661 - val_loss: 126.7141 - val_mae: 6.6802 - val_mse: 126.7141\n",
      "Epoch 772/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.7246 - mae: 4.8321 - mse: 71.7246 - val_loss: 120.4354 - val_mae: 6.3564 - val_mse: 120.4354\n",
      "Epoch 773/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 69.6656 - mae: 4.7563 - mse: 69.6656 - val_loss: 117.4300 - val_mae: 6.3815 - val_mse: 117.4300\n",
      "Epoch 774/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 65.5329 - mae: 4.5802 - mse: 65.5329 - val_loss: 124.6392 - val_mae: 6.9157 - val_mse: 124.6392\n",
      "Epoch 775/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.8005 - mae: 4.8521 - mse: 71.8005 - val_loss: 115.4499 - val_mae: 6.3446 - val_mse: 115.4499\n",
      "Epoch 776/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.8297 - mae: 5.0580 - mse: 74.8297 - val_loss: 135.2696 - val_mae: 6.9586 - val_mse: 135.2696\n",
      "Epoch 777/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 94.1851 - mae: 5.6170 - mse: 94.1851 - val_loss: 140.7483 - val_mae: 7.4501 - val_mse: 140.7483\n",
      "Epoch 778/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 78.7522 - mae: 5.2480 - mse: 78.7522 - val_loss: 121.8805 - val_mae: 6.9307 - val_mse: 121.8805\n",
      "Epoch 779/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 66.4498 - mae: 4.8016 - mse: 66.4498 - val_loss: 111.9180 - val_mae: 6.0368 - val_mse: 111.9180\n",
      "Epoch 780/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 63.8411 - mae: 4.6488 - mse: 63.8411 - val_loss: 112.0322 - val_mae: 6.2945 - val_mse: 112.0322\n",
      "Epoch 781/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 58.1190 - mae: 4.4201 - mse: 58.1190 - val_loss: 123.7102 - val_mae: 6.6977 - val_mse: 123.7102\n",
      "Epoch 782/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 76.3216 - mae: 5.0385 - mse: 76.3216 - val_loss: 128.5697 - val_mae: 6.6925 - val_mse: 128.5697\n",
      "Epoch 783/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 75.6123 - mae: 4.9701 - mse: 75.6123 - val_loss: 121.1890 - val_mae: 6.4121 - val_mse: 121.1890\n",
      "Epoch 784/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 66.8593 - mae: 4.6647 - mse: 66.8593 - val_loss: 109.6912 - val_mae: 6.0905 - val_mse: 109.6912\n",
      "Epoch 785/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 65.6353 - mae: 4.6563 - mse: 65.6353 - val_loss: 118.6624 - val_mae: 6.5320 - val_mse: 118.6624\n",
      "Epoch 786/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 72.5706 - mae: 4.9041 - mse: 72.5705 - val_loss: 186.5275 - val_mae: 8.2732 - val_mse: 186.5275\n",
      "Epoch 787/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 72.8031 - mae: 4.9675 - mse: 72.8031 - val_loss: 116.9054 - val_mae: 6.2964 - val_mse: 116.9054\n",
      "Epoch 788/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 66.9146 - mae: 4.7231 - mse: 66.9146 - val_loss: 125.3044 - val_mae: 6.5014 - val_mse: 125.3044\n",
      "Epoch 789/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 70.8106 - mae: 4.8117 - mse: 70.8106 - val_loss: 133.6539 - val_mae: 6.8869 - val_mse: 133.6539\n",
      "Epoch 790/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 77.4478 - mae: 5.1038 - mse: 77.4478 - val_loss: 126.6890 - val_mae: 6.5846 - val_mse: 126.6890\n",
      "Epoch 791/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 72.8126 - mae: 4.8845 - mse: 72.8126 - val_loss: 111.3947 - val_mae: 6.0903 - val_mse: 111.3947\n",
      "Epoch 792/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 61.0916 - mae: 4.4671 - mse: 61.0916 - val_loss: 178.4531 - val_mae: 8.0079 - val_mse: 178.4531\n",
      "Epoch 793/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 83.5581 - mae: 5.2105 - mse: 83.5581 - val_loss: 156.9826 - val_mae: 7.3728 - val_mse: 156.9826\n",
      "Epoch 794/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 87.3357 - mae: 5.3867 - mse: 87.3357 - val_loss: 120.3749 - val_mae: 6.5728 - val_mse: 120.3749\n",
      "Epoch 795/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 69.8978 - mae: 4.8170 - mse: 69.8978 - val_loss: 163.8400 - val_mae: 7.9931 - val_mse: 163.8400\n",
      "Epoch 796/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 90.9923 - mae: 5.5269 - mse: 90.9923 - val_loss: 122.0793 - val_mae: 6.5962 - val_mse: 122.0793\n",
      "Epoch 797/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 72.7870 - mae: 5.0184 - mse: 72.7870 - val_loss: 126.3301 - val_mae: 6.6261 - val_mse: 126.3301\n",
      "Epoch 798/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 65.8283 - mae: 4.6925 - mse: 65.8283 - val_loss: 126.3737 - val_mae: 6.7073 - val_mse: 126.3737\n",
      "Epoch 799/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 77.0237 - mae: 5.0722 - mse: 77.0237 - val_loss: 112.0003 - val_mae: 6.2790 - val_mse: 112.0003\n",
      "Epoch 800/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 83.7470 - mae: 5.3727 - mse: 83.7470 - val_loss: 112.4785 - val_mae: 6.4013 - val_mse: 112.4785\n",
      "Epoch 801/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 69.3413 - mae: 4.8655 - mse: 69.3413 - val_loss: 123.3102 - val_mae: 6.4053 - val_mse: 123.3102\n",
      "Epoch 802/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 61.4640 - mae: 4.4824 - mse: 61.4640 - val_loss: 115.7828 - val_mae: 6.2694 - val_mse: 115.7828\n",
      "Epoch 803/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 78.7661 - mae: 5.0759 - mse: 78.7661 - val_loss: 139.2567 - val_mae: 6.8512 - val_mse: 139.2567\n",
      "Epoch 804/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 78.4588 - mae: 5.1070 - mse: 78.4588 - val_loss: 110.1862 - val_mae: 6.1285 - val_mse: 110.1862\n",
      "Epoch 805/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 61.6457 - mae: 4.5155 - mse: 61.6457 - val_loss: 110.9495 - val_mae: 6.1636 - val_mse: 110.9495\n",
      "Epoch 806/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 65.5274 - mae: 4.6089 - mse: 65.5274 - val_loss: 108.1598 - val_mae: 5.9951 - val_mse: 108.1598\n",
      "Epoch 807/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 56.1939 - mae: 4.2970 - mse: 56.1939 - val_loss: 113.4055 - val_mae: 6.0710 - val_mse: 113.4055\n",
      "Epoch 808/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 55.1529 - mae: 4.1995 - mse: 55.1529 - val_loss: 105.3812 - val_mae: 5.8079 - val_mse: 105.3812\n",
      "Epoch 809/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 62.2615 - mae: 4.4559 - mse: 62.2614 - val_loss: 124.6385 - val_mae: 6.4669 - val_mse: 124.6385\n",
      "Epoch 810/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 69.9111 - mae: 4.7463 - mse: 69.9111 - val_loss: 162.4726 - val_mae: 7.6263 - val_mse: 162.4726\n",
      "Epoch 811/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 80.1728 - mae: 5.1469 - mse: 80.1728 - val_loss: 115.8298 - val_mae: 6.1689 - val_mse: 115.8298\n",
      "Epoch 812/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 67.5180 - mae: 4.7383 - mse: 67.5180 - val_loss: 116.7135 - val_mae: 6.3423 - val_mse: 116.7135\n",
      "Epoch 813/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 63.6254 - mae: 4.5395 - mse: 63.6254 - val_loss: 123.6096 - val_mae: 6.5422 - val_mse: 123.6096\n",
      "Epoch 814/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 89.2942 - mae: 5.5236 - mse: 89.2942 - val_loss: 117.1479 - val_mae: 6.6639 - val_mse: 117.1479\n",
      "Epoch 815/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.7714 - mae: 5.2518 - mse: 77.7714 - val_loss: 114.3275 - val_mae: 6.3551 - val_mse: 114.3275\n",
      "Epoch 816/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 67.6930 - mae: 4.8206 - mse: 67.6930 - val_loss: 111.7029 - val_mae: 6.1156 - val_mse: 111.7029\n",
      "Epoch 817/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 63.6652 - mae: 4.6055 - mse: 63.6652 - val_loss: 118.9746 - val_mae: 6.6081 - val_mse: 118.9746\n",
      "Epoch 818/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 63.5234 - mae: 4.6798 - mse: 63.5234 - val_loss: 132.7805 - val_mae: 7.1873 - val_mse: 132.7805\n",
      "Epoch 819/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 68.6590 - mae: 4.7928 - mse: 68.6590 - val_loss: 121.9482 - val_mae: 6.4139 - val_mse: 121.9482\n",
      "Epoch 820/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 63.3762 - mae: 4.6209 - mse: 63.3762 - val_loss: 109.8858 - val_mae: 6.0353 - val_mse: 109.8858\n",
      "Epoch 821/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 58.6539 - mae: 4.3824 - mse: 58.6539 - val_loss: 118.4596 - val_mae: 6.3330 - val_mse: 118.4596\n",
      "Epoch 822/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 61.8721 - mae: 4.4738 - mse: 61.8721 - val_loss: 148.5934 - val_mae: 6.9822 - val_mse: 148.5934\n",
      "Epoch 823/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 74.6778 - mae: 4.9959 - mse: 74.6778 - val_loss: 118.4576 - val_mae: 6.5209 - val_mse: 118.4576\n",
      "Epoch 824/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 63.2713 - mae: 4.5634 - mse: 63.2713 - val_loss: 115.3050 - val_mae: 6.0877 - val_mse: 115.3050\n",
      "Epoch 825/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 59.7866 - mae: 4.3496 - mse: 59.7866 - val_loss: 109.1729 - val_mae: 6.1191 - val_mse: 109.1729\n",
      "Epoch 826/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 61.6547 - mae: 4.4690 - mse: 61.6547 - val_loss: 119.2795 - val_mae: 6.3703 - val_mse: 119.2795\n",
      "Epoch 827/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.4823 - mae: 4.3801 - mse: 61.4823 - val_loss: 114.5073 - val_mae: 6.2652 - val_mse: 114.5074\n",
      "Epoch 828/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 56.1996 - mae: 4.2074 - mse: 56.1996 - val_loss: 114.4747 - val_mae: 6.2198 - val_mse: 114.4747\n",
      "Epoch 829/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.5514 - mae: 4.4130 - mse: 61.5514 - val_loss: 122.1075 - val_mae: 6.4838 - val_mse: 122.1075\n",
      "Epoch 830/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 80.3581 - mae: 5.1169 - mse: 80.3581 - val_loss: 122.1344 - val_mae: 6.4900 - val_mse: 122.1344\n",
      "Epoch 831/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 70.9882 - mae: 4.8312 - mse: 70.9882 - val_loss: 122.1058 - val_mae: 6.8099 - val_mse: 122.1058\n",
      "Epoch 832/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 65.1669 - mae: 4.7486 - mse: 65.1669 - val_loss: 123.9982 - val_mae: 6.9705 - val_mse: 123.9982\n",
      "Epoch 833/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 63.1515 - mae: 4.6526 - mse: 63.1515 - val_loss: 110.1817 - val_mae: 6.0894 - val_mse: 110.1817\n",
      "Epoch 834/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 63.1734 - mae: 4.6330 - mse: 63.1735 - val_loss: 113.1784 - val_mae: 6.2565 - val_mse: 113.1784\n",
      "Epoch 835/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.2695 - mae: 5.0196 - mse: 77.2694 - val_loss: 138.1997 - val_mae: 6.7434 - val_mse: 138.1996\n",
      "Epoch 836/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 66.0908 - mae: 4.6374 - mse: 66.0908 - val_loss: 128.8242 - val_mae: 6.4646 - val_mse: 128.8242\n",
      "Epoch 837/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 64.9408 - mae: 4.5523 - mse: 64.9408 - val_loss: 127.0618 - val_mae: 6.6299 - val_mse: 127.0618\n",
      "Epoch 838/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 65.5601 - mae: 4.5461 - mse: 65.5601 - val_loss: 128.0769 - val_mae: 7.0000 - val_mse: 128.0769\n",
      "Epoch 839/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 77.0685 - mae: 5.0770 - mse: 77.0685 - val_loss: 123.9686 - val_mae: 6.7997 - val_mse: 123.9686\n",
      "Epoch 840/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 77.0409 - mae: 5.2205 - mse: 77.0409 - val_loss: 127.1796 - val_mae: 7.1347 - val_mse: 127.1796\n",
      "Epoch 841/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 64.3514 - mae: 4.7424 - mse: 64.3514 - val_loss: 115.1145 - val_mae: 6.0994 - val_mse: 115.1145\n",
      "Epoch 842/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 69.2772 - mae: 4.7803 - mse: 69.2772 - val_loss: 121.5311 - val_mae: 6.5786 - val_mse: 121.5312\n",
      "Epoch 843/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 69.7266 - mae: 4.8279 - mse: 69.7266 - val_loss: 117.9004 - val_mae: 6.2016 - val_mse: 117.9004\n",
      "Epoch 844/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 69.4779 - mae: 4.6937 - mse: 69.4779 - val_loss: 123.4573 - val_mae: 6.5948 - val_mse: 123.4573\n",
      "Epoch 845/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.9195 - mae: 4.7512 - mse: 69.9195 - val_loss: 109.9857 - val_mae: 6.2571 - val_mse: 109.9857\n",
      "Epoch 846/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 57.4905 - mae: 4.3154 - mse: 57.4905 - val_loss: 105.2858 - val_mae: 5.7934 - val_mse: 105.2857\n",
      "Epoch 847/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 60.1586 - mae: 4.3392 - mse: 60.1586 - val_loss: 108.6692 - val_mae: 6.2505 - val_mse: 108.6693\n",
      "Epoch 848/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 59.8272 - mae: 4.3671 - mse: 59.8272 - val_loss: 108.1447 - val_mae: 6.0264 - val_mse: 108.1448\n",
      "Epoch 849/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 56.5298 - mae: 4.2140 - mse: 56.5298 - val_loss: 121.8381 - val_mae: 6.2274 - val_mse: 121.8381\n",
      "Epoch 850/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 60.2739 - mae: 4.3508 - mse: 60.2738 - val_loss: 110.4177 - val_mae: 6.3440 - val_mse: 110.4177\n",
      "Epoch 851/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 63.4642 - mae: 4.5204 - mse: 63.4642 - val_loss: 135.0703 - val_mae: 7.2512 - val_mse: 135.0703\n",
      "Epoch 852/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 66.8107 - mae: 4.7022 - mse: 66.8107 - val_loss: 122.1493 - val_mae: 6.3944 - val_mse: 122.1493\n",
      "Epoch 853/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 67.2612 - mae: 4.6076 - mse: 67.2612 - val_loss: 117.7842 - val_mae: 6.4152 - val_mse: 117.7842\n",
      "Epoch 854/1000\n",
      "17010/17010 [==============================] - 1s 84us/sample - loss: 65.6406 - mae: 4.6112 - mse: 65.6406 - val_loss: 129.9625 - val_mae: 6.7507 - val_mse: 129.9625\n",
      "Epoch 855/1000\n",
      "17010/17010 [==============================] - 1s 85us/sample - loss: 61.8443 - mae: 4.5669 - mse: 61.8443 - val_loss: 118.7187 - val_mae: 6.2977 - val_mse: 118.7188\n",
      "Epoch 856/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 57.4150 - mae: 4.3494 - mse: 57.4150 - val_loss: 108.3842 - val_mae: 5.8655 - val_mse: 108.3842\n",
      "Epoch 857/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.1849 - mae: 4.6680 - mse: 66.1849 - val_loss: 122.4670 - val_mae: 6.5514 - val_mse: 122.4670\n",
      "Epoch 858/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 64.9335 - mae: 4.6647 - mse: 64.9335 - val_loss: 117.7966 - val_mae: 6.3389 - val_mse: 117.7966\n",
      "Epoch 859/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 64.5142 - mae: 4.6034 - mse: 64.5142 - val_loss: 128.2420 - val_mae: 6.6657 - val_mse: 128.2420\n",
      "Epoch 860/1000\n",
      "17010/17010 [==============================] - 1s 83us/sample - loss: 64.5422 - mae: 4.6692 - mse: 64.5422 - val_loss: 131.2753 - val_mae: 6.8413 - val_mse: 131.2753\n",
      "Epoch 861/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 72.4606 - mae: 4.9260 - mse: 72.4606 - val_loss: 113.2215 - val_mae: 6.3444 - val_mse: 113.2215\n",
      "Epoch 862/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 59.2120 - mae: 4.4526 - mse: 59.2120 - val_loss: 115.1849 - val_mae: 6.2783 - val_mse: 115.1849\n",
      "Epoch 863/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 81.0333 - mae: 5.1338 - mse: 81.0333 - val_loss: 121.2034 - val_mae: 6.3746 - val_mse: 121.2034\n",
      "Epoch 864/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 78.9606 - mae: 5.1326 - mse: 78.9606 - val_loss: 122.2859 - val_mae: 6.3646 - val_mse: 122.2859\n",
      "Epoch 865/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 67.0586 - mae: 4.8090 - mse: 67.0586 - val_loss: 118.6053 - val_mae: 6.3570 - val_mse: 118.6053\n",
      "Epoch 866/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 71.4060 - mae: 4.8489 - mse: 71.4060 - val_loss: 124.2109 - val_mae: 6.5974 - val_mse: 124.2109\n",
      "Epoch 867/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 87.5409 - mae: 5.4761 - mse: 87.5408 - val_loss: 112.6605 - val_mae: 6.3832 - val_mse: 112.6605\n",
      "Epoch 868/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 68.8891 - mae: 4.8760 - mse: 68.8891 - val_loss: 114.2210 - val_mae: 6.4015 - val_mse: 114.2210\n",
      "Epoch 869/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.4858 - mae: 4.9111 - mse: 69.4858 - val_loss: 114.9323 - val_mae: 6.2630 - val_mse: 114.9323\n",
      "Epoch 870/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.7539 - mae: 4.8023 - mse: 66.7539 - val_loss: 123.3251 - val_mae: 6.6166 - val_mse: 123.3251\n",
      "Epoch 871/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 65.2181 - mae: 4.6931 - mse: 65.2181 - val_loss: 118.9236 - val_mae: 6.2578 - val_mse: 118.9236\n",
      "Epoch 872/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 69.0867 - mae: 4.8244 - mse: 69.0867 - val_loss: 117.4260 - val_mae: 6.3583 - val_mse: 117.4260\n",
      "Epoch 873/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.6255 - mae: 4.7246 - mse: 66.6255 - val_loss: 109.6044 - val_mae: 6.1244 - val_mse: 109.6044\n",
      "Epoch 874/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 65.3079 - mae: 4.6658 - mse: 65.3079 - val_loss: 119.6089 - val_mae: 6.5874 - val_mse: 119.6089\n",
      "Epoch 875/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.0266 - mae: 4.4205 - mse: 60.0266 - val_loss: 120.2859 - val_mae: 6.3558 - val_mse: 120.2859\n",
      "Epoch 876/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.7161 - mae: 4.6432 - mse: 66.7161 - val_loss: 129.0740 - val_mae: 6.7486 - val_mse: 129.0740\n",
      "Epoch 877/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.8772 - mae: 4.5503 - mse: 63.8772 - val_loss: 110.9302 - val_mae: 6.1282 - val_mse: 110.9302\n",
      "Epoch 878/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 56.4310 - mae: 4.2423 - mse: 56.4310 - val_loss: 113.6376 - val_mae: 6.2875 - val_mse: 113.6376\n",
      "Epoch 879/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 63.3391 - mae: 4.5100 - mse: 63.3391 - val_loss: 127.0169 - val_mae: 6.4548 - val_mse: 127.0169\n",
      "Epoch 880/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 62.9303 - mae: 4.5205 - mse: 62.9303 - val_loss: 125.3312 - val_mae: 6.4231 - val_mse: 125.3312\n",
      "Epoch 881/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.5851 - mae: 4.5145 - mse: 63.5851 - val_loss: 112.8120 - val_mae: 6.1611 - val_mse: 112.8120\n",
      "Epoch 882/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 55.1685 - mae: 4.1725 - mse: 55.1685 - val_loss: 126.2945 - val_mae: 6.3026 - val_mse: 126.2945\n",
      "Epoch 883/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 69.9052 - mae: 4.7041 - mse: 69.9052 - val_loss: 120.9708 - val_mae: 6.3775 - val_mse: 120.9708\n",
      "Epoch 884/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.9188 - mae: 4.8845 - mse: 71.9188 - val_loss: 124.3045 - val_mae: 6.5470 - val_mse: 124.3045\n",
      "Epoch 885/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.6510 - mae: 4.9710 - mse: 74.6510 - val_loss: 113.1330 - val_mae: 6.1596 - val_mse: 113.1330\n",
      "Epoch 886/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 75.4018 - mae: 5.0445 - mse: 75.4018 - val_loss: 116.7620 - val_mae: 6.4204 - val_mse: 116.7620\n",
      "Epoch 887/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.1264 - mae: 4.5916 - mse: 66.1264 - val_loss: 126.6163 - val_mae: 6.7601 - val_mse: 126.6163\n",
      "Epoch 888/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.8240 - mae: 4.4914 - mse: 63.8240 - val_loss: 117.4683 - val_mae: 6.2769 - val_mse: 117.4683\n",
      "Epoch 889/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 59.5694 - mae: 4.4587 - mse: 59.5694 - val_loss: 110.1358 - val_mae: 6.2069 - val_mse: 110.1358\n",
      "Epoch 890/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.4499 - mae: 4.7303 - mse: 64.4499 - val_loss: 131.0019 - val_mae: 6.9731 - val_mse: 131.0018\n",
      "Epoch 891/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 62.3965 - mae: 4.6490 - mse: 62.3965 - val_loss: 130.7821 - val_mae: 6.5582 - val_mse: 130.7821\n",
      "Epoch 892/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 55.7737 - mae: 4.2598 - mse: 55.7737 - val_loss: 118.3814 - val_mae: 6.4953 - val_mse: 118.3814\n",
      "Epoch 893/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 53.3244 - mae: 4.1117 - mse: 53.3244 - val_loss: 105.6679 - val_mae: 6.0243 - val_mse: 105.6679\n",
      "Epoch 894/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 51.1910 - mae: 3.9971 - mse: 51.1910 - val_loss: 130.5049 - val_mae: 6.8732 - val_mse: 130.5049\n",
      "Epoch 895/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 57.5335 - mae: 4.2778 - mse: 57.5335 - val_loss: 112.6348 - val_mae: 6.2285 - val_mse: 112.6348\n",
      "Epoch 896/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 68.0931 - mae: 4.6529 - mse: 68.0931 - val_loss: 113.3112 - val_mae: 6.3966 - val_mse: 113.3112\n",
      "Epoch 897/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 60.7271 - mae: 4.5121 - mse: 60.7271 - val_loss: 112.5337 - val_mae: 6.2522 - val_mse: 112.5337\n",
      "Epoch 898/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 77.0230 - mae: 5.0667 - mse: 77.0230 - val_loss: 117.8485 - val_mae: 6.5154 - val_mse: 117.8485\n",
      "Epoch 899/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.7117 - mae: 4.8044 - mse: 69.7117 - val_loss: 110.6171 - val_mae: 6.1517 - val_mse: 110.6171\n",
      "Epoch 900/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 59.2440 - mae: 4.3666 - mse: 59.2440 - val_loss: 130.8271 - val_mae: 6.6105 - val_mse: 130.8271\n",
      "Epoch 901/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.4725 - mae: 4.6937 - mse: 69.4725 - val_loss: 119.8065 - val_mae: 6.3537 - val_mse: 119.8065\n",
      "Epoch 902/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 60.5951 - mae: 4.3585 - mse: 60.5951 - val_loss: 108.0641 - val_mae: 5.9895 - val_mse: 108.0641\n",
      "Epoch 903/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 57.8735 - mae: 4.3004 - mse: 57.8735 - val_loss: 106.1142 - val_mae: 5.9497 - val_mse: 106.1142\n",
      "Epoch 904/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.3846 - mae: 4.5032 - mse: 66.3846 - val_loss: 155.3609 - val_mae: 6.9750 - val_mse: 155.3609\n",
      "Epoch 905/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 93.2380 - mae: 5.5004 - mse: 93.2380 - val_loss: 123.0131 - val_mae: 6.4625 - val_mse: 123.0131\n",
      "Epoch 906/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 60.1072 - mae: 4.4016 - mse: 60.1072 - val_loss: 108.8804 - val_mae: 6.0565 - val_mse: 108.8804\n",
      "Epoch 907/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 52.9918 - mae: 4.0657 - mse: 52.9918 - val_loss: 116.5389 - val_mae: 6.0874 - val_mse: 116.5389\n",
      "Epoch 908/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.4646 - mae: 4.3107 - mse: 61.4646 - val_loss: 117.1098 - val_mae: 6.2207 - val_mse: 117.1098\n",
      "Epoch 909/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 53.8422 - mae: 4.0741 - mse: 53.8422 - val_loss: 105.2790 - val_mae: 6.0479 - val_mse: 105.2790\n",
      "Epoch 910/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 55.3857 - mae: 4.2008 - mse: 55.3857 - val_loss: 110.6679 - val_mae: 6.1471 - val_mse: 110.6679\n",
      "Epoch 911/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 58.0618 - mae: 4.2193 - mse: 58.0618 - val_loss: 133.3709 - val_mae: 6.8475 - val_mse: 133.3709\n",
      "Epoch 912/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 72.8022 - mae: 4.7972 - mse: 72.8021 - val_loss: 126.0332 - val_mae: 6.4440 - val_mse: 126.0332\n",
      "Epoch 913/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.9895 - mae: 4.5320 - mse: 64.9895 - val_loss: 119.6260 - val_mae: 6.5137 - val_mse: 119.6260\n",
      "Epoch 914/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 57.6295 - mae: 4.2550 - mse: 57.6295 - val_loss: 112.8601 - val_mae: 6.1016 - val_mse: 112.8601\n",
      "Epoch 915/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 51.3374 - mae: 3.9686 - mse: 51.3374 - val_loss: 109.9413 - val_mae: 5.8791 - val_mse: 109.9413\n",
      "Epoch 916/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 52.8000 - mae: 3.9806 - mse: 52.8000 - val_loss: 121.8655 - val_mae: 6.5344 - val_mse: 121.8655\n",
      "Epoch 917/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 70.6312 - mae: 4.6410 - mse: 70.6312 - val_loss: 119.5551 - val_mae: 6.4242 - val_mse: 119.5551\n",
      "Epoch 918/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 70.4959 - mae: 4.7243 - mse: 70.4959 - val_loss: 140.5974 - val_mae: 7.0010 - val_mse: 140.5974\n",
      "Epoch 919/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 77.3351 - mae: 5.0173 - mse: 77.3351 - val_loss: 112.7930 - val_mae: 6.4591 - val_mse: 112.7930\n",
      "Epoch 920/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.7189 - mae: 4.6177 - mse: 64.7189 - val_loss: 123.1431 - val_mae: 6.6379 - val_mse: 123.1431\n",
      "Epoch 921/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 88.2747 - mae: 5.3648 - mse: 88.2747 - val_loss: 129.1475 - val_mae: 6.9100 - val_mse: 129.1475\n",
      "Epoch 922/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 86.6624 - mae: 5.4005 - mse: 86.6624 - val_loss: 133.1211 - val_mae: 6.9088 - val_mse: 133.1212\n",
      "Epoch 923/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 75.6875 - mae: 5.1157 - mse: 75.6875 - val_loss: 124.1717 - val_mae: 6.4076 - val_mse: 124.1717\n",
      "Epoch 924/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.8320 - mae: 4.4900 - mse: 60.8320 - val_loss: 112.8980 - val_mae: 6.1239 - val_mse: 112.8980\n",
      "Epoch 925/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 70.7513 - mae: 4.7438 - mse: 70.7513 - val_loss: 119.0790 - val_mae: 6.7708 - val_mse: 119.0790\n",
      "Epoch 926/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.3340 - mae: 4.6716 - mse: 64.3340 - val_loss: 116.6625 - val_mae: 6.3722 - val_mse: 116.6625\n",
      "Epoch 927/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 58.7747 - mae: 4.3816 - mse: 58.7747 - val_loss: 108.4883 - val_mae: 6.0071 - val_mse: 108.4883\n",
      "Epoch 928/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 57.3744 - mae: 4.3467 - mse: 57.3744 - val_loss: 109.5251 - val_mae: 6.1817 - val_mse: 109.5251\n",
      "Epoch 929/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 58.4688 - mae: 4.2373 - mse: 58.4688 - val_loss: 113.3101 - val_mae: 6.0606 - val_mse: 113.3101\n",
      "Epoch 930/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.9289 - mae: 4.4995 - mse: 63.9289 - val_loss: 121.2102 - val_mae: 6.3563 - val_mse: 121.2103\n",
      "Epoch 931/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 65.0689 - mae: 4.6205 - mse: 65.0689 - val_loss: 113.5844 - val_mae: 6.0708 - val_mse: 113.5844\n",
      "Epoch 932/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 59.3522 - mae: 4.4017 - mse: 59.3522 - val_loss: 155.4215 - val_mae: 7.1289 - val_mse: 155.4215\n",
      "Epoch 933/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 81.6184 - mae: 5.2269 - mse: 81.6184 - val_loss: 136.9259 - val_mae: 6.9742 - val_mse: 136.9259\n",
      "Epoch 934/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 66.1380 - mae: 4.6526 - mse: 66.1380 - val_loss: 113.3305 - val_mae: 6.1568 - val_mse: 113.3305\n",
      "Epoch 935/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.6248 - mae: 4.4185 - mse: 61.6248 - val_loss: 109.7686 - val_mae: 6.2692 - val_mse: 109.7686\n",
      "Epoch 936/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.5080 - mae: 4.4177 - mse: 61.5080 - val_loss: 119.7366 - val_mae: 6.4475 - val_mse: 119.7366\n",
      "Epoch 937/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 64.6020 - mae: 4.5254 - mse: 64.6020 - val_loss: 115.2355 - val_mae: 6.2764 - val_mse: 115.2355\n",
      "Epoch 938/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 73.6114 - mae: 4.7911 - mse: 73.6114 - val_loss: 130.2593 - val_mae: 6.7053 - val_mse: 130.2593\n",
      "Epoch 939/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 68.2095 - mae: 4.7333 - mse: 68.2095 - val_loss: 117.7365 - val_mae: 6.4208 - val_mse: 117.7365\n",
      "Epoch 940/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.0569 - mae: 4.3785 - mse: 60.0569 - val_loss: 115.3945 - val_mae: 6.0923 - val_mse: 115.3945\n",
      "Epoch 941/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 62.5871 - mae: 4.4937 - mse: 62.5871 - val_loss: 159.1802 - val_mae: 7.0643 - val_mse: 159.1801\n",
      "Epoch 942/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 94.9016 - mae: 5.6028 - mse: 94.9016 - val_loss: 120.9577 - val_mae: 6.6676 - val_mse: 120.9577\n",
      "Epoch 943/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 62.3279 - mae: 4.5565 - mse: 62.3279 - val_loss: 110.6568 - val_mae: 6.0720 - val_mse: 110.6568\n",
      "Epoch 944/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.7542 - mae: 4.6162 - mse: 64.7542 - val_loss: 129.6470 - val_mae: 6.6805 - val_mse: 129.6470\n",
      "Epoch 945/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.8613 - mae: 4.4552 - mse: 60.8613 - val_loss: 113.4428 - val_mae: 6.3569 - val_mse: 113.4428\n",
      "Epoch 946/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 53.2712 - mae: 4.1006 - mse: 53.2712 - val_loss: 108.5587 - val_mae: 5.8819 - val_mse: 108.5587\n",
      "Epoch 947/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 53.5646 - mae: 4.0638 - mse: 53.5646 - val_loss: 111.8641 - val_mae: 6.1427 - val_mse: 111.8641\n",
      "Epoch 948/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 52.7493 - mae: 4.0136 - mse: 52.7493 - val_loss: 114.3707 - val_mae: 6.2102 - val_mse: 114.3707\n",
      "Epoch 949/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 56.9207 - mae: 4.1793 - mse: 56.9207 - val_loss: 111.3692 - val_mae: 5.9544 - val_mse: 111.3692\n",
      "Epoch 950/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 52.8317 - mae: 4.0576 - mse: 52.8317 - val_loss: 111.6944 - val_mae: 6.1242 - val_mse: 111.6944\n",
      "Epoch 951/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 55.8802 - mae: 4.1237 - mse: 55.8802 - val_loss: 130.1087 - val_mae: 6.6570 - val_mse: 130.1087\n",
      "Epoch 952/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 65.7221 - mae: 4.6074 - mse: 65.7220 - val_loss: 119.2229 - val_mae: 6.3176 - val_mse: 119.2229\n",
      "Epoch 953/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 72.7293 - mae: 4.8024 - mse: 72.7293 - val_loss: 125.1116 - val_mae: 6.3360 - val_mse: 125.1116\n",
      "Epoch 954/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.3086 - mae: 4.4415 - mse: 61.3086 - val_loss: 115.1474 - val_mae: 6.0991 - val_mse: 115.1474\n",
      "Epoch 955/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 54.3896 - mae: 4.1367 - mse: 54.3896 - val_loss: 109.2836 - val_mae: 5.8723 - val_mse: 109.2836\n",
      "Epoch 956/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.1324 - mae: 4.3267 - mse: 61.1324 - val_loss: 114.7836 - val_mae: 6.2845 - val_mse: 114.7836\n",
      "Epoch 957/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 67.3640 - mae: 4.6451 - mse: 67.3640 - val_loss: 109.8883 - val_mae: 6.0005 - val_mse: 109.8883\n",
      "Epoch 958/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 74.3630 - mae: 4.8493 - mse: 74.3630 - val_loss: 118.3933 - val_mae: 6.1096 - val_mse: 118.3933\n",
      "Epoch 959/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 61.5419 - mae: 4.4185 - mse: 61.5419 - val_loss: 111.1110 - val_mae: 5.9468 - val_mse: 111.1110\n",
      "Epoch 960/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 54.4928 - mae: 4.1282 - mse: 54.4928 - val_loss: 116.3807 - val_mae: 6.4700 - val_mse: 116.3806\n",
      "Epoch 961/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 68.2932 - mae: 4.6099 - mse: 68.2932 - val_loss: 121.8442 - val_mae: 6.3997 - val_mse: 121.8442\n",
      "Epoch 962/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 72.1766 - mae: 4.7706 - mse: 72.1766 - val_loss: 113.5119 - val_mae: 6.0655 - val_mse: 113.5119\n",
      "Epoch 963/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 57.2340 - mae: 4.2278 - mse: 57.2340 - val_loss: 108.4643 - val_mae: 6.0121 - val_mse: 108.4643\n",
      "Epoch 964/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 54.1934 - mae: 4.0752 - mse: 54.1934 - val_loss: 127.8791 - val_mae: 6.8628 - val_mse: 127.8791\n",
      "Epoch 965/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 55.1612 - mae: 4.1056 - mse: 55.1612 - val_loss: 114.5383 - val_mae: 5.9987 - val_mse: 114.5383\n",
      "Epoch 966/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 70.8517 - mae: 4.7242 - mse: 70.8517 - val_loss: 139.6941 - val_mae: 7.0971 - val_mse: 139.6942\n",
      "Epoch 967/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 89.5988 - mae: 5.4306 - mse: 89.5987 - val_loss: 114.6496 - val_mae: 6.3378 - val_mse: 114.6496\n",
      "Epoch 968/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.0073 - mae: 4.7860 - mse: 69.0073 - val_loss: 119.7044 - val_mae: 6.3553 - val_mse: 119.7044\n",
      "Epoch 969/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.8121 - mae: 4.7125 - mse: 66.8121 - val_loss: 112.2572 - val_mae: 6.2199 - val_mse: 112.2572\n",
      "Epoch 970/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 57.0522 - mae: 4.3494 - mse: 57.0522 - val_loss: 111.6164 - val_mae: 6.0747 - val_mse: 111.6164\n",
      "Epoch 971/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 57.0850 - mae: 4.2858 - mse: 57.0850 - val_loss: 105.3256 - val_mae: 5.9378 - val_mse: 105.3256\n",
      "Epoch 972/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 53.2769 - mae: 4.1500 - mse: 53.2769 - val_loss: 113.1130 - val_mae: 6.1190 - val_mse: 113.1130\n",
      "Epoch 973/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.8331 - mae: 4.7900 - mse: 71.8331 - val_loss: 117.6170 - val_mae: 6.6154 - val_mse: 117.6170\n",
      "Epoch 974/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 90.1802 - mae: 5.4845 - mse: 90.1802 - val_loss: 122.5004 - val_mae: 6.5735 - val_mse: 122.5004\n",
      "Epoch 975/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 69.1372 - mae: 4.8973 - mse: 69.1373 - val_loss: 122.0153 - val_mae: 6.5279 - val_mse: 122.0153\n",
      "Epoch 976/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 60.7343 - mae: 4.4845 - mse: 60.7343 - val_loss: 127.3860 - val_mae: 6.5149 - val_mse: 127.3860\n",
      "Epoch 977/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 67.6466 - mae: 4.7303 - mse: 67.6466 - val_loss: 118.0377 - val_mae: 6.4438 - val_mse: 118.0377\n",
      "Epoch 978/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 66.5860 - mae: 4.6803 - mse: 66.5860 - val_loss: 138.6953 - val_mae: 6.6507 - val_mse: 138.6953\n",
      "Epoch 979/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 59.9113 - mae: 4.4036 - mse: 59.9113 - val_loss: 112.2004 - val_mae: 6.0540 - val_mse: 112.2004\n",
      "Epoch 980/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 57.1520 - mae: 4.3019 - mse: 57.1520 - val_loss: 108.7875 - val_mae: 6.0521 - val_mse: 108.7875\n",
      "Epoch 981/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 52.6378 - mae: 4.1163 - mse: 52.6378 - val_loss: 110.8016 - val_mae: 6.1365 - val_mse: 110.8016\n",
      "Epoch 982/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 53.9198 - mae: 4.1247 - mse: 53.9198 - val_loss: 106.4855 - val_mae: 5.9691 - val_mse: 106.4855\n",
      "Epoch 983/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 53.8609 - mae: 4.1045 - mse: 53.8609 - val_loss: 120.1149 - val_mae: 6.2446 - val_mse: 120.1149\n",
      "Epoch 984/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.4135 - mae: 4.5675 - mse: 64.4135 - val_loss: 113.2335 - val_mae: 6.1217 - val_mse: 113.2335\n",
      "Epoch 985/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 59.0781 - mae: 4.3034 - mse: 59.0781 - val_loss: 106.1502 - val_mae: 6.0691 - val_mse: 106.1502\n",
      "Epoch 986/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 62.5753 - mae: 4.4722 - mse: 62.5753 - val_loss: 112.0853 - val_mae: 6.1989 - val_mse: 112.0853\n",
      "Epoch 987/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 59.1040 - mae: 4.3287 - mse: 59.1040 - val_loss: 111.3980 - val_mae: 6.1154 - val_mse: 111.3980\n",
      "Epoch 988/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 58.1287 - mae: 4.2681 - mse: 58.1287 - val_loss: 116.2289 - val_mae: 6.1585 - val_mse: 116.2290\n",
      "Epoch 989/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 56.2888 - mae: 4.2096 - mse: 56.2888 - val_loss: 133.7474 - val_mae: 6.6691 - val_mse: 133.7474\n",
      "Epoch 990/1000\n",
      "17010/17010 [==============================] - 1s 80us/sample - loss: 78.5256 - mae: 4.9610 - mse: 78.5256 - val_loss: 131.8742 - val_mae: 7.0760 - val_mse: 131.8742\n",
      "Epoch 991/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 72.7245 - mae: 4.8836 - mse: 72.7245 - val_loss: 112.2433 - val_mae: 6.3808 - val_mse: 112.2433\n",
      "Epoch 992/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.6764 - mae: 4.5843 - mse: 64.6764 - val_loss: 124.8945 - val_mae: 6.8585 - val_mse: 124.8945\n",
      "Epoch 993/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 63.6692 - mae: 4.6357 - mse: 63.6692 - val_loss: 120.5388 - val_mae: 6.6900 - val_mse: 120.5388\n",
      "Epoch 994/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 65.6758 - mae: 4.9799 - mse: 65.6758 - val_loss: 122.4002 - val_mae: 6.7539 - val_mse: 122.4002\n",
      "Epoch 995/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 64.2265 - mae: 4.8241 - mse: 64.2265 - val_loss: 125.6213 - val_mae: 6.5907 - val_mse: 125.6213\n",
      "Epoch 996/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 67.2909 - mae: 4.9436 - mse: 67.2909 - val_loss: 123.1660 - val_mae: 6.4196 - val_mse: 123.1660\n",
      "Epoch 997/1000\n",
      "17010/17010 [==============================] - 1s 82us/sample - loss: 67.7061 - mae: 4.8955 - mse: 67.7061 - val_loss: 125.0871 - val_mae: 6.5355 - val_mse: 125.0871\n",
      "Epoch 998/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 68.6086 - mae: 4.8941 - mse: 68.6086 - val_loss: 128.5661 - val_mae: 6.5814 - val_mse: 128.5662\n",
      "Epoch 999/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 71.1295 - mae: 4.9930 - mse: 71.1295 - val_loss: 111.4956 - val_mae: 6.2201 - val_mse: 111.4956\n",
      "Epoch 1000/1000\n",
      "17010/17010 [==============================] - 1s 81us/sample - loss: 63.0109 - mae: 4.6616 - mse: 63.0109 - val_loss: 117.0583 - val_mae: 6.2922 - val_mse: 117.0583\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 59.0648\n",
      "Validation MSE: 117.0583\n",
      "\n",
      "Training r2: 0.9499\n",
      "Validation r2: 0.8983\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=512, validation_data=(X_test, y_test))\n",
    "pd.DataFrame(history.history).plot(figsize=(15,7))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('metric value')\n",
    "# plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "deep_learning_model_evaluation(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=10, n_neurons=300, learning_rate=3e-3, input_shape=(X_train.shape[1],)):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17010 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "17010/17010 [==============================] - 4s 224us/sample - loss: 2221.9089 - val_loss: 415.3903\n",
      "Epoch 2/100\n",
      "17010/17010 [==============================] - 3s 182us/sample - loss: 371.0852 - val_loss: 359.6949\n",
      "Epoch 3/100\n",
      "17010/17010 [==============================] - 3s 186us/sample - loss: 345.3933 - val_loss: 435.0678\n",
      "Epoch 4/100\n",
      "17010/17010 [==============================] - 3s 171us/sample - loss: 326.6795 - val_loss: 349.5377\n",
      "Epoch 5/100\n",
      "17010/17010 [==============================] - 3s 180us/sample - loss: 323.2804 - val_loss: 323.5485\n",
      "Epoch 6/100\n",
      "17010/17010 [==============================] - 3s 178us/sample - loss: 321.3426 - val_loss: 260.5724\n",
      "Epoch 7/100\n",
      "17010/17010 [==============================] - 3s 190us/sample - loss: 313.5590 - val_loss: 250.0590\n",
      "Epoch 8/100\n",
      "17010/17010 [==============================] - 3s 189us/sample - loss: 291.0426 - val_loss: 253.3674\n",
      "Epoch 9/100\n",
      "17010/17010 [==============================] - 3s 179us/sample - loss: 304.5391 - val_loss: 257.5922\n",
      "Epoch 10/100\n",
      "17010/17010 [==============================] - 3s 187us/sample - loss: 311.3054 - val_loss: 257.5978\n",
      "Epoch 11/100\n",
      "17010/17010 [==============================] - 3s 191us/sample - loss: 309.9020 - val_loss: 318.9249\n",
      "Epoch 12/100\n",
      "17010/17010 [==============================] - 3s 185us/sample - loss: 302.7682 - val_loss: 248.9326\n",
      "Epoch 13/100\n",
      "17010/17010 [==============================] - 3s 190us/sample - loss: 288.7150 - val_loss: 351.0924\n",
      "Epoch 14/100\n",
      "17010/17010 [==============================] - 3s 191us/sample - loss: 293.7663 - val_loss: 232.1955\n",
      "Epoch 15/100\n",
      "17010/17010 [==============================] - 3s 187us/sample - loss: 283.2512 - val_loss: 246.7392\n",
      "Epoch 16/100\n",
      "17010/17010 [==============================] - 3s 183us/sample - loss: 292.0801 - val_loss: 253.7333\n",
      "Epoch 17/100\n",
      "17010/17010 [==============================] - 3s 176us/sample - loss: 278.5929 - val_loss: 309.2967\n",
      "Epoch 18/100\n",
      "17010/17010 [==============================] - 3s 190us/sample - loss: 275.6973 - val_loss: 231.5493\n",
      "Epoch 19/100\n",
      "17010/17010 [==============================] - 3s 175us/sample - loss: 277.3993 - val_loss: 234.1971\n",
      "Epoch 20/100\n",
      "17010/17010 [==============================] - 3s 192us/sample - loss: 281.8134 - val_loss: 337.6768\n",
      "Epoch 21/100\n",
      "17010/17010 [==============================] - 3s 189us/sample - loss: 267.6965 - val_loss: 234.9066\n",
      "Epoch 22/100\n",
      "17010/17010 [==============================] - 3s 184us/sample - loss: 283.6497 - val_loss: 264.2627\n",
      "Epoch 23/100\n",
      "17010/17010 [==============================] - 3s 188us/sample - loss: 281.2740 - val_loss: 247.4170\n",
      "Epoch 24/100\n",
      "17010/17010 [==============================] - 3s 191us/sample - loss: 273.1440 - val_loss: 236.2984\n",
      "Epoch 25/100\n",
      "17010/17010 [==============================] - 3s 191us/sample - loss: 356.2870 - val_loss: 256.0779\n",
      "Epoch 26/100\n",
      "17010/17010 [==============================] - 3s 187us/sample - loss: 309.9430 - val_loss: 238.0491\n",
      "Epoch 27/100\n",
      "17010/17010 [==============================] - 3s 170us/sample - loss: 274.4330 - val_loss: 228.7020\n",
      "Epoch 28/100\n",
      "17010/17010 [==============================] - 3s 175us/sample - loss: 349.4351 - val_loss: 245.8511\n",
      "Epoch 29/100\n",
      "17010/17010 [==============================] - 3s 175us/sample - loss: 460.7823 - val_loss: 406.3598\n",
      "Epoch 30/100\n",
      "17010/17010 [==============================] - 3s 176us/sample - loss: 361.9502 - val_loss: 278.7807\n",
      "Epoch 31/100\n",
      "17010/17010 [==============================] - 3s 180us/sample - loss: 323.6765 - val_loss: 297.7401\n",
      "Epoch 32/100\n",
      "17010/17010 [==============================] - 3s 177us/sample - loss: 300.6147 - val_loss: 289.8460\n",
      "Epoch 33/100\n",
      "17010/17010 [==============================] - 3s 181us/sample - loss: 288.0493 - val_loss: 257.8880\n",
      "Epoch 34/100\n",
      "17010/17010 [==============================] - 3s 179us/sample - loss: 274.7928 - val_loss: 241.2247\n",
      "Epoch 35/100\n",
      "17010/17010 [==============================] - 3s 175us/sample - loss: 273.0528 - val_loss: 236.1819\n",
      "Epoch 36/100\n",
      "17010/17010 [==============================] - 3s 174us/sample - loss: 280.3489 - val_loss: 243.2399\n",
      "Epoch 37/100\n",
      "17010/17010 [==============================] - 3s 179us/sample - loss: 270.9338 - val_loss: 252.0070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4a71cc9c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_test, y_test),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4253/4253 [==============================] - 0s 67us/sample - loss: 252.0070\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_neurons=77, n_hidden=1 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11340/11340 [==============================] - 1s 132us/sample - loss: 23525.8898 - val_loss: 1091.6132\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 972.2594 - val_loss: 891.4482\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 1023.8146 - val_loss: 1112.6091\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 965.5811 - val_loss: 649.1529\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 1221.8863 - val_loss: 404.9304\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 923.5230 - val_loss: 9680.9478\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 1125.1898 - val_loss: 693.2957\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 870.8791 - val_loss: 456.7404\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 1314.9297 - val_loss: 32013.5776\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 3631.6747 - val_loss: 469.0937\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 520.4034 - val_loss: 380.7971\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 576.4984 - val_loss: 760.8710\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 593.0367 - val_loss: 2925.4895\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 749.3978 - val_loss: 409.7852\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 495.3113 - val_loss: 1061.8930\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 760.5415 - val_loss: 547.7157\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 620.9935 - val_loss: 5021.0711\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 611.9879 - val_loss: 1044.1812\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 508.5424 - val_loss: 402.3025\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 700.1046 - val_loss: 796.1857\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 540.5980 - val_loss: 277.5645\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 495.8097 - val_loss: 306.8872\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 441.3128 - val_loss: 358.0449\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 462.4600 - val_loss: 355.7671\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 91us/sample - loss: 412.4246 - val_loss: 299.2291\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 402.4881 - val_loss: 378.0011\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 403.4313 - val_loss: 382.0873\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 455.2636 - val_loss: 297.0549\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 341.0887 - val_loss: 631.4725\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 359.5582 - val_loss: 291.5930\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 352.4596 - val_loss: 295.6947\n",
      "5670/5670 [==============================] - 0s 43us/sample - loss: 323.3536\n",
      "[CV] ......................... n_neurons=77, n_hidden=1, total=  34.3s\n",
      "[CV] n_neurons=77, n_hidden=1 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11340/11340 [==============================] - 2s 132us/sample - loss: 13236.8181 - val_loss: 1310.4629\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 941.2825 - val_loss: 637.2288\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 732.6081 - val_loss: 638.5463\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 1008.0069 - val_loss: 2974.8878\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 1030.5471 - val_loss: 338.7346\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 677.3443 - val_loss: 987.1284\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 1249.0066 - val_loss: 1790.7336\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 695.8595 - val_loss: 843.3962\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 611.5543 - val_loss: 588.5865\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 862.5484 - val_loss: 1134.5310\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 656.9010 - val_loss: 321.2573\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 585.4996 - val_loss: 594.1723\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 510.2788 - val_loss: 335.2859\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 92us/sample - loss: 605.7853 - val_loss: 1620.1203\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 582.1698 - val_loss: 478.4821\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 577.2625 - val_loss: 610.3479\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 454.7391 - val_loss: 300.6950\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 564.4166 - val_loss: 815.2843\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 411.2799 - val_loss: 309.0299\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 418.7695 - val_loss: 385.5862\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 487.2953 - val_loss: 270.2900\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 354.7072 - val_loss: 843.2699\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 415.4885 - val_loss: 285.4415\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 345.7855 - val_loss: 437.5736\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 474.1554 - val_loss: 448.1277\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 336.5103 - val_loss: 439.4370\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 328.2629 - val_loss: 351.5489\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 323.1430 - val_loss: 263.0780\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 312.8373 - val_loss: 269.6750\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 307.1006 - val_loss: 478.5487\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 307.1498 - val_loss: 242.0087\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 304.6207 - val_loss: 276.2168\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 330.2472 - val_loss: 348.8626\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 309.0495 - val_loss: 294.1295\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 289.5716 - val_loss: 527.7253\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 299.6022 - val_loss: 256.7703\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 322.0768 - val_loss: 255.6713\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 298.1046 - val_loss: 257.0676\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 299.1373 - val_loss: 252.0700\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 282.1940 - val_loss: 406.1943\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 296.1246 - val_loss: 262.6074\n",
      "5670/5670 [==============================] - 0s 43us/sample - loss: 304.3034\n",
      "[CV] ......................... n_neurons=77, n_hidden=1, total=  45.5s\n",
      "[CV] n_neurons=77, n_hidden=1 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 1s 128us/sample - loss: 10412.8524 - val_loss: 1012.0234\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 1439.1596 - val_loss: 2021.0005\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 1505.3159 - val_loss: 833.2842\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 2783.9195 - val_loss: 5269.8752\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 890.6215 - val_loss: 994.8214\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 972.7967 - val_loss: 469.6623\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 810.7342 - val_loss: 409.8144\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 1049.7032 - val_loss: 464.5304\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 749.1609 - val_loss: 2225.7489\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 1925.5825 - val_loss: 1464.9967\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 603.5896 - val_loss: 1216.4803\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 659.5529 - val_loss: 334.9846\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 636.9037 - val_loss: 311.9352\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 1654.6213 - val_loss: 306.5161\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 451.5009 - val_loss: 430.1591\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 442.2396 - val_loss: 487.7517\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 725.5882 - val_loss: 1183.8671\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 558.0096 - val_loss: 679.2249\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 586.1117 - val_loss: 380.5961\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 657.3935 - val_loss: 1017.4784\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 392.3262 - val_loss: 269.5297\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 543.8566 - val_loss: 665.3096\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 441.6173 - val_loss: 628.6775\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 660.2437 - val_loss: 310.6911\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 434.4957 - val_loss: 669.0049\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 360.6367 - val_loss: 535.1416\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 402.5463 - val_loss: 281.5237\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 419.4038 - val_loss: 454.0050\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 365.3562 - val_loss: 419.8719\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 400.7679 - val_loss: 300.9087\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 340.5399 - val_loss: 297.1776\n",
      "5670/5670 [==============================] - 0s 43us/sample - loss: 312.4052\n",
      "[CV] ......................... n_neurons=77, n_hidden=1, total=  35.3s\n",
      "[CV] n_neurons=31, n_hidden=3 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 156us/sample - loss: 3214.4702 - val_loss: 569.1922\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 123us/sample - loss: 573.0618 - val_loss: 427.7667\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 127us/sample - loss: 473.0973 - val_loss: 362.4871\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 400.0672 - val_loss: 541.3038\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 132us/sample - loss: 382.6235 - val_loss: 329.8470\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 2s 139us/sample - loss: 362.5470 - val_loss: 376.0456\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 2s 134us/sample - loss: 344.9469 - val_loss: 460.4333\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 343.9232 - val_loss: 316.2024\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 342.1557 - val_loss: 276.4719\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 321.1978 - val_loss: 267.3794\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 316.1102 - val_loss: 263.4249\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 2s 133us/sample - loss: 285.2293 - val_loss: 274.2029\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 2s 134us/sample - loss: 287.9681 - val_loss: 256.8983\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 2s 135us/sample - loss: 313.5413 - val_loss: 293.4174\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 291.6801 - val_loss: 457.9713\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 305.7990 - val_loss: 257.0520\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 303.4075 - val_loss: 239.5413\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 129us/sample - loss: 288.9397 - val_loss: 256.8968\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 2s 136us/sample - loss: 281.0105 - val_loss: 250.8239\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 126us/sample - loss: 322.1349 - val_loss: 287.8932\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 2s 150us/sample - loss: 291.5141 - val_loss: 270.4888\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 2s 135us/sample - loss: 295.4357 - val_loss: 288.2058\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 2s 136us/sample - loss: 287.9608 - val_loss: 263.3353\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 2s 147us/sample - loss: 288.1742 - val_loss: 256.4777\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 2s 142us/sample - loss: 284.5853 - val_loss: 324.5216\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 2s 141us/sample - loss: 271.3715 - val_loss: 249.9793\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 275.5284 - val_loss: 255.9115\n",
      "5670/5670 [==============================] - 0s 51us/sample - loss: 277.5317\n",
      "[CV] ......................... n_neurons=31, n_hidden=3, total=  39.9s\n",
      "[CV] n_neurons=31, n_hidden=3 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 193us/sample - loss: 3752.9427 - val_loss: 624.7717\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 130us/sample - loss: 603.7223 - val_loss: 479.8161\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 524.9187 - val_loss: 690.5407\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 468.9839 - val_loss: 342.0922\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 419.7512 - val_loss: 479.4411\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 380.5586 - val_loss: 316.1829\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 375.2857 - val_loss: 320.3147\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 371.2117 - val_loss: 322.2725\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 336.9860 - val_loss: 289.4035\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 340.8635 - val_loss: 277.5634\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 341.2645 - val_loss: 314.3653\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 322.0412 - val_loss: 367.9526\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 311.8892 - val_loss: 267.6401\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 346.8050 - val_loss: 276.2628\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 344.6418 - val_loss: 393.1526\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 318.5641 - val_loss: 397.0395\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 328.7067 - val_loss: 297.7372\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 311.2256 - val_loss: 266.4887\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 303.5935 - val_loss: 262.1746\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 288.5883 - val_loss: 237.2688\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 298.5475 - val_loss: 296.7342\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 278.6380 - val_loss: 310.2794\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 287.9671 - val_loss: 273.6645\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 296.7701 - val_loss: 257.8035\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 290.0023 - val_loss: 414.1152\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 128us/sample - loss: 285.8964 - val_loss: 235.5854\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 2s 148us/sample - loss: 279.7751 - val_loss: 432.3001\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 2s 134us/sample - loss: 268.4796 - val_loss: 253.5252\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 2s 134us/sample - loss: 279.2343 - val_loss: 250.1372\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 129us/sample - loss: 272.4894 - val_loss: 289.9325\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 286.4209 - val_loss: 260.5308\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 268.3190 - val_loss: 241.1362\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 2s 135us/sample - loss: 263.6811 - val_loss: 315.9934\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 123us/sample - loss: 277.8241 - val_loss: 252.1623\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 265.5716 - val_loss: 230.6637\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 2s 134us/sample - loss: 269.7646 - val_loss: 246.7530\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 2s 143us/sample - loss: 255.9757 - val_loss: 275.1627\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 125us/sample - loss: 274.7557 - val_loss: 270.5135\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 267.9148 - val_loss: 236.0628\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 257.6895 - val_loss: 230.5424\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 256.5527 - val_loss: 240.3389\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 251.1100 - val_loss: 231.2951\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 269.3077 - val_loss: 254.6865\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 128us/sample - loss: 259.6290 - val_loss: 230.8359\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 257.8600 - val_loss: 228.0304\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 258.7584 - val_loss: 225.0805\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 262.6603 - val_loss: 255.3157\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 256.2553 - val_loss: 261.9319\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 245.8333 - val_loss: 271.6503\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 241.7669 - val_loss: 219.9092\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 262.1060 - val_loss: 236.8280\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 130us/sample - loss: 254.8204 - val_loss: 218.2046\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 129us/sample - loss: 249.0036 - val_loss: 239.4990\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 2s 138us/sample - loss: 250.9436 - val_loss: 238.6872\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 257.0583 - val_loss: 223.6992\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 117us/sample - loss: 243.4369 - val_loss: 226.8765\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 240.8602 - val_loss: 240.4034\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 243.1975 - val_loss: 245.1567\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 246.8345 - val_loss: 229.8498\n",
      "Epoch 60/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 244.0358 - val_loss: 219.2430\n",
      "Epoch 61/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 243.8359 - val_loss: 227.9209\n",
      "Epoch 62/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 244.9129 - val_loss: 225.6956\n",
      "5670/5670 [==============================] - 0s 43us/sample - loss: 246.4101\n",
      "[CV] ......................... n_neurons=31, n_hidden=3, total= 1.4min\n",
      "[CV] n_neurons=31, n_hidden=3 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 147us/sample - loss: 3052.9138 - val_loss: 553.7943\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 480.7840 - val_loss: 427.4563\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 425.0798 - val_loss: 438.0405\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 369.9423 - val_loss: 452.5323\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 379.5728 - val_loss: 305.7667\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 366.8514 - val_loss: 632.5467\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 339.9972 - val_loss: 339.4544\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 355.2503 - val_loss: 291.5169\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 360.2609 - val_loss: 470.8888\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 322.8964 - val_loss: 260.8402\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 336.2100 - val_loss: 334.3725\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 320.0453 - val_loss: 477.9111\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 333.6525 - val_loss: 492.9053\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 319.6981 - val_loss: 317.0841\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 307.0573 - val_loss: 380.7890\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 319.7723 - val_loss: 267.8233\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 313.6572 - val_loss: 274.2981\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 312.6233 - val_loss: 298.1250\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 311.3379 - val_loss: 304.1212\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 304.0035 - val_loss: 311.7404\n",
      "5670/5670 [==============================] - 0s 51us/sample - loss: 331.0979\n",
      "[CV] ......................... n_neurons=31, n_hidden=3, total=  25.6s\n",
      "[CV] n_neurons=90, n_hidden=0 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 137us/sample - loss: 880280.0394 - val_loss: 33366.8020\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 15453.1539 - val_loss: 7664.7102\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 6139.4125 - val_loss: 4714.4761\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 91us/sample - loss: 4005.2571 - val_loss: 3118.7779\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 2821.8466 - val_loss: 2269.0740\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 2048.2072 - val_loss: 1736.6071\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 1553.2828 - val_loss: 1369.0353\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 1226.4311 - val_loss: 1089.8422\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 1000.6197 - val_loss: 871.7131\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 829.3292 - val_loss: 753.3094\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 721.0582 - val_loss: 689.3697\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 629.3054 - val_loss: 661.1147\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 81us/sample - loss: 579.0923 - val_loss: 515.0556\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 517.3965 - val_loss: 479.2491\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 91us/sample - loss: 492.0362 - val_loss: 468.6427\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 477.5432 - val_loss: 473.4145\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 466.8630 - val_loss: 487.5564\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 460.7114 - val_loss: 422.0882\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 447.1717 - val_loss: 432.9532\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 424.2416 - val_loss: 657.6019\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 435.8311 - val_loss: 430.7255\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 464.1855 - val_loss: 367.7050\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 477.5325 - val_loss: 449.4255\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 446.0683 - val_loss: 479.1742\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 516.6034 - val_loss: 472.8268\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 529.6346 - val_loss: 432.7884\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 461.2283 - val_loss: 559.5362\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 433.1411 - val_loss: 370.2196\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 514.4560 - val_loss: 434.5099\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 438.4214 - val_loss: 448.5816\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 457.8127 - val_loss: 379.1322\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 80us/sample - loss: 534.1154 - val_loss: 416.3786\n",
      "5670/5670 [==============================] - 0s 54us/sample - loss: 444.4216\n",
      "[CV] ......................... n_neurons=90, n_hidden=0, total=  34.0s\n",
      "[CV] n_neurons=90, n_hidden=0 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 397121.5363 - val_loss: 18690.5242\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 12842.7612 - val_loss: 8518.0208\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 7006.7672 - val_loss: 5046.6967\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 4392.8629 - val_loss: 3367.3703\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 3059.8118 - val_loss: 2574.4894\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 2239.4503 - val_loss: 1775.8489\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1681.4192 - val_loss: 1342.2329\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 1288.9061 - val_loss: 1051.2790\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 1005.6727 - val_loss: 887.3589\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 826.8921 - val_loss: 674.2304\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 686.3805 - val_loss: 796.9711\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 591.4466 - val_loss: 495.2591\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 531.7566 - val_loss: 504.3997\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 496.6727 - val_loss: 434.6042\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 475.2768 - val_loss: 398.0566\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 451.7609 - val_loss: 398.1198\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 444.1147 - val_loss: 372.2046\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 121us/sample - loss: 424.0155 - val_loss: 360.6622\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 487.1537 - val_loss: 366.7922\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 423.6097 - val_loss: 389.2433\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 423.3503 - val_loss: 387.9485\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 473.7894 - val_loss: 483.7588\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 431.8571 - val_loss: 351.7265\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 434.0201 - val_loss: 470.3144\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 434.5857 - val_loss: 498.1081\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 457.7393 - val_loss: 481.0902\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 78us/sample - loss: 636.7632 - val_loss: 321.8158\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 423.2643 - val_loss: 412.6314\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 91us/sample - loss: 444.8154 - val_loss: 349.3490\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 462.1433 - val_loss: 319.4743\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 374.5343 - val_loss: 332.6675\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 121us/sample - loss: 523.0902 - val_loss: 389.9533\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 460.2094 - val_loss: 537.3845\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 452.5797 - val_loss: 341.2799\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 409.5078 - val_loss: 947.2064\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 81us/sample - loss: 445.1562 - val_loss: 335.5666\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 79us/sample - loss: 410.5232 - val_loss: 421.9081\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 80us/sample - loss: 453.9662 - val_loss: 626.9311\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 465.1887 - val_loss: 327.0847\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 394.7359 - val_loss: 364.4987\n",
      "5670/5670 [==============================] - 0s 43us/sample - loss: 777.2397\n",
      "[CV] ......................... n_neurons=90, n_hidden=0, total=  46.1s\n",
      "[CV] n_neurons=90, n_hidden=0 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 1s 127us/sample - loss: 201561.5137 - val_loss: 21696.5003\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 12131.6731 - val_loss: 6550.8899\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 4934.1119 - val_loss: 3307.5987\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 2895.0090 - val_loss: 2110.4339\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 1922.0061 - val_loss: 1819.0776\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 1378.3504 - val_loss: 1073.2850\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 1047.2130 - val_loss: 879.7514\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 851.2733 - val_loss: 681.7830\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 80us/sample - loss: 729.7636 - val_loss: 729.8350\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 651.8896 - val_loss: 520.3054\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 583.5446 - val_loss: 471.0120\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 559.3433 - val_loss: 581.3485\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 503.4131 - val_loss: 433.6748\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 498.8717 - val_loss: 392.7787\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 467.3218 - val_loss: 409.7818\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 454.0364 - val_loss: 501.9258\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 480.0313 - val_loss: 401.8410\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 468.9991 - val_loss: 464.6218\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 496.8097 - val_loss: 485.8278\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 478.6096 - val_loss: 620.4337\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 94us/sample - loss: 476.0262 - val_loss: 469.8896\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 82us/sample - loss: 463.8569 - val_loss: 608.1057\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 493.5907 - val_loss: 468.4940\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 478.9029 - val_loss: 401.5189\n",
      "5670/5670 [==============================] - 0s 37us/sample - loss: 429.8789\n",
      "[CV] ......................... n_neurons=90, n_hidden=0, total=  25.2s\n",
      "[CV] n_neurons=39, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 187us/sample - loss: 2893.0025 - val_loss: 591.8094\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 120us/sample - loss: 630.9580 - val_loss: 692.4011\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 2s 133us/sample - loss: 586.1783 - val_loss: 2104.6097\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 583.6952 - val_loss: 581.2386\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 496.3145 - val_loss: 1320.8637\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 454.0894 - val_loss: 283.7053\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 411.2695 - val_loss: 290.4690\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 342.5224 - val_loss: 299.0293\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 340.1587 - val_loss: 303.5879\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 356.1316 - val_loss: 570.8612\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 337.0258 - val_loss: 309.6206\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 325.4758 - val_loss: 327.7710\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 311.8635 - val_loss: 302.0212\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 305.4650 - val_loss: 454.5437\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 295.7074 - val_loss: 281.5637\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 303.7782 - val_loss: 326.1276\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 307.5217 - val_loss: 250.3876\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 303.2198 - val_loss: 276.0862\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 287.3736 - val_loss: 246.2257\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 297.0586 - val_loss: 338.7295\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 307.7427 - val_loss: 367.7830\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 280.3271 - val_loss: 319.8854\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 296.1149 - val_loss: 401.6419\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 288.8447 - val_loss: 257.9332\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 299.7609 - val_loss: 250.4325\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 120us/sample - loss: 292.3294 - val_loss: 245.1741\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 270.3674 - val_loss: 265.6913\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 283.3302 - val_loss: 259.6960\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 277.2567 - val_loss: 249.9980\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 270.9428 - val_loss: 287.7195\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 2s 136us/sample - loss: 285.0598 - val_loss: 358.5195\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 277.9944 - val_loss: 244.2769\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 123us/sample - loss: 280.4257 - val_loss: 301.4025\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 130us/sample - loss: 285.6107 - val_loss: 256.5913\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 128us/sample - loss: 276.0282 - val_loss: 325.1194\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 117us/sample - loss: 265.7627 - val_loss: 257.5280\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 277.4914 - val_loss: 240.6286\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 2s 161us/sample - loss: 272.4626 - val_loss: 293.2793\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 2s 165us/sample - loss: 279.0555 - val_loss: 314.3291\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 126us/sample - loss: 270.8891 - val_loss: 263.1174\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 2s 137us/sample - loss: 272.3732 - val_loss: 228.6949\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 266.8036 - val_loss: 232.2195\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 274.0815 - val_loss: 226.2196\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 121us/sample - loss: 270.5650 - val_loss: 228.3186\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 270.2174 - val_loss: 243.9952\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 269.6360 - val_loss: 228.7469\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 282.0043 - val_loss: 349.0724\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 126us/sample - loss: 265.1569 - val_loss: 233.3533\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 272.2208 - val_loss: 238.2746\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 261.8192 - val_loss: 265.3878\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 262.5986 - val_loss: 241.4193\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 257.4231 - val_loss: 229.3267\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 258.0490 - val_loss: 229.5755\n",
      "5670/5670 [==============================] - 0s 55us/sample - loss: 247.7403\n",
      "[CV] ......................... n_neurons=39, n_hidden=2, total= 1.2min\n",
      "[CV] n_neurons=39, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 151us/sample - loss: 2284.5693 - val_loss: 737.3336\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 121us/sample - loss: 724.1902 - val_loss: 496.5824\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 127us/sample - loss: 577.8513 - val_loss: 654.4097\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 456.6816 - val_loss: 403.2667\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 429.6870 - val_loss: 710.1043\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 414.5638 - val_loss: 424.4443\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 371.3693 - val_loss: 309.5818\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 358.2090 - val_loss: 275.3398\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 331.9553 - val_loss: 294.7186\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 330.9646 - val_loss: 262.1658\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 318.2862 - val_loss: 280.8217\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 320.8145 - val_loss: 275.6151\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 297.7953 - val_loss: 289.7878\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 322.6840 - val_loss: 339.7207\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 306.2804 - val_loss: 276.7201\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 288.1585 - val_loss: 262.6320\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 286.0358 - val_loss: 248.9535\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 292.5823 - val_loss: 254.7531\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 314.0805 - val_loss: 264.3017\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 282.4889 - val_loss: 291.2398\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 311.8901 - val_loss: 468.7304\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 289.9739 - val_loss: 337.4438\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 291.0281 - val_loss: 269.5931\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 277.8036 - val_loss: 243.3734\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 294.2991 - val_loss: 321.3602\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 276.1374 - val_loss: 334.9000\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 287.6645 - val_loss: 248.1587\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 295.9988 - val_loss: 250.9862\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 272.6894 - val_loss: 239.2232\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 262.4871 - val_loss: 251.8605\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 272.4695 - val_loss: 263.5771\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 283.5591 - val_loss: 325.3618\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 279.5741 - val_loss: 286.1764\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 269.5384 - val_loss: 239.7200\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 265.8303 - val_loss: 303.7936\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 279.0945 - val_loss: 256.7896\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 276.5924 - val_loss: 240.6230\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 272.5982 - val_loss: 249.2859\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 264.2774 - val_loss: 245.0221\n",
      "5670/5670 [==============================] - 0s 48us/sample - loss: 270.1545\n",
      "[CV] ......................... n_neurons=39, n_hidden=2, total=  47.2s\n",
      "[CV] n_neurons=39, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 145us/sample - loss: 25865.3043 - val_loss: 687.4017\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 653.2278 - val_loss: 583.6792\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 552.2447 - val_loss: 704.0711\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 481.7091 - val_loss: 431.8000\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 443.6323 - val_loss: 411.9712\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 465.1144 - val_loss: 423.7316\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 467.9465 - val_loss: 342.2693\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 421.9258 - val_loss: 402.5184\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 420.6427 - val_loss: 310.6255\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 530.1928 - val_loss: 316.4920\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 427.7595 - val_loss: 419.9575\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 408.5558 - val_loss: 319.6910\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 412.2627 - val_loss: 478.3805\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 346.9236 - val_loss: 417.5212\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 377.7593 - val_loss: 283.6217\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 347.1275 - val_loss: 298.1245\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 369.1590 - val_loss: 316.0838\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 354.8076 - val_loss: 268.1956\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 358.8849 - val_loss: 305.3096\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 332.7465 - val_loss: 376.6859\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 347.5321 - val_loss: 362.7874\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 334.2255 - val_loss: 260.9046\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 304.9766 - val_loss: 346.5377\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 309.1831 - val_loss: 244.4826\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 315.8430 - val_loss: 351.0597\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 311.0701 - val_loss: 254.1845\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 293.5254 - val_loss: 255.0049\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 336.0847 - val_loss: 263.0498\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 120us/sample - loss: 323.0234 - val_loss: 281.9338\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 311.0125 - val_loss: 262.0574\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 298.1637 - val_loss: 266.8288\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 126us/sample - loss: 296.4538 - val_loss: 246.6729\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 291.1024 - val_loss: 255.8583\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 293.2814 - val_loss: 310.3437\n",
      "5670/5670 [==============================] - 0s 46us/sample - loss: 332.7129\n",
      "[CV] ......................... n_neurons=39, n_hidden=2, total=  41.1s\n",
      "[CV] n_neurons=2, n_hidden=2 .........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 145us/sample - loss: 6611.1639 - val_loss: 581.0868\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 485.2604 - val_loss: 424.3389\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 448.6724 - val_loss: 418.1476\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 429.6685 - val_loss: 446.7070\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 392.9822 - val_loss: 382.2845\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 382.1591 - val_loss: 374.3250\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 128us/sample - loss: 370.4526 - val_loss: 393.6944\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 353.7877 - val_loss: 338.1867\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 346.8707 - val_loss: 308.4581\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 335.8071 - val_loss: 301.2437\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 332.6510 - val_loss: 295.8264\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 331.5295 - val_loss: 295.1167\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 336.0515 - val_loss: 287.5188\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 323.8540 - val_loss: 314.1776\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 325.4254 - val_loss: 291.6074\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 322.1041 - val_loss: 313.1582\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 320.0992 - val_loss: 284.6986\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 309.2444 - val_loss: 305.6634\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 310.5291 - val_loss: 297.2255\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 316.0245 - val_loss: 297.0618\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 305.6805 - val_loss: 271.3984\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 310.5206 - val_loss: 310.7004\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 300.8198 - val_loss: 272.2323\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 300.4950 - val_loss: 293.0429\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 301.7564 - val_loss: 268.1848\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 297.8862 - val_loss: 268.7840\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 317.3356 - val_loss: 266.8592\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 298.0847 - val_loss: 288.9051\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 307.4399 - val_loss: 263.7840\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 308.0669 - val_loss: 273.7927\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 302.4552 - val_loss: 273.8818\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 300.3562 - val_loss: 299.6787\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 295.7306 - val_loss: 263.9082\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 300.2975 - val_loss: 272.3207\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 299.7645 - val_loss: 261.6617\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 298.4895 - val_loss: 289.2633\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 304.8638 - val_loss: 314.9588\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 292.9659 - val_loss: 265.8285\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 306.7396 - val_loss: 275.6407\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 297.3494 - val_loss: 279.7043\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 295.6120 - val_loss: 299.1648\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 294.7018 - val_loss: 269.4120\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 291.0203 - val_loss: 264.0017\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 287.5113 - val_loss: 262.6544\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 300.6910 - val_loss: 260.5832\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 295.0725 - val_loss: 289.9579\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 292.8017 - val_loss: 257.0837\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 303.4178 - val_loss: 275.0919\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 293.7524 - val_loss: 261.0797\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 297.3620 - val_loss: 257.8275\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 292.0172 - val_loss: 256.5646\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 293.4343 - val_loss: 258.2784\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 290.6085 - val_loss: 299.0070\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 298.6530 - val_loss: 287.4286\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 291.6264 - val_loss: 260.2713\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 287.8084 - val_loss: 306.3257\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 293.9839 - val_loss: 255.7714\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 286.2939 - val_loss: 260.4501\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 295.8370 - val_loss: 265.9613\n",
      "Epoch 60/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 295.1128 - val_loss: 257.9564\n",
      "Epoch 61/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 298.3563 - val_loss: 259.5122\n",
      "Epoch 62/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 289.9711 - val_loss: 302.4498\n",
      "Epoch 63/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 290.7032 - val_loss: 259.5880\n",
      "Epoch 64/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 287.2935 - val_loss: 265.3310\n",
      "Epoch 65/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 287.7183 - val_loss: 275.0595\n",
      "Epoch 66/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 289.5336 - val_loss: 302.1500\n",
      "Epoch 67/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 293.4407 - val_loss: 291.8191\n",
      "5670/5670 [==============================] - 0s 47us/sample - loss: 318.3346\n",
      "[CV] .......................... n_neurons=2, n_hidden=2, total= 1.3min\n",
      "[CV] n_neurons=2, n_hidden=2 .........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 146us/sample - loss: 31922.9050 - val_loss: 2346.8829\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 2389.8061 - val_loss: 2303.3395\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2354.4543 - val_loss: 2251.8043\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2313.3179 - val_loss: 2216.0146\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2274.2324 - val_loss: 2165.3405\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2226.6420 - val_loss: 2122.7224\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2180.9754 - val_loss: 2069.0613\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2128.5942 - val_loss: 2019.7196\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 2078.5118 - val_loss: 1969.7246\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2026.7139 - val_loss: 1917.4909\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1975.4261 - val_loss: 1875.1722\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1929.6090 - val_loss: 1821.3093\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1877.8257 - val_loss: 1772.6824\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1829.8171 - val_loss: 1727.2007\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1783.9114 - val_loss: 1684.7440\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1740.4626 - val_loss: 1641.6305\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1697.7740 - val_loss: 1602.1745\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1657.4843 - val_loss: 1565.7669\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1619.6391 - val_loss: 1528.6918\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1582.3372 - val_loss: 1493.6190\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1547.5479 - val_loss: 1461.2542\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1514.7435 - val_loss: 1430.8177\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1483.6888 - val_loss: 1402.0936\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1454.4687 - val_loss: 1375.2037\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1427.1258 - val_loss: 1350.1436\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1401.5770 - val_loss: 1326.8508\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1377.8417 - val_loss: 1305.4207\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1355.7267 - val_loss: 1285.5107\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1335.4539 - val_loss: 1267.4948\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 1316.8778 - val_loss: 1251.0220\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1299.8821 - val_loss: 1236.0565\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 1284.4537 - val_loss: 1222.6512\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1270.6364 - val_loss: 1210.7760\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1258.2026 - val_loss: 1200.2873\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1247.2705 - val_loss: 1191.1353\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1237.6169 - val_loss: 1183.1696\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 129us/sample - loss: 1229.2540 - val_loss: 1176.4587\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 1222.1394 - val_loss: 1170.8312\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 1216.0504 - val_loss: 1166.1705\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 1210.9083 - val_loss: 1162.3199\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 1206.6278 - val_loss: 1159.2943\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1203.1855 - val_loss: 1156.8296\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1200.3106 - val_loss: 1154.9846\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 1198.1917 - val_loss: 1153.7107\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 1196.4799 - val_loss: 1152.7556\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1195.1364 - val_loss: 1152.0551\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1194.1267 - val_loss: 1151.6109\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1193.3598 - val_loss: 1151.3281\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1192.8038 - val_loss: 1151.1660\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1192.3947 - val_loss: 1151.0957\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1192.0969 - val_loss: 1151.0812\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1191.8765 - val_loss: 1151.1037\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 1191.7215 - val_loss: 1151.1372\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1191.6090 - val_loss: 1151.1937\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 1191.5427 - val_loss: 1151.2493\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 1191.4763 - val_loss: 1151.3055\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1191.4368 - val_loss: 1151.3682\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1191.4096 - val_loss: 1151.4292\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1191.3979 - val_loss: 1151.4589\n",
      "Epoch 60/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1191.3850 - val_loss: 1151.5081\n",
      "Epoch 61/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1191.3747 - val_loss: 1151.5421\n",
      "5670/5670 [==============================] - 0s 45us/sample - loss: 1153.7498\n",
      "[CV] .......................... n_neurons=2, n_hidden=2, total= 1.2min\n",
      "[CV] n_neurons=2, n_hidden=2 .........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 143us/sample - loss: 3852.1746 - val_loss: 2262.9958\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 2273.7022 - val_loss: 2203.7084\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 2212.7839 - val_loss: 2143.1289\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 2151.9464 - val_loss: 2083.4803\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2092.3854 - val_loss: 2025.4314\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 2034.6645 - val_loss: 1969.3737\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 1978.8857 - val_loss: 1915.2406\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1925.1979 - val_loss: 1863.4419\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1873.6103 - val_loss: 1813.4398\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1824.0313 - val_loss: 1765.5761\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1776.5901 - val_loss: 1719.8530\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1731.1622 - val_loss: 1676.1389\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1687.7497 - val_loss: 1634.3193\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1646.3881 - val_loss: 1594.6534\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1607.0133 - val_loss: 1556.8770\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1569.5953 - val_loss: 1521.0651\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1534.1767 - val_loss: 1487.3790\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1500.6506 - val_loss: 1455.4843\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1469.0384 - val_loss: 1425.3185\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1439.3101 - val_loss: 1397.0695\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 1411.2974 - val_loss: 1370.6483\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1385.1575 - val_loss: 1346.0864\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 1360.8852 - val_loss: 1323.3148\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1338.3122 - val_loss: 1302.1971\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1317.5320 - val_loss: 1282.8861\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1298.4855 - val_loss: 1265.2326\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1281.0357 - val_loss: 1249.1590\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1265.1696 - val_loss: 1234.5906\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1250.8625 - val_loss: 1221.6537\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1238.0646 - val_loss: 1210.0884\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1226.7100 - val_loss: 1199.8914\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1216.7261 - val_loss: 1190.9612\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1207.9479 - val_loss: 1183.2692\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1200.3305 - val_loss: 1176.6870\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1193.8065 - val_loss: 1171.0674\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1188.3525 - val_loss: 1166.4557\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1183.8355 - val_loss: 1162.8072\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1180.1647 - val_loss: 1159.8034\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1177.2174 - val_loss: 1157.5157\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1174.8669 - val_loss: 1155.6750\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 1173.0246 - val_loss: 1154.3616\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1171.6335 - val_loss: 1153.3371\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1170.5708 - val_loss: 1152.5900\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1169.7556 - val_loss: 1152.0664\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1169.1603 - val_loss: 1151.7157\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1168.7047 - val_loss: 1151.4583\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1168.3878 - val_loss: 1151.2890\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 1168.1519 - val_loss: 1151.1840\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1167.9861 - val_loss: 1151.1267\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1167.8731 - val_loss: 1151.0990\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1167.7913 - val_loss: 1151.0838\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1167.7272 - val_loss: 1151.0809\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 1167.6912 - val_loss: 1151.0853\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 1167.6648 - val_loss: 1151.0937\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1167.6410 - val_loss: 1151.1038\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1167.6341 - val_loss: 1151.1133\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 1167.6164 - val_loss: 1151.1287\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 1167.6090 - val_loss: 1151.1459\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 1167.6108 - val_loss: 1151.1430\n",
      "Epoch 60/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1167.6037 - val_loss: 1151.1602\n",
      "Epoch 61/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1167.6043 - val_loss: 1151.1707\n",
      "Epoch 62/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 1167.5983 - val_loss: 1151.1751\n",
      "5670/5670 [==============================] - 0s 46us/sample - loss: 1231.9072\n",
      "[CV] .......................... n_neurons=2, n_hidden=2, total= 1.2min\n",
      "[CV] n_neurons=4, n_hidden=3 .........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 158us/sample - loss: 3467.8582 - val_loss: 2089.5458\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 1933.2904 - val_loss: 1659.1265\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1518.4304 - val_loss: 1318.6473\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1269.8385 - val_loss: 1178.4282\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1190.6772 - val_loss: 1152.5685\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1178.5054 - val_loss: 1151.0913\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1177.6614 - val_loss: 1151.2982\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1177.4526 - val_loss: 1151.1866\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1177.5508 - val_loss: 1151.1525\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 1177.4888 - val_loss: 1151.4686\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 1177.4792 - val_loss: 1151.1860\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 1177.5576 - val_loss: 1151.3859\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 1177.6175 - val_loss: 1151.5522\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1177.5404 - val_loss: 1151.2289\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 1177.5591 - val_loss: 1151.3038\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1177.5533 - val_loss: 1151.2705\n",
      "5670/5670 [==============================] - 0s 47us/sample - loss: 1181.6670\n",
      "[CV] .......................... n_neurons=4, n_hidden=3, total=  21.0s\n",
      "[CV] n_neurons=4, n_hidden=3 .........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 152us/sample - loss: 2343.5167 - val_loss: 2176.9269\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 2147.6316 - val_loss: 1902.4485\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1784.1070 - val_loss: 1508.1993\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1424.4395 - val_loss: 1244.3192\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 1243.3198 - val_loss: 1161.3409\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 1197.8043 - val_loss: 1151.2905\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 1191.8300 - val_loss: 1151.5244\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 1191.3991 - val_loss: 1152.0891\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 1191.4305 - val_loss: 1151.4175\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1191.5098 - val_loss: 1151.8804\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 1191.4933 - val_loss: 1151.7351\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1191.3877 - val_loss: 1152.1158\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 1191.4547 - val_loss: 1151.5076\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 1191.4855 - val_loss: 1151.8467\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 1191.4865 - val_loss: 1151.6900\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 1191.4301 - val_loss: 1151.3285\n",
      "5670/5670 [==============================] - 0s 49us/sample - loss: 1153.5570\n",
      "[CV] .......................... n_neurons=4, n_hidden=3, total=  20.7s\n",
      "[CV] n_neurons=4, n_hidden=3 .........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 159us/sample - loss: 2505.8699 - val_loss: 877.1014\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 779.1558 - val_loss: 654.8773\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 562.3866 - val_loss: 426.9709\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 443.4162 - val_loss: 384.0681\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 406.1960 - val_loss: 354.7077\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 386.4970 - val_loss: 360.9476\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 366.3306 - val_loss: 315.5951\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 359.9880 - val_loss: 324.8379\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 341.1629 - val_loss: 294.1745\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 336.6599 - val_loss: 294.3567\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 328.8320 - val_loss: 322.8114\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 323.9760 - val_loss: 278.0551\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 323.4017 - val_loss: 329.5953\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 338.2163 - val_loss: 291.8705\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 311.9968 - val_loss: 286.5247\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 328.5440 - val_loss: 266.4758\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 316.5761 - val_loss: 371.0941\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 307.0021 - val_loss: 262.1277\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 299.8607 - val_loss: 258.5676\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 296.3102 - val_loss: 267.5500\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 297.0633 - val_loss: 285.1150\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 303.6590 - val_loss: 270.8495\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 297.0951 - val_loss: 249.3278\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 303.0079 - val_loss: 253.9900\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 293.5191 - val_loss: 270.2202\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 286.2650 - val_loss: 273.4358\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 292.9529 - val_loss: 371.7131\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 297.7843 - val_loss: 341.1845\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 294.0000 - val_loss: 245.8594\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 288.7321 - val_loss: 256.5212\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 301.1185 - val_loss: 254.4723\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 297.9132 - val_loss: 248.4333\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 285.3310 - val_loss: 332.0669\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 288.1877 - val_loss: 248.0201\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 285.4595 - val_loss: 244.7552\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 283.5077 - val_loss: 265.8302\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 293.3155 - val_loss: 241.4948\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 280.4429 - val_loss: 239.4151\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 282.5137 - val_loss: 260.2826\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 280.5913 - val_loss: 235.3768\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 283.4950 - val_loss: 259.4397\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 280.1390 - val_loss: 264.8227\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 281.2229 - val_loss: 248.4494\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 285.1301 - val_loss: 257.9539\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 276.7373 - val_loss: 235.1485\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 282.4769 - val_loss: 235.5500\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 271.5040 - val_loss: 237.4049\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 274.7350 - val_loss: 245.1526\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 269.8472 - val_loss: 239.9459\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 282.0291 - val_loss: 247.0298\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 269.5855 - val_loss: 241.7785\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 274.5024 - val_loss: 238.8598\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 129us/sample - loss: 279.7792 - val_loss: 333.2130\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 123us/sample - loss: 276.0336 - val_loss: 252.1513\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 270.3919 - val_loss: 249.7465\n",
      "5670/5670 [==============================] - 0s 48us/sample - loss: 268.9466\n",
      "[CV] .......................... n_neurons=4, n_hidden=3, total= 1.2min\n",
      "[CV] n_neurons=68, n_hidden=0 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 52448.2689 - val_loss: 1369.3677\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 1051.2318 - val_loss: 680.0419\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 96us/sample - loss: 613.4815 - val_loss: 505.8572\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 514.4580 - val_loss: 525.7044\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 480.7870 - val_loss: 564.9646\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 501.2607 - val_loss: 478.1307\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 448.8705 - val_loss: 397.8186\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 97us/sample - loss: 440.1952 - val_loss: 373.5028\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 500.6420 - val_loss: 759.3431\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 451.5239 - val_loss: 350.2572\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 472.1168 - val_loss: 337.9984\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 90us/sample - loss: 473.7599 - val_loss: 342.4740\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 93us/sample - loss: 464.8225 - val_loss: 384.2547\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 467.6322 - val_loss: 349.0897\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 92us/sample - loss: 455.1385 - val_loss: 394.4749\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 486.4490 - val_loss: 374.8078\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 89us/sample - loss: 411.7227 - val_loss: 350.4254\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 95us/sample - loss: 442.8767 - val_loss: 423.8343\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 452.1939 - val_loss: 580.5588\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 449.9153 - val_loss: 359.4206\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 454.2224 - val_loss: 427.8268\n",
      "5670/5670 [==============================] - 0s 45us/sample - loss: 459.7956\n",
      "[CV] ......................... n_neurons=68, n_hidden=0, total=  23.2s\n",
      "[CV] n_neurons=68, n_hidden=0 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 1s 121us/sample - loss: 42829.1229 - val_loss: 4673.4185\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 3049.6627 - val_loss: 1914.4805\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 1449.1657 - val_loss: 953.2104\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 943.1726 - val_loss: 789.3387\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 709.2485 - val_loss: 568.3890\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 588.1795 - val_loss: 498.1484\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 569.0538 - val_loss: 522.0469\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 531.5079 - val_loss: 472.9062\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 473.5490 - val_loss: 408.0507\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 459.3438 - val_loss: 370.2668\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 475.8756 - val_loss: 550.3124\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 520.5729 - val_loss: 426.0217\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 524.3298 - val_loss: 578.6235\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 451.3712 - val_loss: 434.2675\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 458.2155 - val_loss: 360.2274\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 514.5382 - val_loss: 337.8040\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 474.7414 - val_loss: 389.0431\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 438.6724 - val_loss: 449.7863\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 482.4002 - val_loss: 331.0006\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 490.4452 - val_loss: 371.1310\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 487.0792 - val_loss: 619.3175\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 411.5533 - val_loss: 388.1150\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 450.1898 - val_loss: 320.2954\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 433.5782 - val_loss: 810.0688\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 472.1093 - val_loss: 417.7346\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 549.6673 - val_loss: 390.4054\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 420.0841 - val_loss: 334.8109\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 444.7768 - val_loss: 315.1584\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 419.7835 - val_loss: 311.8605\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 406.9789 - val_loss: 365.5691\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 492.3674 - val_loss: 316.4017\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 92us/sample - loss: 470.6249 - val_loss: 448.9217\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 427.5206 - val_loss: 451.1532\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 405.9765 - val_loss: 299.5225\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 437.4739 - val_loss: 878.5596\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 499.8415 - val_loss: 894.5258\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 448.1834 - val_loss: 948.8259\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 428.6640 - val_loss: 420.0118\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 420.6172 - val_loss: 643.7734\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 523.4607 - val_loss: 412.3702\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 431.2371 - val_loss: 296.0513\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 385.8720 - val_loss: 343.5127\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 419.0125 - val_loss: 822.3028\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 400.9865 - val_loss: 418.9157\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 472.8640 - val_loss: 395.2240\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 388.1293 - val_loss: 313.0128\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 440.2727 - val_loss: 340.2268\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 482.7626 - val_loss: 2063.1303\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 538.5010 - val_loss: 427.2385\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 451.1057 - val_loss: 561.2849\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 395.4343 - val_loss: 723.0897\n",
      "5670/5670 [==============================] - 0s 40us/sample - loss: 1358.3940\n",
      "[CV] ......................... n_neurons=68, n_hidden=0, total=  50.2s\n",
      "[CV] n_neurons=68, n_hidden=0 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 129244.2633 - val_loss: 10728.2227\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 88us/sample - loss: 8103.8137 - val_loss: 5695.9153\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 4604.4778 - val_loss: 3482.9776\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 2963.0586 - val_loss: 2497.4417\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 87us/sample - loss: 2080.4771 - val_loss: 1705.7730\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 1553.9279 - val_loss: 1342.9297\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 1180.9691 - val_loss: 1019.3164\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 935.2239 - val_loss: 767.0998\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 780.8138 - val_loss: 647.4599\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 636.6541 - val_loss: 580.7711\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 553.0618 - val_loss: 506.6814\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 534.5682 - val_loss: 618.7568\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 482.7335 - val_loss: 723.7500\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 480.3489 - val_loss: 546.1367\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 452.0776 - val_loss: 404.7566\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 490.2794 - val_loss: 412.0702\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 438.6768 - val_loss: 353.0520\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 474.8229 - val_loss: 376.7054\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 448.4852 - val_loss: 424.8162\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 483.2146 - val_loss: 324.6169\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 481.6040 - val_loss: 701.3624\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 480.5005 - val_loss: 327.5068\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 511.3419 - val_loss: 313.0351\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 415.1985 - val_loss: 722.7774\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 628.9124 - val_loss: 332.0288\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 392.7863 - val_loss: 502.6499\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 422.9092 - val_loss: 393.5701\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 440.1084 - val_loss: 311.4130\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 531.9054 - val_loss: 459.9889\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 86us/sample - loss: 496.6764 - val_loss: 446.3827\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 84us/sample - loss: 482.6763 - val_loss: 335.4063\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 395.6053 - val_loss: 389.1985\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 409.0662 - val_loss: 458.6058\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 433.9081 - val_loss: 570.2716\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 455.2778 - val_loss: 518.4117\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 461.2440 - val_loss: 339.0915\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 85us/sample - loss: 458.1823 - val_loss: 526.8705\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 83us/sample - loss: 422.3577 - val_loss: 395.4066\n",
      "5670/5670 [==============================] - 0s 42us/sample - loss: 462.1812\n",
      "[CV] ......................... n_neurons=68, n_hidden=0, total=  37.2s\n",
      "[CV] n_neurons=96, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 184us/sample - loss: 14924.4426 - val_loss: 538.0902\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 594.9606 - val_loss: 381.8536\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 610.2005 - val_loss: 376.4621\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 975.4444 - val_loss: 499.4745\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 429.8718 - val_loss: 335.1921\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 497.9539 - val_loss: 495.5118\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 448.4466 - val_loss: 321.2845\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 564.2288 - val_loss: 397.5491\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 443.8491 - val_loss: 479.8884\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 395.7302 - val_loss: 306.3244\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 366.5274 - val_loss: 327.1297\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 393.2360 - val_loss: 326.9159\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 337.5625 - val_loss: 501.3523\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 340.8313 - val_loss: 295.1692\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 316.8001 - val_loss: 258.9631\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 297.7257 - val_loss: 269.6681\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 300.0965 - val_loss: 352.3080\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 307.1437 - val_loss: 282.6139\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 313.9223 - val_loss: 260.6270\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 293.6043 - val_loss: 273.4216\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 290.5377 - val_loss: 275.3402\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 287.4005 - val_loss: 271.4368\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 297.5745 - val_loss: 255.0301\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 289.7855 - val_loss: 306.1095\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 288.3121 - val_loss: 243.4552\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 291.4832 - val_loss: 251.1940\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 277.4906 - val_loss: 252.9709\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 278.2365 - val_loss: 273.9397\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 285.7912 - val_loss: 344.2576\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 275.7999 - val_loss: 355.7764\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 279.9959 - val_loss: 255.6538\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 274.3055 - val_loss: 235.3717\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 275.7486 - val_loss: 245.0042\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 278.2360 - val_loss: 254.1556\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 279.5146 - val_loss: 247.9496\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 272.2920 - val_loss: 291.2116\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 281.4435 - val_loss: 245.6449\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 275.7912 - val_loss: 282.2913\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 279.3950 - val_loss: 247.0241\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 277.8248 - val_loss: 282.7405\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 274.2466 - val_loss: 236.5409\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 276.3555 - val_loss: 302.4046\n",
      "5670/5670 [==============================] - 0s 44us/sample - loss: 325.3304\n",
      "[CV] ......................... n_neurons=96, n_hidden=2, total=  51.2s\n",
      "[CV] n_neurons=96, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 145us/sample - loss: 6125.0668 - val_loss: 1210.5288\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 1060.4212 - val_loss: 453.8315\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 720.1788 - val_loss: 494.7596\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 625.1719 - val_loss: 380.6818\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 565.7341 - val_loss: 559.2471\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 417.5546 - val_loss: 410.9735\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 425.4518 - val_loss: 302.1577\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 418.4476 - val_loss: 295.0315\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 405.8880 - val_loss: 288.8057\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 341.9254 - val_loss: 517.4370\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 326.0749 - val_loss: 330.8016\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 318.2901 - val_loss: 290.3812\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 322.4031 - val_loss: 271.2233\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 314.9712 - val_loss: 296.6006\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 316.6627 - val_loss: 394.2908\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 306.8033 - val_loss: 308.7576\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 305.2553 - val_loss: 476.4899\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 301.9854 - val_loss: 264.9764\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 298.7853 - val_loss: 344.4905\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 298.8023 - val_loss: 259.0949\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 301.4075 - val_loss: 294.4252\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 292.1818 - val_loss: 413.2360\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 285.1964 - val_loss: 276.2025\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 299.6182 - val_loss: 258.6793\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 291.5504 - val_loss: 245.2135\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 276.5804 - val_loss: 403.2315\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 308.9132 - val_loss: 252.5780\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 281.6612 - val_loss: 238.4460\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 282.9256 - val_loss: 262.4591\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 267.5715 - val_loss: 257.6215\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 285.7614 - val_loss: 262.5046\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 277.3160 - val_loss: 264.4695\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 293.5970 - val_loss: 241.9253\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 269.5426 - val_loss: 252.0489\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 277.4432 - val_loss: 316.3836\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 271.6729 - val_loss: 245.4291\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 280.1078 - val_loss: 282.2296\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 275.3909 - val_loss: 232.9259\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 267.8362 - val_loss: 234.3911\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 269.7935 - val_loss: 233.6322\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 260.0423 - val_loss: 253.7431\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 275.9730 - val_loss: 233.2909\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 270.2623 - val_loss: 238.4622\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 261.4796 - val_loss: 255.5662\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 255.2799 - val_loss: 234.3395\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 268.2176 - val_loss: 237.4991\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 260.8113 - val_loss: 241.1010\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 254.4571 - val_loss: 226.8616\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 258.0659 - val_loss: 229.5666\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 259.7903 - val_loss: 260.6520\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 264.2857 - val_loss: 227.4004\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 259.4050 - val_loss: 224.2558\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 261.1442 - val_loss: 292.7784\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 250.5946 - val_loss: 238.0263\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 257.8341 - val_loss: 259.5591\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 253.3167 - val_loss: 222.7362\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 259.2492 - val_loss: 223.3789\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 258.6314 - val_loss: 235.8096\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 257.2466 - val_loss: 228.5408\n",
      "Epoch 60/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 247.0690 - val_loss: 224.5938\n",
      "Epoch 61/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 259.7361 - val_loss: 233.2378\n",
      "Epoch 62/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 251.6069 - val_loss: 234.3563\n",
      "Epoch 63/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 251.4352 - val_loss: 279.8690\n",
      "Epoch 64/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 259.5010 - val_loss: 235.1090\n",
      "Epoch 65/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 250.9511 - val_loss: 223.9092\n",
      "Epoch 66/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 248.7378 - val_loss: 225.3684\n",
      "5670/5670 [==============================] - 0s 53us/sample - loss: 248.5309\n",
      "[CV] ......................... n_neurons=96, n_hidden=2, total= 1.3min\n",
      "[CV] n_neurons=96, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 143us/sample - loss: 20177.1774 - val_loss: 718.1306\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 678.9570 - val_loss: 548.8732\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 638.5313 - val_loss: 543.2728\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 656.7669 - val_loss: 499.0360\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 642.5658 - val_loss: 1049.7692\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 582.9746 - val_loss: 1290.3134\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 745.1704 - val_loss: 405.5518\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 606.2182 - val_loss: 539.3607\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 493.5537 - val_loss: 476.2661\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 480.2692 - val_loss: 324.2040\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 462.3396 - val_loss: 374.6365\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 411.9879 - val_loss: 372.4243\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 369.5514 - val_loss: 529.4507\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 379.7311 - val_loss: 421.6943\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 375.7066 - val_loss: 264.9560\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 346.6248 - val_loss: 334.2662\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 336.4230 - val_loss: 336.7594\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 328.1604 - val_loss: 327.7649\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 324.9816 - val_loss: 251.0463\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 332.8317 - val_loss: 253.5427\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 317.0518 - val_loss: 273.3611\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 291.7594 - val_loss: 249.0667\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 297.9177 - val_loss: 265.4718\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 295.1155 - val_loss: 316.8196\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 302.9309 - val_loss: 251.2967\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 304.3339 - val_loss: 251.5887\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 295.0874 - val_loss: 276.6034\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 299.8058 - val_loss: 236.4553\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 295.0407 - val_loss: 255.3137\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 296.0632 - val_loss: 305.5220\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 289.9188 - val_loss: 307.5204\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 297.9389 - val_loss: 270.9160\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 292.9980 - val_loss: 263.1925\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 288.5164 - val_loss: 252.2618\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 281.0868 - val_loss: 255.8118\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 283.3254 - val_loss: 345.5870\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 287.6472 - val_loss: 248.3939\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 283.8540 - val_loss: 239.8074\n",
      "5670/5670 [==============================] - 0s 47us/sample - loss: 253.1946\n",
      "[CV] ......................... n_neurons=96, n_hidden=2, total=  45.5s\n",
      "[CV] n_neurons=56, n_hidden=3 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 154us/sample - loss: 2483.8019 - val_loss: 428.2945\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 521.7998 - val_loss: 477.8891\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 471.5420 - val_loss: 389.5993\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 412.0075 - val_loss: 368.8450\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 378.2116 - val_loss: 335.3642\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 340.8543 - val_loss: 385.6626\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 342.6910 - val_loss: 275.5970\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 336.5293 - val_loss: 328.3608\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 327.5125 - val_loss: 398.5773\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 117us/sample - loss: 327.9739 - val_loss: 372.0368\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 318.3815 - val_loss: 290.6446\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 130us/sample - loss: 308.1721 - val_loss: 288.1531\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 119us/sample - loss: 312.8668 - val_loss: 272.6755\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 302.9609 - val_loss: 265.8834\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 301.5530 - val_loss: 261.0610\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 290.6093 - val_loss: 267.3543\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 286.9602 - val_loss: 251.0244\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 278.8056 - val_loss: 286.7180\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 298.0389 - val_loss: 283.4887\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 284.3832 - val_loss: 242.9733\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 288.9406 - val_loss: 265.6311\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 284.0058 - val_loss: 246.9014\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 272.8885 - val_loss: 288.5691\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 290.0096 - val_loss: 308.2230\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 273.1166 - val_loss: 246.9895\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 275.4866 - val_loss: 343.1669\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 278.6949 - val_loss: 248.7651\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 279.6817 - val_loss: 257.7201\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 276.8638 - val_loss: 232.9092\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 271.0182 - val_loss: 249.5097\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 266.4150 - val_loss: 233.1994\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 271.9491 - val_loss: 313.6368\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 263.6610 - val_loss: 227.6798\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 126us/sample - loss: 268.2951 - val_loss: 261.0238\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 120us/sample - loss: 265.5237 - val_loss: 330.3811\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 118us/sample - loss: 260.9468 - val_loss: 255.2255\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 263.9816 - val_loss: 244.6433\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 267.9265 - val_loss: 244.2314\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 263.6116 - val_loss: 302.3379\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 266.1609 - val_loss: 234.9554\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 258.6280 - val_loss: 224.7888\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 261.5936 - val_loss: 231.2588\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 262.1928 - val_loss: 246.0854\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 261.0611 - val_loss: 231.4314\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 258.1714 - val_loss: 228.4616\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 255.4778 - val_loss: 225.9982\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 260.2924 - val_loss: 254.3408\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 246.1519 - val_loss: 228.4655\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 261.2148 - val_loss: 340.7713\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 255.7258 - val_loss: 233.3044\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 249.7482 - val_loss: 216.0249\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 255.3283 - val_loss: 273.2249\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 251.7680 - val_loss: 215.4363\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 117us/sample - loss: 251.1590 - val_loss: 257.0427\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 246.7245 - val_loss: 242.4181\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 256.7254 - val_loss: 228.1252\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 239.0493 - val_loss: 211.2116\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 244.4712 - val_loss: 224.1695\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 247.3646 - val_loss: 240.9656\n",
      "Epoch 60/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 253.6116 - val_loss: 219.4457\n",
      "Epoch 61/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 252.7763 - val_loss: 229.4736\n",
      "Epoch 62/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 236.1926 - val_loss: 217.6091\n",
      "Epoch 63/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 240.7505 - val_loss: 216.1957\n",
      "Epoch 64/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 249.5171 - val_loss: 220.5973\n",
      "Epoch 65/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 245.7990 - val_loss: 217.0391\n",
      "Epoch 66/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 244.5061 - val_loss: 229.8660\n",
      "Epoch 67/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 247.0410 - val_loss: 213.1121\n",
      "5670/5670 [==============================] - 0s 49us/sample - loss: 230.9639\n",
      "[CV] ......................... n_neurons=56, n_hidden=3, total= 1.4min\n",
      "[CV] n_neurons=56, n_hidden=3 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 157us/sample - loss: 14125.1766 - val_loss: 613.6177\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 512.0292 - val_loss: 394.1118\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 442.1181 - val_loss: 506.7951\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 459.6813 - val_loss: 350.3901\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 408.7793 - val_loss: 370.7086\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 372.7861 - val_loss: 550.8303\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 449.4607 - val_loss: 367.8084\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 363.6590 - val_loss: 423.5606\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 373.3207 - val_loss: 269.4269\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 340.3073 - val_loss: 457.2095\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 2s 137us/sample - loss: 327.6162 - val_loss: 275.4843\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 130us/sample - loss: 334.1932 - val_loss: 359.1496\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 123us/sample - loss: 333.5141 - val_loss: 377.2320\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 129us/sample - loss: 330.2443 - val_loss: 304.6519\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 2s 138us/sample - loss: 299.3778 - val_loss: 300.4703\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 2s 134us/sample - loss: 297.6500 - val_loss: 278.2191\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 278.8842 - val_loss: 251.5818\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 281.8651 - val_loss: 284.6445\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 279.0532 - val_loss: 242.1040\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 300.7686 - val_loss: 348.5301\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 279.1119 - val_loss: 300.9475\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 287.3881 - val_loss: 249.2935\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 271.3153 - val_loss: 268.6269\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 271.3386 - val_loss: 282.5206\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 293.9185 - val_loss: 377.5555\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 278.1036 - val_loss: 239.3735\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 264.6007 - val_loss: 276.9160\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 275.0741 - val_loss: 259.4668\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 273.0693 - val_loss: 244.6609\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 272.3906 - val_loss: 262.6402\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 268.0809 - val_loss: 251.3250\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 262.5193 - val_loss: 233.3012\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 261.6034 - val_loss: 300.0018\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 271.1688 - val_loss: 327.7594\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 269.8638 - val_loss: 226.4253\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 251.5974 - val_loss: 235.0421\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 257.3485 - val_loss: 231.0539\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 262.5550 - val_loss: 264.5813\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 257.7099 - val_loss: 231.8236\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 263.9901 - val_loss: 292.7548\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 268.2114 - val_loss: 245.6595\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 243.6304 - val_loss: 227.2845\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 251.6292 - val_loss: 251.1453\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 252.6422 - val_loss: 231.4242\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 246.7307 - val_loss: 243.5475\n",
      "5670/5670 [==============================] - 0s 50us/sample - loss: 265.5827\n",
      "[CV] ......................... n_neurons=56, n_hidden=3, total=  59.4s\n",
      "[CV] n_neurons=56, n_hidden=3 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 158us/sample - loss: 2097.1709 - val_loss: 452.0334\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 500.8790 - val_loss: 408.3470\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 396.5204 - val_loss: 343.6211\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 367.3301 - val_loss: 283.7482\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 370.5945 - val_loss: 568.9540\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 348.7686 - val_loss: 270.6250\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 325.6061 - val_loss: 312.0337\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 308.6346 - val_loss: 275.8614\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 326.9523 - val_loss: 302.4123\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 314.6170 - val_loss: 317.6626\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 312.6959 - val_loss: 286.5066\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 317.7807 - val_loss: 259.1652\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 291.4396 - val_loss: 263.6847\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 299.8305 - val_loss: 254.0994\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 113us/sample - loss: 314.3568 - val_loss: 303.6390\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 291.6390 - val_loss: 292.1670\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 318.2134 - val_loss: 299.3629\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 303.0099 - val_loss: 249.6794\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 282.7868 - val_loss: 246.2766\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 300.1823 - val_loss: 242.7743\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 280.8897 - val_loss: 235.7775\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 282.8854 - val_loss: 259.4284\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 280.4778 - val_loss: 293.9888\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 280.3965 - val_loss: 321.7163\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 289.6805 - val_loss: 314.1947\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 276.4665 - val_loss: 233.4773\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 275.4079 - val_loss: 413.0564\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 283.4771 - val_loss: 262.4998\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 281.5773 - val_loss: 254.6233\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 273.7633 - val_loss: 232.2222\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 268.1209 - val_loss: 224.9002\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 272.6634 - val_loss: 288.3957\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 270.3003 - val_loss: 264.8184\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 266.7789 - val_loss: 244.1238\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 258.4496 - val_loss: 245.1461\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 270.1712 - val_loss: 239.8881\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 272.0436 - val_loss: 257.6040\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 276.9436 - val_loss: 249.4098\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 259.8106 - val_loss: 257.8064\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 262.2040 - val_loss: 282.9457\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 254.4459 - val_loss: 249.9419\n",
      "5670/5670 [==============================] - 0s 49us/sample - loss: 260.5807\n",
      "[CV] ......................... n_neurons=56, n_hidden=3, total=  52.6s\n",
      "[CV] n_neurons=12, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 142us/sample - loss: 4376.0515 - val_loss: 636.5769\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 625.7616 - val_loss: 673.2167\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 545.3687 - val_loss: 467.6831\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 510.4525 - val_loss: 613.6330\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 487.8884 - val_loss: 397.3338\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 421.0907 - val_loss: 459.2225\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 410.9768 - val_loss: 369.1828\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 380.6610 - val_loss: 324.9267\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 381.8668 - val_loss: 332.7921\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 338.1696 - val_loss: 323.4788\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 328.1577 - val_loss: 286.9621\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 328.9872 - val_loss: 337.9834\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 330.3696 - val_loss: 267.1580\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 314.6839 - val_loss: 311.0160\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 309.1975 - val_loss: 298.9577\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 309.5207 - val_loss: 269.8116\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 311.1890 - val_loss: 273.3831\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 297.1028 - val_loss: 284.9943\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 109us/sample - loss: 294.5568 - val_loss: 255.7059\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 289.7260 - val_loss: 245.3680\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 288.4132 - val_loss: 266.4612\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 294.3836 - val_loss: 273.3183\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 287.5915 - val_loss: 247.9868\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 285.8748 - val_loss: 251.9413\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 289.8276 - val_loss: 264.4988\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 277.9091 - val_loss: 261.6934\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 290.7176 - val_loss: 263.8022\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 280.8703 - val_loss: 304.2048\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 285.5527 - val_loss: 262.8897\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 285.9037 - val_loss: 283.5961\n",
      "5670/5670 [==============================] - 0s 47us/sample - loss: 310.1038\n",
      "[CV] ......................... n_neurons=12, n_hidden=2, total=  36.2s\n",
      "[CV] n_neurons=12, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 142us/sample - loss: 14293.3328 - val_loss: 1157.9303\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 1066.1195 - val_loss: 860.7742\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 792.6361 - val_loss: 647.2571\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 631.3376 - val_loss: 554.2225\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 528.1923 - val_loss: 549.2529\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 509.0528 - val_loss: 452.3722\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 487.3070 - val_loss: 428.1906\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 469.7283 - val_loss: 460.5308\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 468.3023 - val_loss: 443.1317\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 105us/sample - loss: 444.9458 - val_loss: 409.8686\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 429.7670 - val_loss: 385.2205\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 419.3784 - val_loss: 378.7962\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 397.4455 - val_loss: 336.8878\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 356.8429 - val_loss: 304.8793\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 335.2905 - val_loss: 323.5850\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 325.0238 - val_loss: 296.7069\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 327.9146 - val_loss: 311.3864\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 330.7227 - val_loss: 310.6289\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 321.2621 - val_loss: 296.4899\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 311.3894 - val_loss: 379.0630\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 306.3464 - val_loss: 280.3231\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 127us/sample - loss: 313.5772 - val_loss: 265.7864\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 303.5831 - val_loss: 270.4402\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 298.5252 - val_loss: 316.9701\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 316.6474 - val_loss: 308.3036\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 115us/sample - loss: 307.0782 - val_loss: 325.2196\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 120us/sample - loss: 313.5060 - val_loss: 363.1446\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 312.4075 - val_loss: 288.2539\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 111us/sample - loss: 291.8368 - val_loss: 276.6155\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 297.7324 - val_loss: 387.9453\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 114us/sample - loss: 297.9625 - val_loss: 346.0328\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 301.3471 - val_loss: 283.1332\n",
      "5670/5670 [==============================] - 0s 75us/sample - loss: 309.5107\n",
      "[CV] ......................... n_neurons=12, n_hidden=2, total=  39.9s\n",
      "[CV] n_neurons=12, n_hidden=2 ........................................\n",
      "Train on 11340 samples, validate on 4253 samples\n",
      "Epoch 1/100\n",
      "11340/11340 [==============================] - 2s 147us/sample - loss: 4108.8515 - val_loss: 730.7353\n",
      "Epoch 2/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 713.1333 - val_loss: 701.2717\n",
      "Epoch 3/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 600.6437 - val_loss: 516.7732\n",
      "Epoch 4/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 545.4007 - val_loss: 595.1698\n",
      "Epoch 5/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 488.7730 - val_loss: 438.6640\n",
      "Epoch 6/100\n",
      "11340/11340 [==============================] - 2s 140us/sample - loss: 455.0457 - val_loss: 462.7610\n",
      "Epoch 7/100\n",
      "11340/11340 [==============================] - 1s 125us/sample - loss: 422.1036 - val_loss: 393.0045\n",
      "Epoch 8/100\n",
      "11340/11340 [==============================] - 1s 108us/sample - loss: 402.7918 - val_loss: 526.7241\n",
      "Epoch 9/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 391.8072 - val_loss: 349.7630\n",
      "Epoch 10/100\n",
      "11340/11340 [==============================] - 1s 116us/sample - loss: 380.1538 - val_loss: 331.1862\n",
      "Epoch 11/100\n",
      "11340/11340 [==============================] - 1s 107us/sample - loss: 358.1570 - val_loss: 340.6806\n",
      "Epoch 12/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 349.4387 - val_loss: 421.8774\n",
      "Epoch 13/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 356.4357 - val_loss: 300.3963\n",
      "Epoch 14/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 348.3291 - val_loss: 317.7834\n",
      "Epoch 15/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 331.6865 - val_loss: 411.9913\n",
      "Epoch 16/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 336.4333 - val_loss: 265.8453\n",
      "Epoch 17/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 319.9882 - val_loss: 264.4255\n",
      "Epoch 18/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 321.1772 - val_loss: 407.1177\n",
      "Epoch 19/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 327.1582 - val_loss: 289.2320\n",
      "Epoch 20/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 317.6507 - val_loss: 385.0601\n",
      "Epoch 21/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 310.4765 - val_loss: 291.5089\n",
      "Epoch 22/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 296.3158 - val_loss: 252.2228\n",
      "Epoch 23/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 306.7428 - val_loss: 303.8416\n",
      "Epoch 24/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 287.1527 - val_loss: 270.8422\n",
      "Epoch 25/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 305.3712 - val_loss: 249.0372\n",
      "Epoch 26/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 305.7538 - val_loss: 263.7141\n",
      "Epoch 27/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 307.6481 - val_loss: 249.3012\n",
      "Epoch 28/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 292.0830 - val_loss: 252.4254\n",
      "Epoch 29/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 286.0215 - val_loss: 281.0800\n",
      "Epoch 30/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 290.3237 - val_loss: 243.5109\n",
      "Epoch 31/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 283.3508 - val_loss: 248.8556\n",
      "Epoch 32/100\n",
      "11340/11340 [==============================] - 1s 120us/sample - loss: 284.4825 - val_loss: 267.5034\n",
      "Epoch 33/100\n",
      "11340/11340 [==============================] - 1s 122us/sample - loss: 282.0237 - val_loss: 257.6101\n",
      "Epoch 34/100\n",
      "11340/11340 [==============================] - 1s 124us/sample - loss: 281.8649 - val_loss: 245.5608\n",
      "Epoch 35/100\n",
      "11340/11340 [==============================] - 1s 123us/sample - loss: 282.2827 - val_loss: 233.2717\n",
      "Epoch 36/100\n",
      "11340/11340 [==============================] - 1s 110us/sample - loss: 289.3043 - val_loss: 239.7588\n",
      "Epoch 37/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 281.6940 - val_loss: 297.9429\n",
      "Epoch 38/100\n",
      "11340/11340 [==============================] - 2s 137us/sample - loss: 276.7446 - val_loss: 232.0747\n",
      "Epoch 39/100\n",
      "11340/11340 [==============================] - 1s 131us/sample - loss: 268.8726 - val_loss: 256.5690\n",
      "Epoch 40/100\n",
      "11340/11340 [==============================] - 2s 133us/sample - loss: 278.3409 - val_loss: 264.0191\n",
      "Epoch 41/100\n",
      "11340/11340 [==============================] - 1s 130us/sample - loss: 275.5789 - val_loss: 319.4838\n",
      "Epoch 42/100\n",
      "11340/11340 [==============================] - 1s 128us/sample - loss: 270.0135 - val_loss: 237.1208\n",
      "Epoch 43/100\n",
      "11340/11340 [==============================] - 2s 135us/sample - loss: 273.2398 - val_loss: 242.4043\n",
      "Epoch 44/100\n",
      "11340/11340 [==============================] - 1s 131us/sample - loss: 270.4726 - val_loss: 230.3216\n",
      "Epoch 45/100\n",
      "11340/11340 [==============================] - 1s 126us/sample - loss: 278.5762 - val_loss: 226.9732\n",
      "Epoch 46/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 284.6982 - val_loss: 234.9638\n",
      "Epoch 47/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 275.4360 - val_loss: 238.9775\n",
      "Epoch 48/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 269.4800 - val_loss: 245.9357\n",
      "Epoch 49/100\n",
      "11340/11340 [==============================] - 1s 98us/sample - loss: 275.3357 - val_loss: 226.9265\n",
      "Epoch 50/100\n",
      "11340/11340 [==============================] - 1s 100us/sample - loss: 265.2194 - val_loss: 285.2257\n",
      "Epoch 51/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 274.7641 - val_loss: 278.0554\n",
      "Epoch 52/100\n",
      "11340/11340 [==============================] - 1s 99us/sample - loss: 277.9244 - val_loss: 246.0545\n",
      "Epoch 53/100\n",
      "11340/11340 [==============================] - 1s 101us/sample - loss: 271.3641 - val_loss: 280.9158\n",
      "Epoch 54/100\n",
      "11340/11340 [==============================] - 1s 106us/sample - loss: 274.3901 - val_loss: 251.4834\n",
      "Epoch 55/100\n",
      "11340/11340 [==============================] - 1s 102us/sample - loss: 261.9803 - val_loss: 235.3175\n",
      "Epoch 56/100\n",
      "11340/11340 [==============================] - 1s 103us/sample - loss: 269.7385 - val_loss: 231.8028\n",
      "Epoch 57/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 271.8194 - val_loss: 233.8637\n",
      "Epoch 58/100\n",
      "11340/11340 [==============================] - 1s 112us/sample - loss: 270.0012 - val_loss: 239.4119\n",
      "Epoch 59/100\n",
      "11340/11340 [==============================] - 1s 104us/sample - loss: 265.3140 - val_loss: 315.3857\n",
      "5670/5670 [==============================] - 0s 44us/sample - loss: 327.1918\n",
      "[CV] ......................... n_neurons=12, n_hidden=2, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 25.0min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001A4A8BF9508>, as the constructor either does not set or modifies parameter n_neurons",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-464966e34335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0;32m     12\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001A4A8BF9508>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "#     \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_test, y_test),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 56, 'n_hidden': 3}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-252.37579786333177"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3b40e07bb81d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'scorer_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-cbbd136c11f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \"\"\"\n\u001b[0;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m             raise ValueError(\"No score function explicitly defined, \"\n\u001b[0;32m    455\u001b[0m                              \u001b[1;34m\"and the estimator doesn't provide one %s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'scorer_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-f89828bd4b63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4253/4253 [==============================] - 0s 112us/sample - loss: 117.0583 - mae: 6.2922 - mse: 117.0583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[117.05830064706737, 6.2922287, 117.058304]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
